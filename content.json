{"meta":{"title":"SN1987A","subtitle":"LAYのBLOG","description":"Learn not and know not.","author":"SN1987A","url":"http://sn1987a-1.github.io","root":"/"},"pages":[{"title":"关于本站","date":"2020-04-19T04:58:56.000Z","updated":"2022-03-01T07:45:21.165Z","comments":false,"path":"about/index.html","permalink":"http://sn1987a-1.github.io/about/index.html","excerpt":"","text":"SN1987ALearn not and know not. USTC cser 2020. =^= 联系我QQ：945093063phone:18306552190mail:lay_sn1987a@mail.ustc.edu.cn"},{"title":"分类","date":"2020-11-24T07:12:19.000Z","updated":"2022-03-01T07:46:03.375Z","comments":false,"path":"categories/index.html","permalink":"http://sn1987a-1.github.io/categories/index.html","excerpt":"","text":""},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2022-03-01T07:45:35.465Z","comments":true,"path":"archives/index.html","permalink":"http://sn1987a-1.github.io/archives/index.html","excerpt":"","text":""},{"title":"留言板","date":"2020-10-31T02:11:28.000Z","updated":"2022-03-01T07:46:33.435Z","comments":false,"path":"comments/index.html","permalink":"http://sn1987a-1.github.io/comments/index.html","excerpt":"","text":"new Artitalk({ appId: 'o2lydQokojD1IP8EGhex24WU-MdYXbMMI', appKey: '8ykSyPm9CwzCDdR5dbid1AWT' })"},{"title":"友情链接","date":"2018-06-07T14:17:49.000Z","updated":"2022-03-01T07:48:07.885Z","comments":true,"path":"link/index.html","permalink":"http://sn1987a-1.github.io/link/index.html","excerpt":"","text":""},{"title":"我的歌单","date":"2019-05-17T08:14:00.000Z","updated":"2022-02-07T02:33:38.000Z","comments":true,"path":"music/index.html","permalink":"http://sn1987a-1.github.io/music/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-11-24T07:14:39.000Z","updated":"2022-03-01T07:49:18.985Z","comments":false,"path":"tags/index.html","permalink":"http://sn1987a-1.github.io/tags/index.html","excerpt":"","text":""},{"title":"相册","date":"2022-02-09T00:58:41.100Z","updated":"2022-01-27T13:30:37.000Z","comments":false,"path":"List/gallery/index.html","permalink":"http://sn1987a-1.github.io/List/gallery/index.html","excerpt":"","text":"壁纸 收藏的一些壁纸 OH MY GIRL 关于OH MY GIRL的图片"},{"title":"Music-BBOX","date":"2020-04-23T04:58:56.000Z","updated":"2022-02-06T09:31:49.000Z","comments":false,"path":"List/music/index.html","permalink":"http://sn1987a-1.github.io/List/music/index.html","excerpt":"","text":""},{"title":"","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-27T13:30:37.000Z","comments":false,"path":"List/movies/index.html","permalink":"http://sn1987a-1.github.io/List/movies/index.html","excerpt":"","text":"励志视频"},{"title":"","date":"2020-11-24T08:05:01.000Z","updated":"2022-01-27T13:30:37.000Z","comments":false,"path":"List/gallery/ohmygirl/index.html","permalink":"http://sn1987a-1.github.io/List/gallery/ohmygirl/index.html","excerpt":"","text":""},{"title":"","date":"2022-02-09T00:58:41.100Z","updated":"2022-01-27T13:30:37.000Z","comments":false,"path":"List/gallery/wallpaper/index.html","permalink":"http://sn1987a-1.github.io/List/gallery/wallpaper/index.html","excerpt":"","text":""}],"posts":[{"title":"ML算法：XGBoost","slug":"XGBOOST","date":"2023-11-28T12:48:34.000Z","updated":"2023-09-24T03:47:34.736Z","comments":true,"path":"posts/f54e13d4.html","link":"","permalink":"http://sn1987a-1.github.io/posts/f54e13d4.html","excerpt":"","text":"XGBoost实验目的本实验要求学习XGBoost模型的原理，并实现该模型，以及在数据集上完成训练和测试。 实验原理XGBoost的基本原理就是以决策树作为基学习器的加法模型，每棵树根据前t个模型的输出计算节点的权重，最终的输出为： y_i^{(t)}=∑^t_{k=1}f_k (x_i )=y _i^{(t-1)}+f_t (x_i )本实验的问题模型为回归问题，即$𝑙𝑜𝑠𝑠(𝑦_𝑖,𝑦 _𝑖^{(𝑡)} )=(𝑦_𝑖−\\hat y _𝑖^{(𝑡)} )^2$。 对于损失loss，记 $g_i$ 为一阶导数，$h_i$ 为二阶导数，即$g_i=\\frac{\\partial\\ loss(y_i,y _i^{(t-1)})}{\\partial\\ y _i^{(t-1) } }=2(\\hat y^{t-1}-y)$, $h_i=\\frac{\\partial^2 loss(y_i,y _i^{(t-1)} )}{\\partial \\ (y _i^{(t-1)} )^2 }=2\\\\ $。 在训练第t棵决策树时,目标函数为$Obj^{(t)}=∑_{i=1}^n[g_i f_t (x_i )+\\frac12 h_i f_t^2 (x_i)]+penalty(f_t )$ 对于一棵决策树，其惩罚为： penalty(f)=\\gamma\\cdot T+\\frac12\\lambda\\cdot\\|w\\|^2将分配到第 $j$ 个叶子节点的样本用 $I_j$ 表示，即 $I_j=\\{i|q(x_i )=j\\} (1≤j≤T)$，在树结构确定时可以进行如下优化： \\begin{split} 𝑂𝑏𝑗^{(𝑡)} &=∑_{𝑗=1}^𝑇[(∑_{i∈𝐼_𝑗}𝑔_𝑖 )w_j+\\frac12(\\sum_{i\\in I_j}h_i+\\lambda)w^2_j]+\\gamma T \\end{split}\\\\ 记 G_j=∑_{i∈𝐼_𝑗}𝑔_𝑖 , H_j=∑_{i∈𝐼_𝑗}h_𝑖 \\\\ Obj^{(t)}=\\sum_{j=1}^T[G_jw_j+\\frac12(H_j+\\lambda)w_j^2]+\\gamma T求解$w$ :$w_j^*=-\\frac{G_j}{H_j+\\lambda}$，此时决策树的得分：$Obj^{(t)}=-\\frac12\\sum^{T}_{j=1}\\frac{G_j^2}{H_j+\\lambda}+\\gamma T$ 实验步骤读取数据和数据处理数据文件中的各项数据均不含有NULL项，无需进行特殊处理。 df = pd.read_csv('train.data') df.shape[1] df = pd.read_csv('train.data',names=[i for i in range(df.shape[1])]) #重新读取数据，防止将第一行的数据识别为索引 Data=np.array(df) a=int(0.3*Data.shape[0]) Data=np.c_[Data,np.zeros(Data.shape[0]).T] num=np.random.permutation(Data.shape[0]) Data=Data[num] test_data=Data[0:a-1,:] train_data=Data[a:,:] #按照7：3的比例划分训练集和测试集 在数据集的基础上添加一列0，用来存储每轮训练结束后的预测值，即data=[:,-2]代表真实值,data[:,-1]代表预测值。 回归树模型超参数: maxdepth=4,minscore=0,minindex=3,lambda=800,gamma=1e-7 class RegressionTree: def __init__(self) : ...初始化 def Leaf(self,data):#叶节点 G=(2*np.sum(data[:,-1]-data[:,-2])) H=2*data.shape[0] return -G/(H+self.lam) def Obj(self,data):#计算得分 G=(2*np.sum(data[:,-1]-data[:,-2])) H=2*data.shape[0] obj=-G**2*0.5/(H+self.lam)+self.gamma return obj def split(self,data,num,val):#根据num和val找到最佳划分 lchild=data[np.nonzero(data[:,num]&lt;=val)[0],:] rchild=data[np.nonzero(data[:,num]&gt;val)[0],:] return lchild,rchild def ChooseSplit(self,data,depth): \"\"\" 对样本集进行划分，找到最佳划分 \"\"\" if data.shape[0]&lt;self.minindex or depth&gt;self.maxdepth: return -1,self.Leaf(data) if len(set(data[:,-2].T.tolist()))==1: return -1,self.Leaf(data) pobj=self.Obj(data) maxscore=-1 maxnum=0 maxval=0 n,m=data.shape for i in range(m-2): n=data[:,i].T.tolist() for j in set(n): lchild,rchild=self.split(data,i,j) if len(lchild)==0 or len(rchild)==0: continue score=-self.Obj(lchild)+self.Obj(rchild)+pobj if score&gt;maxscore: maxscore=score maxnum=i maxval=j if maxscore&lt;=self.minscore: return -1,self.Leaf(data) return maxnum,maxval def CreateTree(self,data,depth): num,val=self.ChooseSplit(data,depth) if num==-1: return val lchild,rchild=self.split(data,num,val) Tree={} \"\"\" 如果不是叶节点，则以字典形式建树，否则节点只存储叶子的值 \"\"\" Tree['num']=num Tree['val']=val Tree['lchild']=self.CreateTree(lchild,depth+1) Tree['rchild']=self.CreateTree(rchild,depth+1) return Tree 其中，决策树的非叶子节点有属性： num，val：在该结点处选取第num个属性值进行划分，最佳划分点为val lchild，rchild：分别指向第num个属性小于等于val和大于val的子树 对于单棵决策树的停止策略： maxdepth：每次划分记录树的高度，深度为maxdepth时直接当作叶子节点 minindex：每次划分时，如果当前节点的样本数小于minindex，则直接作为叶子节点 minscore：若每次划分的最佳划分的得分小于等于minscore时，直接作为叶子节点 优化ChooseSpilt函数。为了减少每次对得分Obj的计算时存在的重复计算，将函数的核心部分做以下修改：（将数据按照当前属性进行排序，每次选取的属性值依次增大，因此左右两孩子的g，h线性增/减，对于左孩子：$\\Delta g=\\sum _{data[j,i]=val}(data1[j,-1]-data1[j,-2])2.0$,$\\Delta h=2\\sum_{data[j,i]=val}$） gl=0 hl=0 gr=(2*np.sum(data[:,-1]-data[:,-2])) hr=2*n data1=data[data[:,i].argsort()] for j in range(n-1): gl+=(data1[j,-1]-data1[j,-2])*2.0 gr-=(data1[j,-1]-data1[j,-2])*2.0 hl+=2 hr-=2 if data1[j,i]==data1[j+1,i]: continue obj1=-gl**2*0.5/(hl+self.lam)+self.gamma obj2=-gr**2*0.5/(hr+self.lam)+self.gamma score=pobj-obj1-obj2 if score&gt;maxscore: maxscore=score maxnum=i maxval=data1[j,i] XGBoost模型超参数：treenum=30 class XGBoost: def __init__(self,data,treenum=30): ... def isTree(self,tree):#判断节点的类型，非叶子节点为字典类型，叶子节点为float类型 return type(tree).__name__=='dict' def find(self,data,i,tree):#对于单个样本，找到所在决策树的位置 if self.isTree(tree): if data[i,tree[\"num\"]]&lt;=tree['val']: return self.find(data,i,tree['lchild']) else: return self.find(data,i,tree['rchild']) else: return tree def fit(self): \"\"\" 训练函数，其中共训练了treenum棵树，调用RegressionTree，并计算损失和相关系数 \"\"\" loss=[] r2=[] va=(np.var(self.data[:,-2])) for i in range(self.treenum): print(i) tree=Rtree.CreateTree(self.data,1) for j in range(self.length): self.data[j,-1]+=self.find(self.data,j,tree) r=np.sqrt(np.sum((self.data[:,-2]-self.data[:,-1])**2/self.length)) r2.append(1-r**2/va) lo=np.sum((self.data[:,-2]-self.data[:,-1])**2) loss.append(lo) self.forest.append(tree) return loss,r2 def predict(self,data): m,n=data.shape for i in range(self.treenum): for j in range(m): test_data[j,-1]+=self.find(data,j,self.forest[i]) 训练模型并实现损失函数可视化Rtree=RegressionTree() boost=XGBoost(train_data) loss,r2=boost.fit() boost.predict(test_data) x = np.arange(1,len(loss)+1) plt.plot(x,loss) plt.xlabel(u\"times\") plt.ylabel(u\"loss-value\") plt.show() 模型预测并评估结果结果评估指标： $RMSE=\\sqrt{\\frac1n\\sum_{i=1}^n{(y-\\hat y)^2}}$ $R2=1-\\frac{RMSE}{var(y)}$ 误差分布直方图 r=np.sqrt(np.sum((test_data[:,-2]-test_data[:,-1])**2/test_data.shape[0])) r2=(1-r**2/np.var(test_data[:,-2])) res=test_data[:,-1]-test_data[:,-2] res=np.sort(res) plt.hist(res, bins=30, rwidth=0.9, density=True) plt.xlabel(u\"data\") plt.ylabel(u\"num\") plt.show() print(test_data[:,-1]-test_data[:,-2]) print(r,r2) 实验结果与分析（调参过程略）","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://sn1987a-1.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"ML算法：SVM","slug":"SVM","date":"2023-11-10T12:48:34.000Z","updated":"2023-09-24T03:45:05.647Z","comments":true,"path":"posts/7ab554ae.html","link":"","permalink":"http://sn1987a-1.github.io/posts/7ab554ae.html","excerpt":"","text":"SVM实验目标学习支持向量机的原理，用两种不同的算法寻找支持向量机的解，并完成比较。 实验原理对于给定样本集，SVM的任务就是基于样本集在样本空间中确定一个划分超平面，将不同类别的样本分开，即找到w,b使得$y(w^T+b)\\ge1$成立，并实现最大化间隔，即最大化$||w||^{-1}$。为求解w的最优解，，由于实验中的数据并不完全是线性可分的，因此采用硬间隔的方法求解存在困难，本次实验分别采用梯度下降法和SMO（序列最小优化算法）来求解。 SVM的任务： min_W||w||^2/2\\\\ s.t. y_i(w^T)\\phi(x_i)+b)\\ge 1,i=1,2,...m 梯度下降法 SVM中的梯度下降方法也类似于逻辑回归中的梯度下降原理，根据迭代的值计算损失和梯度更新参数，每次迭代过程中，计算当前的$y*(w^T+b)$的值，将值小于一的样本进行累加计算梯度，根据梯度和学习率更新w和b。 SMO SMO算法是John Platt在《Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines》一文中提出的算法，对于解决稀疏数据集上的问题有着很高的效率。已知SVM的对偶问题为： argmax\\sum _\\alpha ^N \\alpha _i-1/2*\\sum_{i=1}^N\\sum_{j=1}^Ny_iy_j\\alpha_i\\alpha_jx_i^Tx_j \\\\ s.t.\\alpha_i\\ge0,\\sum_{i=1}^T\\alpha_iy_i=0其中，我们要对$（\\alpha_1,\\alpha_2,…,\\alpha_N)$进行优化，但数据集较大时，直接对N个参数进行优化的效率将很低，因此采用SMO算法求解，SMO的原理是将N个参数的优化问题转化为多个子问题，其中每个子问题只对两个参数进行优化，每次计算并选取一对最优的$(\\alpha_i,\\alpha_j)$更新对应的$\\alpha$值。 实验步骤梯度下降法 损失函数$loss=1/2*w^tw+\\sum_{i=1}^mmax{0,1-y_i(wx_i-b)}$ mar=y*(np.dot(X,self.w)+self.b) lo=0.5*np.sum(np.square(self.w))+np.maximum(0, 1 - mar).sum() if lo&lt;tol : break 损失函数的梯度$\\Delta=\\lambda w-\\sum{i=1}^mI|wx_i+b&lt;1|*x_iy_i$，根据梯度更新w和b for i in range(len(y)): if y[i]*(X[i].dot(self.w)+self.b) &lt;= 1: self.w -= lr * (-y[i]*X[i].reshape((len(X[i]),1))) self.b -= lr * -y[i] SMO 预先存储部分数据，提高运算效率 self.m=X.shape[0] self.alpha=np.zeros((self.m,1))#每次迭代更新 self.err=-self.y.flatten()#每次迭代更新 #以下是为了方便计算loss的值，不需要计算loss值时无需计算，更节省时间和内存 self.kappa_x=self.kappa(self.X,self.X) self.mulyx=np.outer(self.y,self.y)*self.kappa_x self.outer_a=np.zeros((self.m,self.m))#每次迭代更新 损失函数$\\sum _\\alpha ^N \\alpha _i-1/2*\\sum_{i=1}^N\\sum_{j=1}^Ny_iy_j\\alpha_i\\alpha_jx_i^Tx_j$ 0.5*(np.sum(self.mulyx*self.outer_a)-np.sum(self.alpha)) 选取合适的$(\\alpha _i,\\alpha_j)$ 统计误差不为0的索引值，有不为零的误差时统计误差 没有为零误差时，随机选取$\\alpha$ if arrlen&gt; 1: t=np.argmax(np.abs(self.err-ei)) if t!=i and self.step(t,i)==1: return 1 arr=np.where((self.alpha!=0 )&amp; (self.alpha!=self.c))[0] ra=np.roll(arr,np.random.choice(np.arange(self.m))) for j in ra: if j!=i and self.step(j,i)==1: return 1 ra=np.roll(np.arange(self.m), np.random.choice(np.arange(self.m))) for j in ra: if j!=i and self.step(j,i)==1: return 1 每次迭代更新数据 if y1 !=y2:#取L，H t1=max(0,a2-a1) t2=min(0,a2-a1)+self.c else: t1=max(self.c,a1+a2)-self.c t2=min(self.c,a1+a2) if t1==t2: return 0 t3=k11+k22-2*k12 if t3&gt;0:#求解\\alpha新值 al2 = a2+y2*(e1-e2)/t3 if al2&lt;t1: al2=t1 elif al2&gt;t2: al2=t2 else: #意外情况,很少出现 self.alpha[i2]=t1 loss1=self.calloss() self.alpha[i2]=t2 loss2=self.calloss() self.alpha[i2]=a2 if loss1-loss2&gt;self.eps: al2=t2 elif loss2-loss1&gt;self.eps: al2=t1 else: al2=a2 if al2&lt;=0: al2=0.0 #截断处理 al2=max(al2,0.0) al2=min(al2,self.c) if np.abs(al2-a2)&lt;self.eps*(al2 + a2 + self.eps): return 0 al1=a1+(a2-al2)*y1*y2 b1 = e1 + y1*(al1 - a1)*k11 + y2*(al2 - a2)*k12 + self.b b2 = e2 + y1*(al1 - a1)*k12 + y2*(al2 - a2)*k22 + self.b #根据以上的al1，al2，b1，b2更新参数的值：b,alpha,err 迭代 change：上一轮迭代中发生改变的数目 entire：是否对全部的参数进行检查 ep:记录迭代次数，迭代次数到最大时退出循环 while change&gt;0 or entire: change=0 if entire : for i in range(self.m): if self.examine(i): change+=1 else: ra=np.where((self.alpha!=0) &amp; (self.alpha!=self.c))[0] for i in ra: if self.examine(i): change+=1 if(ep&gt;self.max_iters): break if entire==1: entire=0 elif change==0: entire=1 数据处理，预测和分析本次实验对训练集和测试集按照8：2进行划分： mu = np.mean(X_norm,0) sigma = np.std(X_norm,0) for i in range(X.shape[1]): X_norm[:,i]=(X_norm[:,i]-mu[i])/sigma[i] y=np.array(y) num=np.random.permutation(len(y)) X_norm=X_norm[num] y=y[num] a=int(0.2*len(y)) X_test=X_norm[0:a-1,:] X_train=X_norm[a:,:] y_test=y[0:a-1] y_train=y[a:] 预测函数： m,n=X.shape ##SMO: p=np.dot(self.kappa(X, self.X),self.alpha*self.y) - self.b ##GD: p=np.dot(X,self.w)+self.b for i in range(m): ans=np.sign(p[i]) res.append(ans) 损失曲线： loss=model2.fit(X_train,y_train) x = np.arange(1,len(loss)+1) plt.plot(x,loss) plt.xlabel(u\"times\") plt.ylabel(u\"loss-value\") plt.show() 数据分析 pred2 = model.predict(X_test) m = len(y_test) for i in range(m): if(y_test[i]&gt;0 and pred2[i]&gt;0): sum+=1 if(y_test[i]&lt;0 and pred2[i]&lt;0): sum+=1 print(sum/m) #SVM预测的准确率 for i in range(m): if pred1[i]==pred2[i]: i+=1 print(i/m) #SVM1，SVM2的预测相似率 实验结论和分析梯度下降法参数解释： X，训练集X y，训练集 lr，学习率，默认为0.001 max_iters，最大迭代次数，默认为1000 tol，最小误差， 0.0001 训练一次的损失曲线如下所示（数据规模为10000，维度为20，训练时间为41.2s），初始的loss值较大是训练时预设了w的值为随机生成np.random.randn(col,1). 准确率：96.1% 可以看出梯度下降的收敛效果较好，在训练次数较低时损失函数显著降低，得到的结果准确率也较高。 而当学习率变大（改为lr=0.1)时，损失函数会发生震荡，导致预测的准确率降低 SMO参数解释： dim：数据的维度 c：松弛变量，默认为1.0 eps：容错率，默认为0.01 max_iters:最大迭代次数，默认为1000 kappa函数：选取的核函数类型，默认为linear 训练一次的损失曲线（数据规模为2000，20维，训练次数1000，训练时间10s） 梯度下降法和SMO的对比总体来说，梯度下降法和SMO的准确率均在90%以上，收敛的速度都很快，对结果预测的相似度为97%，两种模型的训练效果均较好，梯度下降的准确率相对更高，训练过程相对更直观；SMO的优势在于每次只对最小的问题进行优化，问题规模小，占用的内存少，对硬件的要求低，对于不同的参数，或者较大或较小的数据集都有较好的结果。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://sn1987a-1.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"编译原理-LLVM IR语法","slug":"编译原理2","date":"2023-10-17T12:48:34.000Z","updated":"2023-09-24T05:28:23.642Z","comments":true,"path":"posts/615503d3.html","link":"","permalink":"http://sn1987a-1.github.io/posts/615503d3.html","excerpt":"","text":"问题1: getelementptr请给出 IR.md 中提到的两种 getelementptr 用法的区别,并稍加解释: %2 = getelementptr [10 x i32], [10 x i32]* %1, i32 0, i32 %0 %2 = getelementptr i32, i32* %1, i32 %0 两种GEP都是取数组中的特定元素的地址指针，区别在于（1）计算基础类型为数组指针，（2）中的计算基础类型为元素指针， (1)中的用法是借助长度为10，数据类型为i32的数组指针取其中某个元素的地址指针，其中数据索引的偏移有两个，因为数据类型是[10 x i32],第一个偏移对应的内存偏移量为偏移值（0） x 10 x 4，第二个偏移对应的内存偏移量为偏移值（%0） x 4，偏移量与原地址相加计算得到的数据存入%2中，类型为i32；（2）中的用法是通过元素指针和偏移值得到某个元素的地址指针，数据类型为i32，因此只有一个偏移值，对应的内存偏移量为偏移值（%0） x 4，偏移量与原地址相加计算得到的数据存入%2中，类型为i32。 问题2: cpp 与 .ll 的对应 assign 不含有转移指令，因此整个函数主体部分与.ll文件main函数部分对应 fun std::vector&lt;Type *&gt; Ints(1, Int32Type); auto calleeFunType = FunctionType::get(Int32Type, Ints); auto calleeFun = Function::create(calleeFunType, \"callee\", module); auto bb = BasicBlock::create(module, \"entry\", calleeFun); builder-&gt;set_insert_point(bb); std::vector&lt;Value *&gt; args; for (auto arg = calleeFun-&gt;arg_begin(); arg != calleeFun-&gt;arg_end(); arg++) { args.push_back(*arg); } auto temp = builder-&gt;create_imul(CONST_INT(2),args[0]); builder-&gt;create_ret(temp); /*对应： define dso_local i32 @callee (i32 %0) #0 { %2 = mul i32 2,%0 ret i32 %2 } */ auto mainFun = Function::create(FunctionType::get(Int32Type, {}), \"main\", module); bb = BasicBlock::create(module, \"entry\", mainFun); builder-&gt;set_insert_point(bb); auto call = builder-&gt;create_call(calleeFun, {CONST_INT(110)}); /*对应： define dso_local i32 @main () #0{ %1 = call i32 @callee(i32 110) */ builder-&gt;create_ret(call); /*对应： ret i32 %1 */ if auto mainFun = Function::create(FunctionType::get(Int32Type, {}), \"main\", module); auto bb = BasicBlock::create(module, \"entry\", mainFun); builder-&gt;set_insert_point(bb); auto aAlloca = builder-&gt;create_alloca(FloatTypenum); builder-&gt;create_store(CONST_FP(5.555),aAlloca); auto aload = builder-&gt;create_load(aAlloca); auto fcmp = builder-&gt;create_fcmp_gt(aload,CONST_FP(1.0)); auto trueBB = BasicBlock::create(module, \"trueBB\", mainFun); auto falseBB = BasicBlock::create(module, \"falseBB\", mainFun); auto br = builder-&gt;create_cond_br(fcmp, trueBB, falseBB); /*对应： %1 = alloca float store float 0x40163851E0000000, float* %1 %2 = load float, float* %1 %3 = fcmp ogt float %2,1.000000e+00 br i1 %3, label %4, label %5 */ builder-&gt;set_insert_point(trueBB); builder-&gt;create_ret(CONST_INT(233)); /*对应： 4: ret i32 233 */ builder-&gt;set_insert_point(falseBB); builder-&gt;create_ret(CONST_INT(0)); /*对应： 5: ret i32 0 */ while auto aAlloca = builder-&gt;create_alloca(Int32Type); auto iAlloca = builder-&gt;create_alloca(Int32Type); builder-&gt;create_store(CONST_INT(10),aAlloca); builder-&gt;create_store(CONST_INT(0),iAlloca); builder-&gt;create_br(loopBB); /*对应： %1 = alloca i32 store i32 10,i32* %1 %2 = alloca i32 store i32 0,i32* %2 br label %3 */ builder-&gt;set_insert_point(loopBB); auto iLoad = builder-&gt;create_load(iAlloca); auto icmp = builder-&gt;create_icmp_lt(iLoad,CONST_INT(10)); auto br = builder-&gt;create_cond_br(icmp, trueBB, falseBB); /*对应： 3: %4 = load i32, i32* %2 %5 = icmp slt i32 %4,10 br i1 %5,label %6,label %11 */ builder-&gt;set_insert_point(trueBB); auto temp = builder-&gt;create_iadd(iLoad,CONST_INT(1)); builder-&gt;create_store(temp,iAlloca); iLoad = builder-&gt;create_load(iAlloca); auto aLoad = builder-&gt;create_load(aAlloca); auto temp1 = builder-&gt;create_iadd(aLoad,iLoad); builder-&gt;create_store(temp1,aAlloca); builder-&gt;create_br(loopBB); /*对应： 6: %7 = add i32 %4,1 store i32 %7, i32* %2 %8 = load i32, i32* %2 %9 = load i32, i32* %1 %10 = add i32 %8,%9 store i32 %10, i32* %1 br label %3 */ builder-&gt;set_insert_point(falseBB); aLoad = builder-&gt;create_load(aAlloca); builder-&gt;create_ret(aLoad); /* 对应： 11: %12 = load i32, i32* %1 ret i32 %12 */ 问题3: Visitor Pattern分析 calc 程序在输入为 4 * (8 + 4 - 1) / 2 时的行为： 请画出该表达式对应的抽象语法树（使用 calc_ast.hpp 中的 CalcAST* 类型和在该类型中存储的值来表示），并给节点使用数字编号。 请指出示例代码在用访问者模式遍历该语法树时的遍历顺序。 序列请按如下格式指明（序号为问题 3.1 中的编号）： 3-&gt;2-&gt;5-&gt;1 抽象语法树： 遍历顺序： 1-&gt;2-&gt;3-&gt;4-&gt;6-&gt;8-&gt;7-&gt;9-&gt;11-&gt;14-&gt;16-&gt;12-&gt;15-&gt;10-&gt;13-&gt;5 实验要求本次实验的核心任务是使用访问者模式来实现cminus-f 语言的LLVM IR 的自动生成。 实验难点 数据类型不匹配时及时进行数据转换，如以下情况 assign语句 比较/计算等二元运算的参数类型不一致 计算数组下标的结果并非int型 函数参数类型和调用时的实参类型不匹配 函数返回值的表达式和类型不匹配 其中int,float之间的转换需要的函数为create_sitofp,create_fptosi,int1和int32之间的转换需要的函数为create_zext,create_icmp_ne(*,CONST_INT(0))。 区别元素值和元素地址，二者存储的数据类型均为Value *类型，本实验中，设置两个全局变量cur_val,cur_expr分别存储地址和值，其中地址仅在指针/数组运算以及赋值语句被用到。 区分指针类型和数组类型，根据lab2问题1，获取元素的地址有两种方法，分别是作为指针根据基元素的值进行运算，和作为数组类型的指针根据基元素的地址进行计算，在调用时要加以区分。 函数形参和实参的处理 实验设计全局变量 number 在对基本块进行命名时，如果程序中存在多个类型相同的基本块，则会发生冲突，因此设置一个int类型的全局变量，每遇到需要显示命名的基本块，则将当前number的值转化为字符串加入基本块的命名中(std::to_string(number++))。 cur_val &amp; cur_expr cur_val记录当前数据对应的地址，如运行赋值语句时，右值计算的数值将存储到左值中对应的地址中，以及根据基地址计算数组某个元素对应的位置； cur_expr记录当前数据对应的值的拷贝，用于各类表达式的计算和赋值，调用create_load(cur_val)即可得到当前数据地址的对应的值。 优化 SelectionStmt部分，在trueBB，falseBB对应的语句执行结束后，如果在执行完的基本块中没有终止语句，则不会产生向下一个基本块的跳转。 int exist=0; if(builder-&gt;get_insert_block()-&gt;get_terminator()==nullptr) { retBB=BasicBlock::create(module.get(),\"retBB\"+std::to_string(number),cur_fun); builder-&gt;create_br(retBB); exist=1; } if(builder-&gt;get_insert_block()-&gt;get_terminator()==nullptr) { if(exist==0) { retBB=BasicBlock::create(module.get(),\"retBB\"+std::to_string(number),cur_fun); builder-&gt;create_br(retBB); exist=1; } else builder-&gt;create_br(retBB); } iteration同理 数组负下标检测,调用neg_idx_expect函数，仅对负下标进行检测，不会对数组的上界进行检查（即越界访问） auto b=builder-&gt;create_icmp_lt(cur_expr,CONST_INT(0)); auto trueBB=...; autofalseBB=...; auto br=builder-&gt;create_cond_br(b,trueBB,falseBB); builder-&gt;set_insert_point(trueBB); auto err=scope.find(\"neg_idx_except\"); builder-&gt;create_call(err,{}); builder-&gt;create_br(falseBB); builder-&gt;set_insert_point(falseBB); 函数声明部分，对函数参数的处理仅在FunDeclaration部分完成，未调用ASTParam部分。 实验总结 实验框架的基本思路是访问者模式实现LR的自动生成，和lab2中问题三的思路类似。 加深了对数组和指针类型的理解，以及对基本块，跳转语句等的理解 对C++的语法掌握更多","categories":[{"name":"编译原理","slug":"编译原理","permalink":"http://sn1987a-1.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"LLVM IR语法","slug":"编译原理3","date":"2023-10-17T12:48:34.000Z","updated":"2023-09-24T05:27:12.380Z","comments":true,"path":"posts/b38fcafd.html","link":"","permalink":"http://sn1987a-1.github.io/posts/b38fcafd.html","excerpt":"","text":"","categories":[{"name":"编译原理","slug":"编译原理","permalink":"http://sn1987a-1.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"ML算法：逻辑回归","slug":"逻辑回归","date":"2023-10-17T12:48:34.000Z","updated":"2023-09-24T03:48:50.515Z","comments":true,"path":"posts/f1383170.html","link":"","permalink":"http://sn1987a-1.github.io/posts/f1383170.html","excerpt":"","text":"逻辑回归实验内容及步骤本实验主要利用逻辑回归(logistics regression)对kaggle数据集进行分析预测。 数据处理 #NULL项舍弃 df=df.dropna() ENcode，将非数字型的属性值编码为0~1的数字 df.Gender=df.Gender.map({'Male':1,'Female':0}) df.Married=df.Married.map({'Yes':1,'No':0}) df.Dependents=df.Dependents.map({'1':0,'0':0.3,'2':0.6,'3+':1}) df.Education=df.Education.map({'Graduate':1,'Not Graduate':0}) df.Self_Employed=df.Self_Employed.map({'Yes':1,'No':0}) df.Property_Area=df.Property_Area.map({'Rural':0,'Urban':0.5,'Semiurban':1}) df.Loan_Status=df.Loan_Status.map({'Y':1,'N':0}) 数据归一化，采用$X_{norm}=(X-\\mu)/\\sigma$，其中$\\mu$为平均值，$\\sigma$为标准差 import numpy as np from sklearn.model_selection import train_test_split X = df.drop([\"Loan_Status\"], axis=1) y = df[\"Loan_Status\"] X_norm=np.array(X) mu = np.mean(X_norm,0) sigma = np.std(X_norm,0) for i in range(X.shape[1]): X_norm[:,i]=(X_norm[:,i]-mu[i])/sigma[i] 划分训练集和测试集，此处采用训练集：测试机=8：2的方式进行划分，利用permutation()函数进行处理 num=np.random.permutation(len(y)) X_norm=X_norm[num] y=y[num] a=int(0.2*len(y)) X_test=X_norm[0:a-1,:] X_train=X_norm[a:,:] y_test=y[0:a-1] y_train=y[a:] 训练部分预处理 col=X.shape[1]+1 m=len(y) X=np.array(X) X = np.hstack((np.ones((m,1)),X)) y=np.array(y).reshape(-1,1) theta=np.zeros((col,1)) n=len(theta) temp=np.matrix(np.zeros((n,int(max_iter)))) 损失函数：利用交叉熵损失函数计算 loss=-np.dot(np.transpose(np.log(self.sigmoid(X,theta))),y)/m-np.dot(np.transpose(np.log(1-self.sigmoid(X,theta))),1-y)/m 梯度下降 grad=np.dot(np.transpose(X),self.sigmoid(X,theta)-y) 正则化，其中L1相当于添加1-范数项，L2相当于在损失函数中添加2-范数项 if self.penalty==\"l1\": loss+=self.gamma*np.sum(np.abs(theta))/m grad+=self.gamma*np.sign(theta) else: loss+=self.gamma*np.sum(np.square(theta))/m grad+=self.gamma*theta 训练部分函数主体 for i in range(int(max_iter)): #计算loss和gard temp[:,i]=theta-(lr/m)*grad theta=temp[:,i] m = len(y) j_history=np.append(j_history,np.sum(np.square(loss)) if np.sum(np.square(loss))&lt;tol: break sigmoid函数 return 1.0/(1+np.exp(-np.dot(w,x))) 预测函数 def predict(self, X,y,theta): m=len(y) X=np.array(X) X=np.hstack((np.ones((m,1)),X)) p=np.dot(X,theta) p=p.reshape(-1,1) y=np.array(y).reshape(-1,1) sum=0 for i in range(m): if y[i]==1 and p[i]&gt;0: sum+=1 elif y[i]==0 and p[i]&lt;0: sum+=1 return sum/m 实验结果及分析采用实验默认参数进行训练：lr=0.01, tol=1e-7, max_iter=3e3,penalty=”l2”,gamma=0,fit_intercept=True Acc=83.2% 参数比较 首先对不同的学习率进行比较，如下为不同的学习率下的损失函数 lr=0.001,此时到达max_iter时损失函数仍在快速递减、 相比之下lr=0.01的学习率避免了图像的抖动，也避免了训练过慢导致训练时间长。 不同的正则化参数： 观察图像的纵坐标，可以看出选择l2正则化的收敛效果最好，因此采取l2正则化。 最佳准确率的情况： （此时的参数：lr=0.01, tol=1e-7, max_iter=3e3,penalty=”l2”,gamma=1,fit_intercept=True） 准确率达到了87.37%，其中测试集和训练集的比例为2：8","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://sn1987a-1.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"Gin框架","slug":"Gin框架","date":"2023-09-23T12:48:34.000Z","updated":"2023-09-23T13:05:25.832Z","comments":true,"path":"posts/6d104c29.html","link":"","permalink":"http://sn1987a-1.github.io/posts/6d104c29.html","excerpt":"","text":"GoWeb官方包net/http提供了基础的路由函数组合和功能函数，无需API package main import (...) func echo(wr http.ResponseWriter, r *http.Request) { msg, err := ioutil.ReadAll(r.Body) if err != nil { wr.Write([]byte(\"echo error\")) return } writeLen, err := wr.Write(msg) if err != nil || writeLen != len(msg) { log.Println(err, \"write len:\", writeLen) } } func main() { http.HandleFunc(\"/\", echo) err := http.ListenAndServe(\":8080\", nil) if err != nil { log.Fatal(err) } } 框架类型 Router MVC GinGin Gin路由func main() { // 创建一个 Gin 路由 r := gin.Default() // 设置一个路由处理器，处理根路径 \"/\" r.GET(\"/\", func(c *gin.Context) { // 发送 \"Hello, World!\" 作为响应 c.String(http.StatusOK, \"Hello, World!\") }) // 在端口 8000 上启动 Web 服务器 r.Run(\":8000\") } 类似地 r.POST(\"/xxxpost\",getting) r.PUT(\"/xxxput\") 支持Restful风格API，（表现层状态转化），是一种互联网应用程序的API设计理念：URL定位资源，用HTTP描述操作 1.获取文章 /blog/getXxx Get blog/Xxx 2.添加 /blog/addXxx POST blog/Xxx 3.修改 /blog/updateXxx PUT blog/Xxx 4.删除 /blog/delXxxx DELETE blog/Xxx API参数：可以通过context地Param方法获取API参数 r.GET(\"/user/:name/*action\", func(c *gin.Context) { name := c.Param(\"name\") action := c.Param(\"action\") action = strings.Trim(action, \"/\") c.String(http.StatusOK, name+\" is \"+action) }) URL参数：可以通过DefaultQuery()（参数不存在，返回默认值）或Query()（参数不存在，返回空串）方法获取 name := c.DefaultQuery(\"xx\",\"默认值\") 表单参数表单参数是post请求，通过PostForm获取 types := c.DefaultPostForm(\"type\", \"post\") username := c.PostForm(\"username\") password := c.PostForm(\"userpassword\") &lt;form action=\"http://localhost:8080/form\" method=\"post\" action=\"application/x-www-form-urlencoded\"&gt; 用户名：&lt;input type=\"text\" name=\"username\" placeholder=\"请输入你的用户名\"&gt; &lt;br&gt; 密&amp;nbsp;&amp;nbsp;&amp;nbsp;码：&lt;input type=\"password\" name=\"userpassword\" placeholder=\"请输入你的密码\"&gt; &lt;br&gt; &lt;input type=\"submit\" value=\"提交\"&gt; &lt;/form&gt; 上传文件 file, err := c.FormFile(\"file\") if err != nil { c.String(500, \"上传图片出错\") } c.SaveUploadedFile(file, file.Filename) c.String(http.StatusOK, file.Filename) 对于上传的文件，可以限制文件类型，文件大小 也可以上传多个文件，获取所有的文件，再遍历文件，逐个处理（html的multiple） routes group 管理相同的URL v1 := r.Group(\"/v1\") // {} 是书写规范 { v1.GET(\"/login\", login) v1.GET(\"/submit\", submit) } v2... 路由原理：httprouter会将所有路由规则构造成前缀树 URI包含URL和URN url用来标识资源的位置 urn用来标识资源的名称，不含位置信息 uri数据指的是URI的字符串表示形式 gin数据解析和绑定json数据 type Login struct { // binding:\"required\"修饰的字段，若接收为空值，则报错，是必须字段 User string `form:\"username\" json:\"user\" uri:\"user\" xml:\"user\" binding:\"required\"` Pssword string `form:\"password\" json:\"password\" uri:\"password\" xml:\"password\" binding:\"required\"` } var json Login // 将request的body中的数据，自动按照json格式解析到结构体 if err := c.ShouldBindJSON(&amp;json); err != nil { // 返回错误信息 // gin.H封装了生成json数据的工具 c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) return } // 判断用户名密码是否正确 if json.User != \"root\" || json.Pssword != \"admin\" { c.JSON(http.StatusBadRequest, gin.H{\"status\": \"304\"}) return } c.JSON(http.StatusOK, gin.H{\"status\": \"200\"}) 表单数据，类似于json数据，只需修改解析的函数，使用bind()默认解析到form的格式 var form Login // Bind()默认解析并绑定form格式 // 根据请求头中content-type自动推断 if err := c.Bind(&amp;form); err != nil { URI数据 URI数据的get函数参数\"/:user/:password\"以便标识 if err := c.ShouldBindUri(&amp;login); err != nil {... gin渲染JSON，XML，YAML，结构体 r.get(\"/someXML\")(替换成someStruct/someYAML/someJSON)，用c.XML...接收（struct格式需要处理msg格式，用c.JSON接收） HTML模板渲染 在r.GET之前调用r.LoadHTMLGlob(\"tem/**/*\")(具体根据目录来定) HTML首尾分离 首： {{define \"public/header\"}} &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt; &lt;title&gt;{{.title}}&lt;/title&gt; &lt;/head&gt; &lt;body&gt; {{end}} 尾： {{define \"public/footer\"}} &lt;/body&gt; &lt;/html&gt; {{ end }} index文件： {{ define \"user/index.html\" }} {{template \"public/header\" .}} fgkjdskjdsh{{.address}} {{template \"public/footer\" .}} {{ end }} 重定向 c.Redirect(http.StatusMovedPermanently, \"http...\") 同步和异步处理 goroutine可以进行异步处理 启动新的goroutine时，不应该使用原始上下文，而是使用只读副本 // 1.异步 r.GET(\"/long_async\", func(c *gin.Context) { // 需要搞一个副本 copyContext := c.Copy() // 异步处理 go func() { time.Sleep(3 * time.Second) log.Println(\"异步执行：\" + copyContext.Request.URL.Path) }() }) // 2.同步 r.GET(\"/long_sync\", func(c *gin.Context) { time.Sleep(3 * time.Second) log.Println(\"同步执行：\" + c.Request.URL.Path) }) gin中间件“默认使用两个中间件：Logger，Recovery”r:=gin.Default() 全局中间件：所有请求都经过该中间件 定义中间件： func MiddleWare() gin.HandlerFunc{ //设置变量到Context的key中，可以通过’Get‘获取 c.Set(\"request\",\"...\") //获取相关变量 status := c.Writer.Status() } 注册中间件： r.Use(MiddleWare()) r.GET(\"/ce\",func(c *gin.Context)){}... Next()方法：中间件执行完后续的一些事情，在定义中间件部分写入 func MiddleWare() gin.HandlerFunc { return func(c *gin.Context) { t := time.Now() c.Set(\"request\", \"中间件\") c.Next() status := c.Writer.Status() t2 := time.Since(t) fmt.Println(\"time:\", t2) } } 对比： 去掉c.Next()函数：输出的time（时间间隔）为0 加上c.Next()函数，输出的time不为0，为中间件开始执行到运行结束的时间 局部中间件 局部中间件注册的方法：（也可以类似于全局的声明） r.GET(\"/ce\",MiddleWare(),func(c *gin.Context){...}) 局部和全局的区别：局部可以针对忒党的路由或路由组生效，在注册前创建路由组： authgroup:=r.Group(\"/xxx\") authgroup.USE(MiddleWare) authgroup.GET(...) 会话控制HTTP：无状态协议，HTTP1.1引入cookie解决无状态的方案，Cookie由服务器创建，浏览器保存，每次发送请求给服务器时，发送Cookie cookie设置 r.GET(\"cookie\",func(c *gin.Context){ cookie,err=c.Cookie(\"key_cookie\") if err !=nil{ //说明cookie未设置 c.SetCookie()... } }) 借助中间件校验cookie，如果校验失败：返回错误信息并退出 c.JSON(http.StatusUnauthorized,gin.H{\"error\":\"err\"}) c.Abort()) 上述cookie的缺点 不安全，通过明文传输（只有https传输才可以保证安全性） 可以被禁用 增加宽带损耗 cookie有上限 只在同一域名下的页面之间共享 Sessions 主要功能： 简单的API，可以作为设置签名cookie的简便方法 内置的后端可以将session存储在cookie的或者文件系统中 Flash消息：持续读取session 切换Session的持久性和便捷方法 旋转身份验证，加密密钥 每个请求有多个session 自定义session后端的接口和基础结构，可以通过API减少并批量保存 sessions的特点 在服务器存储，存储在服务器的内存或者数据库中 没有明确的容量限制 可以持久存在 客户端无法直接访问你或修改，更安全 可以解决cookie的跨域问题，更灵活 通常用来存储敏感数据，如用户的身份验证信息 sessions相关函数用法： 保存session（更改） func SaveSession(w http.ResponseWriter, r *http.Request) { session, err := store.Get(r, \"session-name\") //Get永远会返回一个session，即便是空的session if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } session.Values[\"foo\"] = \"bar\" ... // 保存更改 session.Save(r, w) } 获取session func GetSession(w http.ResponseWriter, r *http.Request) { session, err := store.Get(r, \"session-name\") if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } foo := session.Values[\"foo\"] fmt.Println(foo) } 删除session: 将session的最大存储时间设置为小于零的数即为删除 session.Options.MaxAge = -1 session.Save(r, w) 参数验证结构体验证：GIN框架进行数据验证，无需解析数据，更简洁 var person Person if err := c.ShouldBind(&amp;person); err != nil { c.String(500, fmt.Sprint(err)) return } c.String(200, fmt.Sprintf(\"%#v\", person)) 如果需要添加自定义验证： 首先，要在struct中限制：form，binding等（用``） 自定义校验方法（如限制字段不为空，不等于admin） 注册校验方法 v:=binding.Validator.Engine().(*validator.Validate) v.RegisterValidation(\"name\",func_name) 再用ShouldBind进行校验 多语言翻译验证 当业务系统对验证信息有特殊需求时，例如：返回信息需要自定义，手机端返回的信息需要是中文而pc端返回的信息需要时英文，如何做到请求一个接口满足上述三种情况。 借助中间件实现。 func startPage(c *gin.Context) { //这部分应放到中间件中 locale := c.DefaultQuery(\"locale\", \"zh\") trans, _ := Uni.GetTranslator(locale) switch locale { ... break } //自定义错误内容 Validate.RegisterTranslation(\"required\", trans, func(ut ut.Translator) error { return ut.Add(\"required\", \"{0} must have a value!\", true) // see universal-translator for details }, func(ut ut.Translator, fe validator.FieldError) string { t, _ := ut.T(\"required\", fe.Field()) return t }) //这块应该放到公共验证方法中 user := User{} c.ShouldBind(&amp;user) fmt.Println(user) err := Validate.Struct(user) if err != nil { errs := err.(validator.ValidationErrors) sliceErrs := []string{} for _, e := range errs { sliceErrs = append(sliceErrs, e.Translate(trans)) } c.String(200, fmt.Sprintf(\"%#v\", sliceErrs)) } c.String(200, fmt.Sprintf(\"%#v\", \"user\")) } 验证码库：github.com/dchest/captcha 具体实现： 生成一个路由，在session里写入键值对k，v，将v加载到图片上，然后生成图片。在浏览器显示 前端将图片的内容发送给后端，后端根据session中的k取得v，比对校验 示例代码 package main import ( \"bytes\" \"github.com/dchest/captcha\" \"github.com/gin-contrib/sessions\" \"github.com/gin-contrib/sessions/cookie\" \"github.com/gin-gonic/gin\" \"net/http\" \"time\" ) // 中间件，处理session func Session(keyPairs string) gin.HandlerFunc { store := SessionConfig() return sessions.Sessions(keyPairs, store) } func SessionConfig() sessions.Store { sessionMaxAge := 3600 sessionSecret := \"topgoer\" var store sessions.Store store = cookie.NewStore([]byte(sessionSecret)) store.Options(sessions.Options{ MaxAge: sessionMaxAge, //seconds Path: \"/\", }) return store } func Captcha(c *gin.Context, length ...int) { l := captcha.DefaultLen w, h := 107, 36 if len(length) == 1 { l = length[0] } if len(length) == 2 { w = length[1] } if len(length) == 3 { h = length[2] } captchaId := captcha.NewLen(l) session := sessions.Default(c) session.Set(\"captcha\", captchaId) _ = session.Save() _ = Serve(c.Writer, c.Request, captchaId, \".png\", \"zh\", false, w, h) } func CaptchaVerify(c *gin.Context, code string) bool { session := sessions.Default(c) if captchaId := session.Get(\"captcha\"); captchaId != nil { session.Delete(\"captcha\") _ = session.Save() if captcha.VerifyString(captchaId.(string), code) { return true } else { return false } } else { return false } } func Serve(w http.ResponseWriter, r *http.Request, id, ext, lang string, download bool, width, height int) error { w.Header().Set(\"Cache-Control\", \"no-cache, no-store, must-revalidate\") w.Header().Set(\"Pragma\", \"no-cache\") w.Header().Set(\"Expires\", \"0\") var content bytes.Buffer switch ext { case \".png\": w.Header().Set(\"Content-Type\", \"image/png\") _ = captcha.WriteImage(&amp;content, id, width, height) case \".wav\": w.Header().Set(\"Content-Type\", \"audio/x-wav\") _ = captcha.WriteAudio(&amp;content, id, lang) default: return captcha.ErrNotFound } if download { w.Header().Set(\"Content-Type\", \"application/octet-stream\") } http.ServeContent(w, r, id+ext, time.Time{}, bytes.NewReader(content.Bytes())) return nil } func main() { router := gin.Default() router.LoadHTMLGlob(\"./*.html\") router.Use(Session(\"topgoer\")) router.GET(\"/captcha\", func(c *gin.Context) { Captcha(c, 4) }) router.GET(\"/\", func(c *gin.Context) { c.HTML(http.StatusOK, \"index.html\", nil) }) router.GET(\"/captcha/verify/:value\", func(c *gin.Context) { value := c.Param(\"value\") if CaptchaVerify(c, value) { c.JSON(http.StatusOK, gin.H{\"status\": 0, \"msg\": \"success\"}) } else { c.JSON(http.StatusOK, gin.H{\"status\": 1, \"msg\": \"failed\"}) } }) router.Run(\":8080\") }","categories":[{"name":"Golang","slug":"Golang","permalink":"http://sn1987a-1.github.io/categories/Golang/"}],"tags":[{"name":"Gin","slug":"Gin","permalink":"http://sn1987a-1.github.io/tags/Gin/"}]},{"title":"Vue基础知识","slug":"vue基础知识","date":"2023-09-23T12:48:34.000Z","updated":"2023-09-23T13:29:20.201Z","comments":true,"path":"posts/1d1c79fd.html","link":"","permalink":"http://sn1987a-1.github.io/posts/1d1c79fd.html","excerpt":"","text":"","categories":[{"name":"前端","slug":"前端","permalink":"http://sn1987a-1.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://sn1987a-1.github.io/tags/Vue/"}]},{"title":"并行数据结构-p-tree","slug":"并行数据结构-p-tree","date":"2023-09-22T07:46:11.000Z","updated":"2023-09-23T13:05:25.842Z","comments":true,"path":"posts/a4d33f77.html","link":"","permalink":"http://sn1987a-1.github.io/posts/a4d33f77.html","excerpt":"","text":"并行数据结构并行数据结构的几个概念 non-blocking 一个线程被挂起或中断不会导致其他线程执行被block lock-free 保证整个系统的执行进度是不断推进的 wait-free 保证每个线程的执行进度是不断推进的 通常需要做到lock-free,不要求wait-free(较难实现，性能较差) lock-free: auto expected = x.load(); do { bool ok = x.compare_exchange_strong(expected, new_value); } while(!ok) //compare_exchange_strong 解释。 // if true, 则x和expected相等，使用new_value替换x的值 //if false, 则x和expected不相等，并expected会被修改成x的值 （否则需要spin lock） 仅仅使用串行数据结构+锁远远不能达到要求（还可能导致死锁） 涉及的数据结构 CSDS（并行查找数据结构） 链表，跳表，哈希表 主要实现：查找，插入，删除 查找：遍历 插入删除，先找到位置，再进行操作 关键 速度快，避免耗时操作（写操作），等待和重试 细粒度，修改尽量设计较小的范围，需要用锁：细粒度锁 非查找数据结构： 队列，栈，竞争点都在头/尾，队尾竞争激烈 并行数据结构设计单链表串行数据结构的单链表的增删改查都相对容易，在并发中容易遇到的问题： 删除和插入，插入和插入，删除和删除，都会引发问题 内存管理问题：对已删除的节点，需要释放内存，但如果其他线程持有在该点的操作，不能立即释放 ABA问题：插入某节点时，该节点的前驱刚被释放且空间被分配到另一个节点（内存复用），导致链表乱序 线性化问题：遍历链表得到的遍历结果不一定是历史存在过的链表版本数据（解决方案：不提供遍历操作即可，只提供插入删除和查找，这三个操作可以是线性化的） 解决方案（大部分的问题都是删除操作、释放空间产生的） 节点不删除，先标记再集中GC，GC加锁 s删除导致的GC会出现短暂阻塞，出现长尾 节点删除但不释放内存 内存会不断增长 节点删除并释放内存 使用引用计数的方式管理链表内存释放，每次遍历对节点进行引用计数（对性能影响较大） 插入删除冲突的解决 关键在于：被删除节点的next不能被改变，可以将被删除节点的next添加标记符1（next&amp;1），阻止其他线程改变该节点的值。 bool del_node(ListNode* pre_del_node) { ListNode* del_node = pre_del_node-&gt;next.load(); //1. 标记del_node-&gt;next; ListNode* excepted_next = del_node-&gt;next.load(); //2. next指针添加标记位 if (!del_node-&gt;next-&gt;compare_exchange_strong(excepted_next, excepted_next&amp;1)) { return false; } //3. 修改前驱节点next指针 if(!pre_del_node-&gt;next.compare_exchange_strong(del_node, del_node-&gt;next)) { return false; } return true; } 如果修改不成功将退出，插入也类似。 compare_exchange_strong ABA问题的解决 使用tagged pointer解决（在指针上带上版本号进行管理） 使用指针的最高16尾存储指针的版本信息，每次指针内容发生变化时改变版本号（指针一般64位，CPU内存远远不及）参考 内存管理问题解决 风险指针Hazard Pointers 原理： 每个线程把自己访问的节点的地址放在全局可见的地方，这样的全局可见的指针被称为风险指针，访问完节点后清除自己的风险指针 每个线程维护一个freelist： 当某个结点A被删除后，放到freelist里 检查其他线程的风险指针，看看有没有和A相同的地址，如果没有其他节点正在访问A，A可以被释放 优化：风险指针自身也要保证线程安全，需要高效实现——shared_ptr 使用shared-ptr组织链表，每个ListNode*都是智能指针。 存在的问题： 遍历链表时，每走过一个节点，该节点引用数+1，离开时引用数-1，原子操作比较慢，因此搜索速度慢，不满足CSDS的原则 采用递归方式释放整个链表，或者链表中的一段，可能会导致栈溢出 如果一个线程获得一个结点的引用计数，但被卡住了一段时间之后才会释放这个计数，该节点所有的后继节点都会被延迟释放 并行扩张树P-treeSunYihan Parallel Ordered Sets Using Join 2016,PAM: Parallel Augmented Maps 2018,Join-based Parallel Balanced Binary Trees 2019 对于存储在磁盘上的上万个图节点，在做图算法时，对图进行虚拟化。虚拟图可以使用如下两种方式来动态构建：1. “中断”式的构建；2. 多线程的构建，即存在一个扫描线程，后台扫描满足要求的节点，加载到虚拟图中。 所谓“中断”式的构建，是指要遍历到的下一个节点不在虚拟图上，触发“中断”，开始从磁盘加载一批新的图节点进来。而多线程构建方式，则是动态卸载已经访问过的节点，同时动态加载新的节点。为了提高对虚拟图读写的并发性，就需要使用一种数据结构：Parrellel Auguemented Map. 两个基本函数： join(l,k,R)，表示以k为根节点连接的左右两棵子树LR expose(T)表示以树T的根k作为分裂节点，将树分裂为L，k，R并返回 相关函数： split ()以k为节点划分树，返回左子树，右子树和是否null split(T,k) if T = null (null,false,null) else (L,m,R)=expose(T) if k = m (L,true,R) else if k &lt; m (LL,b,LR)=split(L,k) (LL,b,join(LR,m,R)) else (RL,b,RR)=split(R,k) (join(L,m,RL),b,RR) insert（）插入一个新节点 insert(T,k) (TL,m,TR)=split(T,k) join(TL,k,TR) splitlast() 移除T最大值的节点（即右子树的最下方的值，返回移除后的平衡树和移除的节点） splitlast(T) (L,k,R)=expose(T) if R=null (L,k) else (T',k')=splitLast(R) (join(L,k,T'),k') join2() 将两棵树拼接起来，根节点为左子树的最大根 join2(TL,TR) if TL = null TR else (TL',k)=splitlast(TL) join(TL',k,TR) delete()从T中删除一个节点k delete(T,k) (TL,m,TR)=split(T,k) join2(TL,TR) 以上的几个函数未涉及并发，在以上的基础上，使用并发进行实现以下函数：(用来处理节点过多的情况，提高效率) 其中，||表示左右两边的函数可以并发进行 union()将两个树合并成一个新的树 union(T1,T2) if T1 = null T2 else if T2 = null T1 else (L2,k,R2)=expose(T2) (L1,m,R1)=spilt(T1,k) TL=union(L1,L2)|| TR=union(R1,R2) join(TL,k,TR) difference(T1,T2) 将T1中包含T2的节点删除，可以用来批量删除节点 difference(T1,T2) if T1=null null else if T2=null T1 else (L2,k,R2)=expose(T2) (L1,m,R2)=split(T1,k) T1=difference(L1,L2) || T2=difference(R1,R2) join2(T1,TR)","categories":[{"name":"HPC","slug":"HPC","permalink":"http://sn1987a-1.github.io/categories/HPC/"}],"tags":[{"name":"并行数据结构","slug":"并行数据结构","permalink":"http://sn1987a-1.github.io/tags/%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"CGO","slug":"CGO基础知识","date":"2023-09-20T12:48:34.000Z","updated":"2023-09-23T13:03:50.253Z","comments":true,"path":"posts/d4c66f48.html","link":"","permalink":"http://sn1987a-1.github.io/posts/d4c66f48.html","excerpt":"","text":"CGO在Go中调用C的代码//include \"xxx.h\" import \"C\" C.puts(helloworld) .h文件中声明函数，.c/.cpp文件对应函数的定义 import “C”前面的注释即为要运行的C代码 默认C，如果需要用C++（cpp文件），要声明： #include &lt;iostream&gt; export \"C\"{ #include &lt;xxx.h&gt; } Go生成C函数 通过使用extern \"C\"，可以确保函数在C链接下可用，从而允许从C代码中调用它，而不会受到C++名称重整的影响。 //export funct func funct (){ ... } ... func main(){ C.funct() } 使用go重新实现C语言函数。 go函数C.CSstring()将字符串转化为(const)char* 上述函数运行过程： Go的main函数执行，到CGO自动生成的C语言版本的funct桥接函数，回到GO中的funct函数。 C语言可以调用GO生成的函数，CGO省的”_cgi_export.h”包含了导出后的C语言函数声明 类型转化数字类型转化： C 语言类型 CGO 类型 Go 语言类型 char C.char byte signed char C.schar int8 unsigned char C.uchar uint8 short C.short int16 unsigned short C.ushort uint16 int C.int int32 unsigned int C.uint uint32 long C.long int32 unsigned long C.ulong uint32 long long int C.longlong int64 unsigned long long int C.ulonglong uint64 float C.float float32 double C.double float64 size_t C.size_t uint 在CGO生成的_cgo_export.h头文件中，会为go的字符串，切片，字典，接口，管道等特殊数据结构生成对应的C语言类型。（只有切片和字符串有一定的调用价值，因CGO对他们的某些操作函数生成了对应的C语言版本） typedef struct {const char *p; GoInt n;} GoString; typedef void *GoMap; typedef void *GoChan; typedef struct {void *t; void *v;} GoInterface; typedef struct {void *data; GoInt len; GoInt cap;} GoSlice; 结构体 通过C.struct_xxx访问C中定义的struct xxx的结构体类型，结构体内存布局按照C语言通用对齐规则（32/64位），若结构体的成员的名字是go的关键字，可以在成员名开头添加_来访问 /* struct A { int type; // type 是 Go 语言的关键字 }; */ import \"C\" import \"fmt\" func main() { var a C.struct_A fmt.Println(a._type) // _type 对应 type } 如果恰好有两个成员 type,_type，则type将被屏蔽。 C语言中无法直接访问Go定义的结构体类型。 切片和字符串 Go中的切片和C中的指向一定长度内存的指针（slice实际上是简化版的动态数字） go中的字符串是只读的 指针 C语言中的指针可以进行显示或隐式切换（隐式会在编译阶段给出warnings），go对不同类型的转换非常严格，无法自由转换。如果格式一致，指针可以通用。CGO解决了GO无法自由转换和进行指针运算的限制。 var p *X var q *Y q = (*Y)(unsafe.Pointer(p)) // *X =&gt; *Y p = (*X)(unsafe.Pointer(q)) // *Y =&gt; *X 使用unsafe.Pointer作为中间桥接类型实现不同类型指针的转换，转换流程：*X-&gt;unsafe.pointer-&gt;*Y 同样，go也无法实现数值类型转化为指针类型，采用uintptr作为中间类型实现，转化过程：int32-&gt;uintptr-&gt;unsafe.pointer-&gt;char* 函数调用C不支持多返回值，但Go需要error返回报错信息(如div除数为0)，解决方案： 引入errno包 #include &lt;errno.h&gt; int div(int a, int b) { if(b == 0) { errno = EINVAL; return 0; } return a/b; } CGO的处理：在CGO中如果有两个返回值，那么第二个返回值为errno，可以近似地将函数看作以下类型： func C.div(a,b C.int)(C.int,[error]) void函数返回值 按照前文所述，对于没有返回值的void函数，如果出现errno，也只有一个返回值，CGO无法直接判断错误状态，CGO的处理如下： import \"C\" import \"fmt\" func main() { _, err := C.noreturn() fmt.Println(err) }","categories":[{"name":"Golang","slug":"Golang","permalink":"http://sn1987a-1.github.io/categories/Golang/"}],"tags":[{"name":"CGO","slug":"CGO","permalink":"http://sn1987a-1.github.io/tags/CGO/"}]},{"title":"Golang基础知识","slug":"Golang基础知识","date":"2023-09-18T12:48:34.000Z","updated":"2023-09-23T13:03:58.933Z","comments":true,"path":"posts/c303e9c6.html","link":"","permalink":"http://sn1987a-1.github.io/posts/c303e9c6.html","excerpt":"","text":"golangmap实现：哈希查找表，通过链表法解决哈希冲突 随机遍历，顺序无法预测 扩容特点：逐步进行，新，旧bucket 遍历中出现扩容 遍历前已经开始扩容 slice底层结构：本质上是引用类型，底层结构有三个变量：len，cap，底层数组的指针 空切片时，cap=len=0 一般初始化方式a:=[]int{}cap=len=初始化长度 使用make进行初始化：a:=make([]int,4,5)：cap=5，len=4，a为[0,0,0,0] var a []int默认cap=len=0 append操作 cap足够，直接修改len，追加 cap不足时… cap足够时，一次追加多个和多次追加一个结果相同，cap不足时会出现不一样的结果（cap的结果不同，多次追加一个的情况可能会更大） 切片截取操作： 切片进行截取时，数组容量的末尾和原切片数组末尾对齐，数组地址为截取单元的首地址，且可以超过其len的范围进行截取，当其中一个数组发生扩容时，另一个数组的地址不变 切片扩容时会改变：cap和数字指针 垃圾回收 引用计数，0回收，无法处理 循环引用 标记-清除： 需要STW 分代收集：按照生存周期老/新不同的算法，效率高，算法设计复杂 三色标记法：白-垃圾，灰-遍历到的对象，黑，遍历灰色，标记为黑色并将引用的变量标记为灰色，直到没有灰色 每次GC循环时，不需要将所有对象移动到白色区域，只要将黑色和白色的颜色互换即可，更高效 STW：影响性能&lt;1ms 写屏障技术缩短STW 引用对象丢失：黑色节点添加了指向白色结点的引用，但无法被扫描 破坏以下二者之一： dijistra写屏障（强三色不变性），不允许黑色节点引用白色节点，引用则将白色节点改为灰色 yuasa写屏障（弱三色不变性），白色节点被删除了一个引用时，认为会被黑色节点新增引用（悲观），设置为灰色 go的垃圾回收器是和主程序并行的，关键在于三色标记法能让系统的gc暂停时间能够预测 GPM调度和CSP模型不要以共享内存的方式来通信，要以通信的方式来共享内存 CSP模型：以通信的方式共享内存（channel进行通信） GPM含义 G：go协程Goroutine M：工作线程，CPU数量 P：处理器，用来调度G，M的关联关系，M拥有P才能执行G的代码 Goroutine的调度策略 队列轮转：P周期性地调度G到M中运行，一段时间后保存上下文切换（队列） 系统调用：G0即将进入系统调用时，M0释放P，某个M1获得P运行剩下的G，G0结束后等待其他的P调度（或空闲P），此后进入缓存池睡眠 Chan原理（channel） type hchan struct { qcount uint // 队列中的总元素个数 dataqsiz uint // 环形队列大小，即可存放元素的个数 buf unsafe.Pointer // 环形队列指针 elemsize uint16 //每个元素的大小 closed uint32 //标识关闭状态 elemtype *_type // 元素类型 sendx uint // 发送索引，元素写入时存放到队列中的位置 recvx uint // 接收索引，元素从队列的该位置读出 recvq waitq // 等待读消息的goroutine队列 sendq waitq // 等待写消息的goroutine队列 lock mutex //互斥锁，chan不允许并发读写 } 写数据 recvq不为空，缓冲区无数据/无缓冲区，则直接从recvq取出G，写入数据，并把G唤醒 缓冲区有空余位置，写入缓冲区 缓冲区无空余位置，将数据写入G，将当前G加入sendq，进入睡眠被唤醒 读数据 sendq不为空，且无缓冲区，直接从sendq去除G，把G数据读走并唤醒 sendq不为空（缓冲区已满），从缓冲区首部读出数据，将G中的数据写入缓冲区尾部，唤醒G 缓冲区有数据，从缓冲区读取数据 将当前G加入recvq进入睡眠 关闭channel 唤醒recvq中所有的G，本该写入数据的内容为nil，sendq中的G唤醒（会出现panic） panic出现的场景 关闭值为nil的channel 关闭已经关闭的channel 向已关闭的channel写入数据 无缓冲区情况：读和写同步（会阻塞） context上下文结构并发安全，树状的goroutine 只定义了接口 type Context interface { Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct{} Err() error Value(key interface{}) interface{} } deadline：到达ddl自动发起取消请求 Done：返回只读的channel，如果可以读取说明已经发出取消信号，可以清理并释放 err：返回被取消的原因 value：获取context上绑定的值，key-value 竞态与内存逃逸 竞态：在程序中，同一个内存块被多个gorountine访问 解决：对资源进行加锁，sync.Mutex,sync.RWMutex 检测：添加-race 逃逸分析：内存的分配位置由编译器决定，分配速度慢且会形成内存碎片 以下场景 指针逃逸 栈空间不足逃逸 动态类型逃逸 闭包引用对象逃逸 零碎安全读写共享变量方式 Mutex锁 goroutine通过channel new和make的区别 make用来分配和初始化类型为slice，map，chan的数据，new任意数据并返回内存指针 make返回引用，即type，分配空间后进行初始，new分配的空间会被清零 对nil的slice和空silce的处理区别 slice:=make([]int,0)：空slice，不为0 slice:=[]int{} 值是nil，保证返回slice的函数异常时仍可保证返回nil 协程，进程，线程的区别 进程: 进程是具有一定独立功能的程序，进程是系统资源分配和调度的最小单位。 每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。 线程: 线程是进程的一个实体,线程是内核态,而且是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。 协程: 协程是一种用户态的轻量级线程，协程的调度完全是由用户来控制的。协程拥有自己的寄存器上下文和栈。 协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 golang的内存模型中，为什么小对象多了会加大GC压力 小对象过多会导致GC三色法消耗过多CPU 解决思路：减少对象分配 channel为什么可以做到线程安全 先进先出，本身用来在多任务间传递数据，通过通信共享内存，有天然优势 GC触发条件 手动触发（主动）：调用runtime.GC，阻塞式 被动触发： 系统监控，超过两分钟没有GC则触发 pacing（步调）算法，控制内存增长的比例，每次分配内存时检测是否以达到阈值，默认100% goroutine的数量查看和限制 查看： GOMAXPROCS控制未被阻塞的所有goroutine，通过GOMAXPROCE即可查看 限制：使用channel，每次执行goroutine前向通道写入值 Channel是同步还是异步的 ​ 异步的 channel的状态： nil，初始或手动赋值，无法关闭（panic），send/recv被永久阻塞 closed，关闭或send会panic，recv不会阻塞 active，可关闭，send/recv goroutine 和线程的区别 线程可以有多个goroutine 线程，进程都是同步的，协程是异步的 协程可以保留上一次调用的状态 协程需要线程来承载运行，不能代替线程 线程是分割的CPU资源，协程是组织好的代码流程 struct能不能比较 相同struct类型可以 不同struct不能比较，编译不通过 go主协程如何等待其他协程 用sync.WaitGroup，内部实现计数器计数未完成的操作个数，Add()添加计数，Done()计数减一，Wait()等待所有操作结束，计数为0（立即返回） slice扩容 append追加元素，空间不足则扩容，重新分配slice 扩容规则（只对容量） 小于1024：扩容时翻倍，超过1024，增长因子变为1.25 容量够用则追加，len++ 容量不够用，先扩容再追加 map顺序读取 （一般是随机的） 先把map中的key用sort排序后根据key读取 值接收者和指针接收者 方法的接收者 值类型：可以调用值接收者的方法和指针接收者的方法 指针类型：可以调用值接收者的方法和指针接收者的方法 接口实现不同： 值类型接口：类型本身和该类型的指针类型都实现了该接口 指针类型接口：只有对应的指针类型才被认为实现了接口 通常使用指针作为方法的接收者 能够修改接收者指向的值 避免每次调用方法时复制该值，更高效 发生内存泄漏的原因 goroutine需要维护用户代码的上下文信息，运行过程中需要消耗一定的内存来保存此类信息，如果一个程序不断产生goroutine，不结束已创建的goroutine并复用该部分内存，会造成内存泄漏 协程泄露：（某段代码卡住，陷入死循环等）应该被释放的协程没有被正确释放 如何检测内存泄漏 自带的工具：pprof，或者用Gops检测当前运行的go程占用的资源 两个nil可能不相等 接口interface是对接口值的封装，内部包含类型T和值V，一个接口为nil当且仅当T=nil，V=unset 两个接口比较时，先比较T再比较V(接口值和非接口值进行比较会将非接口值转化为接口值) 例如var p *int =nil转化为接口值T=*int，显然和值为nil的接口不相等 函数传参是值类型还是引用类型 只存在值传递（值或指针的副本），都会开辟新的空间 不要混淆值传递，引用传递和值类型，引用类型 内存对齐 CPU都是以字长访问的（32位，64位），不进行内存对齐会增加CPU访问内存的次数，内存对齐对实现变量的原子性操作有好处（并发场景下） 两个interface的比较 判断类型是否一样：reflect.TypeOf(a).Kind() 判断接口是否相等：reflect.DeepEqual(a,b,interface{}) 将interface赋值给另一个：reflect.ValueOf(a).Elem().Set(reflect.ValueOf(b)) 打印%v,%+v,%#v的区别 (输出struct中的元素) %v输出所有的值 %+v先输出字段名字，再输出该字段的值（name:value） %#v先输出结构体名字，再输出结构体（name:value） rune类型 go的字符有以下两种 uint8（byte），表示ASCII的字符 rune类型，表示UTF-8字符，等价于int32 string底层通过byte数组实现，对string求len计算了字节长度 []rune(str) :string转化为rune类型，统计长度示例： “hello 你好” string length=12(汉字3个),rune length=8 空struct{}占用的空间 使用unsafe.Sizeof(struct{})=0，不占用任何内存空间 空struct的用途 优点：不占内存空间，通常被当作占位符 map作为集合使用（type set map[string]struct{}) 不发送数据的channel，只是通知子协程执行任务或控制协程并发（make(chan struct{})） 有可能结构体中只包含方法，不含任何字段 变量的分配位置在堆上还是栈上 由编译器决定，如果无法判断变量作用域和大小，通常会分配到堆上（堆上的变量在函数出栈自行释放，无需gc） select执行 select：多个可用操作：随机选一个 select 中只要有一个 case 能 return，则立刻执行 当如果同一时间有多个 case 均能 return 则伪随机方式抽取任意一个执行 如果没有一个 case 能 return 则可以执行”default” 块 array和slice的区别 array：固定长度，长度是数组类型的一部分，需指定大小或根据初始化值确定 slice：可变长度，三个属性：指针，长度，容量，通过make初始化，可以扩容 defer的作用 在调用普通函数或方法前加上关键词defer即可。defer被执行时，defer后面的函数被延迟执行，直到包含该defer语句的函数执行完毕（不管return结束还是panic结束），即为在函数返回之前调用，defer是在return之前完成的。 常被用于处理成对的操作，保证资源能被释放等（打开/关闭，连接/断开，加锁/释放锁） 释放资源的defer跟在请求资源的语句后 最后面的defer最先被调用（类似于栈） return xxx并不是一条原子语句：先给返回值赋值，再调用defer语句，例如： func f() (r int) { t := 5 defer func() { t = t + 5 }() return t } 返回值为5 func defer_call() { defer func() { fmt.Println(\"打印前\") }() defer func() { fmt.Println(\"打印中\") }() defer func() { fmt.Println(\"打印后\") }() panic(\"触发异常\") } 输出结果 打印后 打印中 打印前 panic:触发异常 go关键字 go func(x,y,z)只有fun(x,y,z)在新的goroutine中运行，参数的计算在原goroutine中完成。 var和:=定义变量的区别 :=只能在声明局部变量使用，var无限制 代码type student struct { Name string Age int } func pase_student() { m := make(map[string]*student) stus := []student{ {Name: \"zhou\", Age: 24}, {Name: \"li\", Age: 23}, {Name: \"wang\", Age: 22}, } for _, stu := range stus { m[stu.Name] = &amp;stu } } 错误：for _, stu := range stus {m[stu.Name] = &amp;stu}一句中，stu实际上是副本，所以此处返回的均为同一个地址。 修改： for i:=0;i&lt;len(stus);i++ { m[stus[i].Name] = &amp;stus[i] } func main() { runtime.GOMAXPROCS(1) wg := sync.WaitGroup{} wg.Add(20) for i := 0; i &lt; 10; i++ { go func() { fmt.Println(\"A: \", i) wg.Done() }() } for i := 0; i &lt; 10; i++ { go func(i int) { fmt.Println(\"B: \", i) wg.Done() }(i) } wg.Wait() } 输出结果 A:均为输出 10，B:从 0~9 输出 (顺序不定) defer多层嵌套 func main() { fmt.Println(\"A\") defer func() { fmt.Println(\"B\") defer fmt.Println(\"C\") fmt.Println(\"D\") }() defer fmt.Println(\"E\") fmt.Println(\"F\") } 结果输出顺序：AFEDBC func main() { for i:=0; i&lt;5; i++ { defer func() { fmt.Println(i) }() } } 输出：5 5 5 5 5 func main() { for i:=0; i&lt;5; i++ { defer func(i int) { fmt.Println(i) }(i) } } 输出：4 3 2 1 0 func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret } func main() { a := 1 b := 2 defer calc(\"1\", a, calc(\"10\", a, b)) a = 0 defer calc(\"2\", a, calc(\"20\", a, b)) b = 1 } 输出 10 1 2 3 20 0 2 2 2 0 2 2 1 1 3 4","categories":[{"name":"Golang","slug":"Golang","permalink":"http://sn1987a-1.github.io/categories/Golang/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://sn1987a-1.github.io/tags/Go/"}]},{"title":"AI algorithms","slug":"AI algorithms","date":"2023-06-30T12:48:34.000Z","updated":"2023-09-24T03:27:01.940Z","comments":true,"path":"posts/e95a583.html","link":"","permalink":"http://sn1987a-1.github.io/posts/e95a583.html","excerpt":"","text":"贝叶斯网络，k-means 和transformer PART1手写数字识别本部分通过贝叶斯网络实现手写数字的识别 实验内容 fit函数 Pixels中每一行代表一个图像，每一列代表一个像素值。Labels是一个形状为（n_samples,）的向量，其中每个元素都是相应图像的类标签。 该方法通过计算每个类别的先验概率和给定每个类别的每个像素值的条件概率，将模型与数据拟合。它使用类的两个属性：self.labels_prior 和 self.pixels_cond_label。前者是一个形状为(n_classes,)的向量，用于存储每个类别的先验概率。后者是一个形状为（n_pixels, n_values, n_classes）的矩阵，存储了给定每个类别的每个像素值的条件概率。该方法通过计算数据中每个类别和每个像素值的频率并除以适当的分母来更新这些属性。 def fit(self, pixels, labels): n_samples = len(labels) for label in labels: self.labels_prior[label] += 1 self.labels_prior /= n_samples for i in range(n_samples): pixel_values = pixels[i] label = labels[i] for pixel in range(self.n_pixels): self.pixels_cond_label[pixel][pixel_values[pixel]][label] += 1 for pixel in range(self.n_pixels): for value in range(self.n_values): self.pixels_cond_label[pixel][value] /= self.labels_prior predict函数 该方法返回一个形状为（n_samples,）的向量，其中每个元素都是相应图像的预测类别标签。通过找到后验概率最大的类别来获得预测结果。通过拟合方法计算self.labels_prior和self.pixels_cond_label属性。该方法对每幅图像和每个类别进行循环，并通过将先验概率的对数与给定类别的每个像素值的条件概率的对数相加来计算后验概率。然后将后验概率与当前最大值进行比较，如果后验概率大于当前最大值，则更新预测标签。然后将预测标签分配给输出向量。 def predict(self, pixels): n_samples = len(pixels) labels = np.zeros(n_samples) for i in range(n_samples): pixel_values = pixels[i] max_posterior = float(\"-inf\") predicted_label = None for label in range(self.n_labels): posterior = np.log(self.labels_prior[label]) for pixel in range(self.n_pixels): posterior += np.log(self.pixels_cond_label[pixel][pixel_values[pixel]][label]) if posterior &gt; max_posterior: max_posterior = posterior predicted_label = label labels[i] = predicted_label return labels 图片压缩本部分使用k-means实现图片压缩，并在不同的参数下实现不同的压缩效果。 实验原理图片压缩的原理是将图片中的像素分成几个类别，每个类别用一个代表颜色来表示，从而减少图片中的颜色数目，降低文件大小。步骤如下： 使用RGB颜色空间表示图像的颜色，将图片展平为一个二维数组，每一行代表一个像素，每一列代表一个颜色通道。 对展平的图片数组应用K-means聚类算法，K代表压缩后的图片中想要的颜色数目。算法会根据像素的RGB值将相似的像素分到一起，并给每个类别分配一个平均的RGB值。其中K的值决定了压缩的程度。 将原始图片中的每个像素替换为其所属类别的平均RGB值。这样就得到了一个颜色数目更少，但是外观相似的图片。 实验内容 assign_points函数 主要流程： 遍历每个样本点，计算它与每个聚类中心的欧几里得距离，使用np.linalg.norm函数。 找出距离最小的聚类中心的索引，使用np.argmin函数，将其作为该样本点的聚类标签，存入labels数组中。 最后更新labels数组。 def assign_points(self, centers, points): n_samples, n_dims = points.shape labels = np.zeros(n_samples) for i in range(n_samples): distances = np.linalg.norm(points[i] - centers, axis=1) labels[i] = np.argmin(distances) return labels uptdate_centers函数 主要流程 遍历每个聚类中心，找出所有属于该聚类的样本点。 如果该聚类有样本点，则计算这些样本点在每个维度上的平均值作为新的聚类中心。 如果该聚类没有样本点，则保持原来的聚类中心不变。 def update_centers(self, centers, labels, points): for k in range(self.k): cluster_points = points[labels == k] if len(cluster_points) &gt; 0: centers[k] = cluster_points.mean(axis=0) return centers fit函数 主要流程： 调用initialize_centers方法，随机初始化聚类中心centers。 进行max_iter次循环 调用assign_points方法，根据当前的聚类中心centers，将每个样本点分配到最近的聚类中，得到每个样本点的聚类标签labels。 调用update_centers方法，根据新的点分配labels，更新聚类中心centers。 返回最终的聚类中心centers。 def fit(self, points): centers = self.initialize_centers(points) for _ in range(self.max_iter): labels = self.assign_points(centers, points) centers = self.update_centers(centers, labels, points) return centers compress函数 主要流程 将图片的像素值展平为一个RGB二维数组。 调用fit方法，对展平的像素点进行K-means聚类，得到聚类中心centers。 对于每个像素点，计算它与每个聚类中心的欧几里得距离，找出距离最小的聚类中心的索引。 用距离最小的聚类中心的颜色值替换原来的像素值，得到压缩后的像素点。 像素点重塑为原来的图片形状，得到压缩后的图片。 def compress(self, img): points = img.reshape((-1, img.shape[-1])) centers = self.fit(points) compressed_img = centers[np.argmin(np.linalg.norm(points[:, np.newaxis] - centers, axis=-1), axis=-1)] compressed_img = compressed_img.reshape(img.shape) return compressed_img PART 2Transformer实验内容char_tokenizer实现了一个基于字符的分词器。将一个字符串转换为一个整数列表，或者将一个整数列表转换为一个字符串。 具体功能包含以下部分： 初始化__init__，计算语料库中的不同字符的个数，并创建一个字典，将每个字符映射到一个唯一的整数。 def __init__(self, corpus: List[str]): self.corpus = corpus self.vocab = {char: i for i, char in enumerate(sorted(list(set(''.join(corpus)))))} self.n_vocab = len(self.vocab) 编码encode，编码文本，将字符串中的每个字符替换为字典中对应的整数，并返回一个整数列表。 def encode(self, string: str): encode_res=[self.vocab[c] for c in string] return encode_res 解码decode，解码编码。将整数列表中的每个整数替换为字典中对应的字符，并返回一个字符串。 def decode(self, codes: List[int]): decode_res=''.join([list(self.vocab.keys())[list(self.vocab.values()).index(c)] for c in codes]) return decode_res Head自注意力是一种用于捕捉序列中的长距离依赖关系的机制，它通过计算序列中每个元素与其他元素的相关性来生成一个加权平均的输出。本部分实现了一个注意力单头。 具体功能包含以下部分： init 创建三个线性层，分别称为Key，Query和Value，它们都将输入维度n_embd映射到输出维度head_size。 def __init__(self, head_size): super().__init__() self.Key = nn.Linear(n_embd, head_size) self.Query = nn.Linear(n_embd, head_size) self.Value = nn.Linear(n_embd, head_size) self.head_size = head_size self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size))) forward函数 调用Key，Query和Value对inputs进行线性变换。 计算query和key张量的点积，并在最后两个维度上转置key张量，得到scores张量。 对scores张量进行掩码操作，将其上三角部分（包括对角线）填充为负无穷大。 在最后一个维度上对scores张量进行softmax操作，得到weights张量，表示每个元素对其他元素的注意力权重。 通过weights和value计算得到out张量，表示每个元素的加权平均输出。 def forward(self, inputs): key = self.Key(inputs) query = self.Query(inputs) value = self.Value(inputs) scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_size) mask = torch.tril(torch.ones_like(scores)).bool() scores = scores.masked_fill(mask == 0, float('-inf')) weights = F.softmax(scores, dim=-1) out = torch.matmul(weights, value) return out MultiHead_Attention多头自注意力是一种将多个单头自注意力的输出拼接起来，并进行线性变换的机制。本部分在Head的基础上实现了MultiHead。 init函数 创建一个模块列表，包含n_heads个Head对象。 创建一个线性层，将n_heads * head_size映射到n_embd def __init__(self, n_heads, head_size): super().__init__() self.heads = nn.ModuleList([Head(head_size) for i in range(n_heads)]) self.projection = nn.Linear(n_heads * head_size, n_embd) forward函数 对heads列表中的每个Head对象，调用其前向方法，对inputs进行单头自注意力，并将所有单头的输出在最后一个维度上拼接起来. 调用projection层，对拼接后的张量进行线性变换，并返回。 def forward(self, inputs): out = torch.cat([head(inputs) for head in self.heads], dim=-1) return self.projection(out) Feedforward前馈神经网络是一种将输入通过一系列的线性变换和非线性激活函数映射到输出的机制。 init函数 创建一个顺序模块，包含两个线性层和一个ReLU激活函数。第一个线性层将n_embd映射到4n_embd，第二个线性层将4n_embd映射回n_embd。 class FeedForward(nn.Module): def __init__(self, n_embd): super().__init__() Linear_1 = nn.Linear(n_embd, 4*n_embd) Linear_2 = nn.Linear(4*n_embd, n_embd) self.net = nn.Sequential(Linear_1,nn.ReLU(),Linear_2) def forward(self, inputs): return self.net(inputs) Block本部分将多头自注意力和前馈神经网络结合起来，并使用残差连接和层归一化的机制，实现序列到序列的映射和编码。 init函数 创建两个层归一化层，一个多头自注意力模块和一个前馈神经网络模块 def __init__(self, n_embd, n_heads): super().__init__() self.norm1 = nn.LayerNorm(n_embd) self.norm2 = nn.LayerNorm(n_embd) self.attention = MultiHeadAttention(n_heads, n_embd//n_heads) self.feed_forward = FeedForward(n_embd) forward函数 对inputs和多头自注意力模块的输出即相加，对第一个层归一化，得到attention_output。 对attention_output和前馈神经网络模块的输出相加，对第二个层归一化得到outputs。 def forward(self, inputs): attention_output = self.norm1(inputs+self.attention(inputs)) outputs = self.norm2(attention_output+self.feed_forward(attention_output)) return outputs Transformer借助以上的模块，可以构建Transformer模块。 init 嵌入表，将词汇表中的每个单词映射到一个n_embd维的向量。 归一化层，对输入进行归一化处理。 线性层，将n_embd维的向量映射回词汇表中的每个单词。 位置嵌入参数，表示每个位置的向量，用于增加位置信息。 模块列表，包含n_layers个变换器的块。 def __init__(self): super().__init__() self.embedding = nn.Embedding(n_vocab, n_embd) self.norm = nn.LayerNorm(n_embd) self.linear = nn.Linear(n_embd, n_vocab) self.position_embedding = nn.Parameter(torch.zeros(1, block_size, n_embd)) self.blocks = nn.ModuleList([Block(n_embd, n_heads) for i in range(n_layers)]) forward 得到每个单词的嵌入向量embedding。 根据inputs的时间维度，截取位置嵌入参数中对应的部分，得到position_embedding张量，表示每个位置的嵌入向量。 将embedding和position_embedding相加，得到attens张量. 对attens列表中的每个变换器的块对象，调用forward方法，更新attens张量。 对attens应用层归一化层。 对attens应用线性层，得到logits张量，表示每个时间步每个单词的预测概率。 def forward(self, inputs, labels=None): batch, time = inputs.shape embedding = self.embedding(inputs) position_embedding = self.position_embedding[:, :time] attens = embedding + position_embedding for block in self.blocks: attens = block(attens) attens = self.norm(attens) logits = self.linear(attens) if labels is None: loss = None else: batch, time, channel = logits.shape logits = logits.view(batch * time, channel) labels = labels.view(batch * time) loss = F.cross_entropy(logits, labels) return logits, loss generate forward对inputs进行预测，得到logits张量。 对logits张量在最后一个时间取最大值，得到最可能的索引。 并更新inputs张量。 以上操作进行max_new_tokens次循环 def generate(self, inputs, max_new_tokens): for i in range(max_new_tokens): logits, _ = self(inputs) logits = logits[:, -1:, :].argmax(dim=-1) inputs = torch.cat([inputs, logits], dim=1) return inputs","categories":[{"name":"AI","slug":"AI","permalink":"http://sn1987a-1.github.io/categories/AI/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"智能合约","slug":"智能合约","date":"2023-06-28T12:48:34.000Z","updated":"2023-09-24T03:52:18.905Z","comments":true,"path":"posts/c85b8ed3.html","link":"","permalink":"http://sn1987a-1.github.io/posts/c85b8ed3.html","excerpt":"","text":"实验目的 理解以太坊上的智能合约 开发实现简单的智能合约 部署以太坊上的智能合约 实验原理智能合约是一种特殊协议，在区块链内制定合约时使用，当中内含了代码函数 (Function)，亦能与其他合约进行交互、做决策、存储资料及发送以太币等功能。智能合约主力提供验证及执行合约内所订立的条件。智能合约允许在没有第三方的情况下进行可信交易。这些交易可追踪且不可逆转。 在以太坊上，智能合约是一个运行在以太坊链上的程序。 它是位于以太坊区块链上一个特定地址的一系列代码（函数）和数据（状态）。 智能合约也是一个以太坊帐户，即合约帐户。 这意味着它们有余额，可以成为交易的对象。 但是，它们无法被人操控，它们是被部署在网络上作为程序运行着。 个人用户可以通过提交交易执行智能合约的某一个函数来与智能合约进行交互。 智能合约能像常规合约一样定义规则，并通过代码自动强制执行。 默认情况下，您无法删除智能合约，与它们的交互是不可逆的.以太坊上的智能合约基本生命周期可以分为开发、编译、部署和运行。 实验内容编写投票合约本实验实现了简单的投票合约示例，即VotingContract，基本结构为： Option表示每个投票选项的名称和投票计数。addoption()可以增加新的选项；getOptionCount()获取当前的投票选项数目；getOption()获取特定的选项的具体信息。99 8888888struct Option { string OptionName; uint256 voteCount; } Option[] public options; function addOption(string memory _name) public { options.push(Option(_name, 0)); } function getOptionCount() public view returns (uint256) { return options.length; } function getOption(uint256 _optionIndex) public view returns (string memory, uint256) { require(_optionIndex &lt; options.length, \"Invalid option index\"); Option memory option = options[_optionIndex]; return (option.OptionName, option.voteCount); } 投票由votes存储，通过映射讲地址和选项索引关联起来 mapping(address =&gt; uint256) public votes; 用户通过vote()进行投票，已经投票的用户无法再投票 function vote(uint256 _optionIndex) public { require(_optionIndex &lt; options.length, \"Invalid option index\"); require(votes[msg.sender] == 0, \"Already voted\"); options[_optionIndex].voteCount++; votes[msg.sender] = _optionIndex; } 部署和调用合约对投票合约进行部署，修改js文件： const VotingContract = artifacts.require(\"VotingContract\"); module.exports = function(deployer) { deployer.deploy(VotingContract); }; 部署命令： truffle compile truffle develop truffle migrate --reset 部署结果： &gt; Compiling .\\contracts\\lab.sol &gt; Artifacts written to E:\\2023spring\\blockchain\\lab4\\build\\contracts &gt; Compiled successfully using: - solc: 0.8.20+commit.a1b79de6.Emscripten.clang 调用合约 创建投票选项 truffle(develop)&gt; let contract = await VotingContract.deployed() undefined truffle(develop)&gt; await contract.addOption(\"Option 1\") { tx: '0x7736c02bd8c1801d1785efa78ac225ca00cb670fe94f564965e241072ed8349a', recei ... } 投票 truffle(develop)&gt; await contract.vote(0); { tx: ' ... } 查看投票信息 truffle(develop)&gt; let optionCount = await contract.getOptionCount(); undefined truffle(develop)&gt; console.log(\"Option count:\", optionCount.toNumber()); Option count: 1 undefined truffle(develop)&gt; let option = await contract.getOption(0); undefined truffle(develop)&gt; console.log(\"Option:\", option[0], \"Votes:\", option[1].toNumber()) Option: Option 1 Votes: 1 undefined","categories":[{"name":"区块链","slug":"区块链","permalink":"http://sn1987a-1.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"代数结构习题课-2","slug":"代数结构习题课2","date":"2023-06-02T12:48:34.000Z","updated":"2023-09-23T13:35:08.541Z","comments":true,"path":"posts/94cbcba9.html","link":"","permalink":"http://sn1987a-1.github.io/posts/94cbcba9.html","excerpt":"","text":"2023spring代数结构习题课讲义 第二次习题课知识整理环的定义（验证$$是否是环） $$是交换群 $$是含幺半群（封闭性，结合律，乘法单位元） 乘法对加法有左右分配律 交换环：乘法具有交换律 负元：加法逆元，一定存在 可逆元：乘法逆元存在时，称为可逆元 运算:$a\\cdot 0=0\\cdot a=0,a\\cdot(-b)=(-a)\\cdot b=-(a\\cdot b),(-a)\\cdot (-b)=a\\cdot b$ 特殊的环： 数环，R，C，Q 自同态环: $$是交换群，$E=\\{f|f:G\\rightarrow G是同态映射\\}$，在E上定义运算： (f+g)(x)=f(x)+g(x)\\\\ (f\\cdot g)(x)=f(x)\\cdot g(x)此时$$为环，交换群G上的自同态环。 模n同余类环$&lt;\\Z_n,+,\\cdot&gt;$ [i]+[j]=[i+j]\\\\ [i]\\cdot[j]=[i\\cdot j] 整环和域 零因子，左（右）零因子：$a\\in R,\\exist b,a\\cdot b=0(b\\cdot a=0)$ 无零因子 当且仅当 乘法有左右消去律 整环：非平凡交换环，无零因子 有左右消去律 加阶（关于加法运算的阶）：无限（特征为0）/素数（特征为p） 域：非平凡交换环，每个非零元素a都存在乘法逆元（关于乘法构成交换群） 域$\\Rightarrow$整环（必要不充分） 有限整环$\\Rightarrow$域，即为有限域，特征为p（充分不必要） 整数环不是域，$&lt;\\Z_p,+\\cdot&gt;$是域 子环 判断子环 关于加法构成子群 对乘法运算封闭 包含乘法单位元 环同态映射f： $f(a+b)=f(a)+f(b)$ $f(a\\cdot b)=f(a)\\cdot f(b)$ $f(1_{R_1})=1_{R_2}$(如果没有该条件保证，会出现$f(1_{R_1})=0_{R_2}$的情况) 同态映射相关性质 $f(0_{R_1})=0_{R_2}$ $f(-a)=-f(a)$ 可逆元映射到可逆元，$f(a’)=(f(a))’$ 同态映射不能保持整环/域等的结构（例7.14），环同构映射可以。 对于满射f: f(a+b)=f(a)+f(b)\\\\ f(a\\cdot b)=f(a)\\cdot f(b)可以判断是环。 理想和商环 理想：对于环R的非空子集I，满足$\\forall x,y\\in I,r\\in R\\Rightarrow x-y \\in I,x\\cdot r\\in I,r\\cdot x\\in I$ 理想关于加法构成子群 真理想，平凡理想 理想的运算得到的都是理想 I_1\\cdot I_2=\\{\\sum _{k=1}^{n}r_{1k}\\cdot r_{2k}|r_{1k}\\in R_1,r_{2k}\\in R_2,1\\leq k_1\\leq n,n=1,2... \\}\\\\ I_1+I_2=\\{r_1+r_2|r_1\\in I_1,r_2\\in I_2 \\} 商环：$R/I=\\{x+I|x\\in R\\}$ 若理想I中有可逆元，$I=R$(平凡理想)$\\Rightarrow$域中所有的理想都是平凡理想，没有真理想 主理想：交换环中元素a生成的理想：$\\forall a \\in R,(a)=\\{a\\cdot r|r\\in R\\}$；推广到交换环的子集：$\\forall S=\\{a_1,a_2,…a_k\\} \\subseteq R,(a_1,a_2,…a_k)=\\{a_1\\cdot r_1+…a_k\\cdot r_k|r_1,r_2,…r_k\\in R\\}$ 主理想环：所有的理想都是主理想 (整数环) 多项式环 环R上的多项式$p(x)=a_0+a_1x+…+a_nx^n,a_n\\neq 0_R,n\\geq 0$ $a_i$为系数，x为未定元，n为次数$deg(p(x))=n$；R上的非零元素：常数多项式；$0_R$零多项式； 全体多项式记为R[x]，定义运算： \\forall f(x),g(x)\\in R[x],\\\\ f(x)+g(x)=\\sum^{max\\{m,n\\}}_{k=0}(a_k+b_k)x^k\\\\ f(x)\\cdot g(x)=\\sum^{m+n}_{k=0}c_kx^k,c_k=\\sum_{i+j=k}a_i\\cdot b_j,0\\leq k\\leq m+nR[x]是环（零元，逆元，乘法单位元），且是整环。 域上的多项式 对于R[x]上的f(x),g(x)，若g(x)不是零多项式，存在唯一的$q(x),r(x)\\in F[x]$: f(x)=q(x)\\cdot g(x)+r(x)，其中r(x)的次数小于deg(g(x))，也可能是零多项式。该式子说明域上的多项式可以做除法，商和余式唯一确定；其中$f(x)=q(x)\\cdot g(x)$时，称g(x)为f(x)的因式； f(x)=q(x)\\cdot(x-a)+r_0\\Rightarrow f(a)=r_0因此x-a为f(x)的因式当且仅当$f(a)=0_F$,此时a为f(x)的根。 域上的多项式环是主理想环。（都可以写为$I=(g(x))$） 域上的多项式商环 F[x]/P=\\{f(x)+P|f(x)\\in F(x) \\},f(x)=q(x)\\cdot p(x)+r(x),f(x)-r(x)\\in(p(x))\\\\ F[x]/P=\\{b_0+b_1x+...+b_{n-1}+P|b_0,b_1,...b_{n-1}\\in F \\} 环同态定理 同态核：$\\phi$为从$R_1$到$R_2$的同态映射，$Ker\\phi =\\{r|r\\in R_1,\\phi(r)=0_{R_2} \\}$ $Ker\\phi$为$R_1$的理想 环同态基本定理：环$R_1$的任意商环都是环$R_1$的同态像。若$\\phi$是从$R_1$到$R_2$的满同态映射 R_1/Ker\\phi \\cong R_2 若f为从$R_1$到$R_2$的同态映射 $S_1$是$R_1$的子环，$f(S_1)$是$R_2$的子环（$f(R_1)$是子环） $S_1$是$R_1$的理想，$f(S_1)$是$R_2$的理想 $S_2$是$f(R_1)$的子环，$f^{-1}(S_2)$是$R_1$的子环 $S_2$是$f(R_1)$的理想，$f^{-1}(S_2)$是$R_1$的理想，且$R_1/f^{-1}(S_2)\\cong f(R_1)/S_2$ 若$I_1,I_2$为R的理想，$I_2\\subseteq I_1$，$I_1/I_2$是$R/I_2$的理想 \\frac{R/I_2}{I_1/I_2}\\cong R/I_1 补充习题 找到$\\mathbb{Z}[\\mathrm{i}],\\mathbb{Q}[\\mathrm{i}]$中全部可逆元。 $\\mathbb{Z}[\\mathrm{i}]$中的元素可以写为$a+b\\mathrm{i},a,b\\in\\mathbb{Z}$，当$a,b$不全为0时，若$(a+b\\mathrm{i})(c+d\\mathrm{i})=1$，解出$c=\\frac{a}{a^2+b^2},d=\\frac{-b}{a^2+b^2}$。若可逆，意味着$c,d\\in\\mathbb{Z}$。当$a\\ne0,b\\ne0$时，$a&lt;a^2+b^2$，$c$不可能为整数，因此不可能可逆，分$a=0$或$b=0$讨论可知$\\mathbb{Z}[\\mathrm{i}]$可逆元为$1,-1,\\mathrm{i},-\\mathrm{i}$。 $\\mathbb{Q}[\\mathrm{i}]$中的元素可以写为$a+b\\mathrm{i},a,b\\in\\mathbb{Q}$，当$a,b$不全为0时，若$(a+b\\mathrm{i})(c+d\\mathrm{i})=1$，解出$c=\\frac{a}{a^2+b^2},d=\\frac{-b}{a^2+b^2}$。若可逆，意味着$c,d\\in\\mathbb{Q}$。非零有理数加减乘除一定还为有理数，因此$c,d\\in\\mathbb{Q}$一定成立，这意味着$\\mathbb{Q}[\\mathrm{i}]$中非零元素均可逆，它是域。 证明$\\mathbb{Z}[x]$不为主理想环。 考虑$(2,x)$，若$(2,x)$为主理想，意味着存在$f(x)\\in\\mathbb{Z}[x]$使得$2=g(x)f(x),x=h(x)f(x),g(x),h(x)\\in\\mathbb{Z}[x]$。由这两式可以推出$f(x)|\\gcd(2,x)=1$，因此$f(x)=\\pm1$。 但是，$f(x)=\\pm1$时，$f(x)$生成的理想为$\\mathbb{Z}[x]$，而$2$与$x$生成的理想不包含1（注意$\\frac{1}{2}\\notin\\mathbb{Z}[x]$），矛盾，由此即证明了$(2,x)$不为主理想，$\\mathbb{Z}[x]$不为主理想环。 这也展现了为什么最大公因数与生成理想常都记作$(a,b)$，在主理想环中，可以证明理想$(a,b)$即为最大公因数$(a,b)$生成的理想。 （改编自去年期末考试）证明$\\mathbb{R}[x]/(x^2+1)\\simeq\\mathbb{C}$，这里$\\simeq$表示环同构。 构造映射$\\phi:\\mathbb{R}[x]\\to\\mathbb{C},\\phi(f(x))=f(\\mathrm{i})$，由于$\\phi(f(x)+g(x))=f(\\mathrm{i})+g(\\mathrm{i})=\\phi(f(x))+\\phi(g(x))$，$\\phi(f(x)g(x))=f(\\mathrm{i})g(\\mathrm{i})=\\phi(f(x))\\phi(g(x))$，其为环同态。 对其应用环同态第一定理，$\\mathrm{ker}\\phi=\\{f\\mid f(\\mathrm{i})=0\\}$，下证$\\mathbb{R}[x]$中这等价于$x^2+1\\mid f(x)$： 若$f(\\mathrm{i})=0$，等式两边取共轭，由于系数均为实数，可知$f(-\\mathrm{i})=0$。利用因式定理，这意味着$(x-\\mathrm{i})(x+\\mathrm{i})\\mid f(x)$，也即$x^2+1\\mid f(x)$，另一方面，当$f(x)$有因式$x^2+1$时，代入可知$f(\\mathrm{i})=0$。 于是，$\\mathrm{ker}\\phi=\\{f\\mid x^2+1\\mid f(x)\\}=(x^2+1)$。 而对任何$a+b\\mathrm{i}\\in\\mathbb{C}$，取$f(x)=bx+a$即有$\\phi(f)=a+bi$，因此$\\phi$是满射，从而利用环同态第一定理得证。 环同态第一定理的最大作用是证明商环与某个环同态，但构造映射的过程可能有一定的技巧性。本题是由于注意到$\\mathbb{i}$是$x^2+1$的根，而$\\mathbb{C}=\\mathbb{R}[\\mathrm{i}]$，因此想到如此构造。 证明$\\mathbb{Z}[x]/(x+1,x^2+4)\\simeq\\mathbb{Z}_5$。 本题基本不可能直接看出映射，因此需要构造：出于$\\ker\\phi=(x+1,x^2+4)$希望$\\phi(x^2+4)=\\phi(x+1)=0$。注意到$x^2+4=(x-1)(x+1)+5$，利用环同态可知$\\phi(x^2+4)=\\phi(x+1)\\phi(x-1)+\\phi(5)=0$，于是$\\phi(5)=\\phi(x+1)=0$。因此可以构造： 构造$\\phi:\\mathbb{Z}[x]\\to\\mathbb{Z}_5$，$\\phi(f(x))=[f(-1)]$，类似上题可说明其为环同态，下面计算$\\ker\\phi$。 $f\\in\\ker\\phi\\Leftrightarrow 5\\mid f(-1)$，利用因式定理得也即存在$t\\in\\mathbb{Z}$使得$f(x)-5t=(x+1)g(x),g\\in\\mathbb{Z}[x]$。因此，$f(x)=5t+(x+1)g(x)$，这意味着$f(x)\\in(5,x+1)$。另一方面，$f(x)\\in(5,x+1)$时，一定可以写为$5g(x)+(x+1)h(x),g,h\\in\\mathbb{Z}[x]$，于是$\\phi(f)=[5g(-1)]=[0]$，即证明$\\ker\\phi=(5,x+1)$。 由于$x^2+4=(x-1)(x+1)+5$，在有$x+1$时$x^2+4$与5可以互相生成，于是$(x^2+4,x+1)=(5,x+1)$。此外，令$f(x)=0,1,2,3,4$可知$\\phi$是满射，从而利用环同态第一定理得证。 这里也可以发现，生成理想与最大公因数有类似的允许辗转相除性质。","categories":[{"name":"代数结构","slug":"代数结构","permalink":"http://sn1987a-1.github.io/categories/%E4%BB%A3%E6%95%B0%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"Astar&CSP","slug":"Astar&CSP","date":"2023-06-01T12:48:34.000Z","updated":"2023-09-24T03:23:59.051Z","comments":true,"path":"posts/58da92e9.html","link":"","permalink":"http://sn1987a-1.github.io/posts/58da92e9.html","excerpt":"","text":"Astar and CSP Question实验1.1实验目的使用A-star算法，解决$N\\times N$二进制迷锁问题。 实验内容启发式函数 在本实验中，选用启发式函数$h(x)=\\frac13\\sum$(1的个数)。在实际搜索中，可以根据当前状态计算下一步的1的个数，无需重新遍历数组进行计算 admissible：每次操作时，对3个位置进行翻转，因此可能存在的最优解为$\\sum (d_{ij}==1)/3$向上取整，$h(x)\\leq h*(x)$ consistent：该启发函数是consistent的，因为两个相邻节点之间$c(m,n)\\geq${m中1的个数和n中1的个数的差}/3，$h(n)-h(m)=h(n-m)$，因此$h(n)\\leq c(n,m)+h(m)$ 思路 借助数组data[][]存储当前的图的情况，step存储当前的步数，solution存储当前的解法，其中solution每一行分别存储每一步的x，y坐标和以该点为中心的四种转法； 使用存储受限的启发式搜索，并限制深度，每次递归搜索，使用priority queue存储每次搜索时探索的节点，其中优先队列的排序根据是每个节点探索后剩余的1的个数，从小到大排序，即为优先探索可以最小化1的个数的情况。 auto cmp = [](const int* a, const int* b) { return a[0] &gt; b[0]; }; priority_queue&lt;int*, vector&lt;int*&gt;, decltype(cmp)&gt; pq(cmp); while(!pq.empty()) { auto cur=pq.top(); pq.pop(); change_data(cur[1],cur[2],cur[3]); solution[step-1][0]=cur[1]; solution[step-1][1]=cur[2]; solution[step-1][2]=cur[3]; cur_1_num=cur[0]; visit_state[cur[1]][cur[2]][cur[3]]=1; if(RBFS()==2) return 2; visit_state[cur[1]][cur[2]][cur[3]]=0; change_data(cur[1],cur[2],cur[3]); cur_1_num=temp_1_num; } 每次搜索，计算下一步1的个数 int each_step(int cases,int x,int y) { int after_num=cur_1_num; after_num+=1-2*data[x][y]; switch (cases) { case 1: after_num+=1-2*data[x][y+1]; after_num+=1-2*data[x-1][y]; break; //...case 2 3 4 default: break; } return after_num; } 每次进入递归或退出递归时，都要及时更新：step,cur_1_num,data void change_data(int x,int y,int cases){ data[x][y]=1-data[x][y]; switch (cases) { case 1: data[x][y+1]=1-data[x][y+1]; data[x-1][y]=1-data[x-1][y]; break; //case 2 3 4: default: break; } } 剪枝操作 由于最优解中，一定不存在同一个位置的同一种转法，可以维护数组限制仅拓展未被探索的节点 解法的顺序不影响解的结果，因此可以限制每次拓展的节点，具体方法为：遍历data数组，直到遇到第一个1，要把这个1翻转成0，则必须存在一步包含该1，这样的操作最多存在12种，因此只需拓展相关的12个节点即可。 for(int i=0;i&lt;size;i++){ for(int j=0;j&lt;size;j++) { if(data[i][j]==1) { if(i!=0&amp;&amp;j!=0) { next_step=find_next(i,j,2); if(visit_state[i][j][2]==0) pq.push(next_step); next_step=find_next(i-1,j,3); if(visit_state[i-1][j][3]==0) pq.push(next_step); next_step=find_next(i,j-1,1); if(visit_state[i][j-1][1]==0) pq.push(next_step); } //...other nine states t_flag=1; break; } }} 深度受限搜索中，理论上对于每个单独存在的1，可以用3步将其变为0且不改变其他的状态，因此可以根据每次搜索到解时当前的解的步数更新深度限制depth-limit，以及更新当前最优解 if(cur_1_num==0) { if(step&lt;best_step) { best_step=step; for(int i=0;i&lt;step;i++) for(int j=0;j&lt;3;j++) best_solution[i][j]=solution[i][j]; } if(depth_limit&gt;step) depth_limit=step; step--; return 1; } 对比Dijkstra Dijkstra搜索和启发式搜索的区别在于Dijkstra不需要借助启发函数确定下一步需拓展的节点，即将原函数的启发函数一直认为是0即可，在其他条件不变的情况下，和启发式搜索的区别： 如果需要搜索最优解，由于启发式搜索对深度限制和剪枝的存在，可以大大降低运行的时间和运行的内存占用，Dijkstra并不适合求解最优解 如果要搜索可行解，启发式搜索的搜索结果步数低于Dijkstra算法 实验1.2实验目的使用CSP算法，为学校宿管阿姨安排值班表，以满足约束条件，尽可能地满足阿姨们的轮班请求，斌并使用MRV、Forward Checking、Constraint Propagation等优化技术，以便快速解决任务并最大化满足请求数。 实验内容实验的问题模型可以抽象为一个CSP问题：要找到最大化满足约束$Request\\subset \\{0,1\\}^{N\\times D\\times S}$的取值为staff_num的days_num*shifts_num个变量。下面是CSP算法设计的具体内容： 最小剩余值：使用MRV求解问题，可以提高求解速度，mrv函数的工作就是根据当前的未被分配的变量中，剩余值最少的变量并返回其 index，如果不存在未被分配的变量，即前n步已经完成了排版，返回-1 int mrv() { int min_index=0; int flag=0; for(int i=1;i&lt;shifts_num*days_num;i++) { if(remaining_value[i]&lt;remaining_value[min_index]) min_index=i; if(remaining_value[i]&gt;0) flag=1; } if(flag==0||remaining_value[min_index]==1000000) return -1; return min_index; } 处于公平起见，应该让所有的staff被排班的次数均接近平均值，为了达到这一效果，每次对某一时间段进行排版时，根据满足条件的staff已经排班的次数从小到大进行排序，优先安排排版次数较少者；另外，为了保证优先最大化请求数量，如果该时间段存在可以满足约束的请求，优先在可以满足请求的staff中选择，不考虑无法满足的部分，否则再考虑无法满足请求的情况。 vector&lt;int&gt; staff_order(int index) { vector&lt;int&gt; order; for(int i=0;i&lt;staff_num;i++) { if(data[i][index]==1) order.push_back(i); } if(order.size()==0) { for(int i=0;i&lt;staff_num;i++) { if(data[i][index]==0) order.push_back(i); } } sort(order.begin(), order.end(), [](int a, int b){return staff_times[a] &lt; staff_times[b];}); return order; } CSP算法的主干部分，递归求解，下面是为全部的时间段找到解的处理，其中对返回值的解释如下：其中not_fot_num记录了未满足的约束的数目 1：找到了满足所有请求的解，此时要更新相关参数并退出递归 2：找到了解，没有满足所有请求，但比之前求解的解更好，此时要更新相关参数 -1：找到了不满足所有约束的解，并且不如之前的解，不做处理 if(num==days_num*shifts_num&amp;&amp;not_fit_num==0) { best_fit_num=not_fit_num; for(int i=0;i&lt;days_num*shifts_num;i++) { best_plan[i]=final_plan[i]; } return 1;} else if (not_fit_num&gt;best_fit_num) return -1; else if(num==days_num*shifts_num&amp;&amp;not_fit_num&lt;best_fit_num) { best_fit_num=not_fit_num; for(int i=0;i&lt;days_num*shifts_num;i++) { best_plan[i]=final_plan[i]; } return 2; } 对于一般的情况，要根据MRV的原则找到最小剩余值，并根据已排班数量staff_num来确定赋值顺序。每次进入或退出递归时，都要更新或恢复相关的变量： 修改data中该staff相邻时间的状态 修改相邻时间中remain_value 更改无法满足的情况时not_fit_num 修改staff已经被排班的次数 int index=mrv(); int state=0; auto order=staff_order(index); int t; for(int j=0;j&lt;order.size();j++) { int i=order[j]; int old_data_i_index=data[i][index]; if(old_data_i_index==0) not_fit_num+=1; data[i][index]=0; state=0; if(index!=0&amp;&amp;data[i][index-1]==1) { remaining_value[index-1]-=1; state=1; } if(index!=0) data[i][index-1]=-1; if(index!=days_num*shifts_num-1&amp;&amp;data[i][index+1]==1) { remaining_value[index+1]-=1; state+=2; } if(index!=days_num*shifts_num-1) data[i][index+1]=-1; final_plan[index]=i; int temp=remaining_value[index]; remaining_value[index]=1000000; staff_times[i]++; t=csp(num+1); staff_times[i]--; remaining_value[index]=temp; if(t==1) { return 1; } if(index!=0) data[i][index-1]=0; if(index!=days_num*shifts_num-1) data[i][index+1]=0; if(state%2==1) { data[i][index-1]=1; remaining_value[index-1]+=1; } if(state&gt;=2) { data[i][index+1]=1; remaining_value[index+1]+=1; } data[i][index]=old_data_i_index; if(old_data_i_index==0) not_fit_num--; } return 2; 最后处理输入数据，输出数据模块，即可完成CSP排班的全部内容。 void get_input(char * filename) { ifstream file(filename); char c; file&gt;&gt;staff_num&gt;&gt;c&gt;&gt;days_num&gt;&gt;c&gt;&gt;shifts_num; each_time=days_num*shifts_num/staff_num; best_fit_num=100000; not_fit_num=0; for(int i=0;i&lt;staff_num;i++) { for(int j=0;j&lt;days_num;j++) { for(int k=0;k&lt;shifts_num;k++) { if(k) file&gt;&gt;c; file&gt;&gt;data[i][j*shifts_num+k]; remaining_value[j*shifts_num+k]+=data[i][j*shifts_num+k]; }} }} void get_output(char * filename) { fstream file(filename); for(int i=0;i&lt;days_num;i++) { for(int j=0;j&lt;shifts_num;j++) { if(j!=shifts_num-1) file&lt;&lt;best_plan[i*shifts_num+j]&lt;&lt;','; else file&lt;&lt;best_plan[i*shifts_num+j]&lt;&lt;endl; } } file&lt;&lt;days_num*shifts_num-best_fit_num&lt;&lt;endl; }","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://sn1987a-1.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"UTXO区块链","slug":"区块链","date":"2023-05-28T12:48:34.000Z","updated":"2023-09-24T03:52:59.486Z","comments":true,"path":"posts/e65e9bf0.html","link":"","permalink":"http://sn1987a-1.github.io/posts/e65e9bf0.html","excerpt":"","text":"PART1实验目的 了解区块链上的简单数据结构 实现Merkle树的构建 初步理解UTXO的使用和验证 理解比特币上的交易创建 实验内容区块链的基本结构type BlockChain struct{ tip []byte//最新区块的哈希值 db *bolt.DB//数据库连接 } 区块链通过链式结构连接各个区块，形成一个不断增长的分布式账本系统。 区块的基本结构作为区块链的主要组成部分，区块由区块头和区块体构成，区块头存储了版本号，上一个区块的哈希值，当前区块交易的哈希值，时间戳等信息，唯一标识一个区块。 type BlkHeader struct { Version int64 PrevBlockHash []byte MerkleRoot []byte Timestamp int64 Bits int64 Nonce int64 } 实验步骤Merkle树每一个区块的交易节点从底向上构建Merkle树，采用哈希加密（单次sha256）。 新建Merkle节点，分为叶子节点和非叶子节点 func NewMerkleNode(left, right *MerkleNode, data []byte) *MerkleNode { NewNode:=&amp;MerkleNode{} NewNode.Left=left NewNode.Right=right if left==nil &amp;&amp; right==nil{ data_sha:=sha256.Sum256(data) NewNode.Data=data_sha[:] } else{ data_c:=append(left.Data,right.Data...) data_sha:=sha256.Sum256(data_c) NewNode.Data=data_sha[:] } return NewNode } 新建Merkle树，调用新建节点的函数自底向上构建，直到结点数为1，并且保证节点数量为偶数 func NewMerkleTree(data [][]byte) *MerkleTree { NewTree:=&amp;MerkleTree{} var nodes []MerkleNode NewTree.Leaf=data for _,data_i := range data{ node_i:=NewMerkleNode(nil,nil,data_i) nodes=append(nodes,*node_i) } for len(nodes)&gt;1{ var newnodes []MerkleNode for i:=0;i&lt;len(nodes)/2;i++{ node:=NewMerkleNode(&amp;nodes[2*i],&amp;nodes[2*i+1],nil) newnodes=append(newnodes,*node) } if len(nodes)%2==1{ node:=NewMerkleNode(&amp;nodes[len(nodes)-1],&amp;nodes[len(nodes)-1],nil) newnodes=append(newnodes,*node) } nodes=newnodes } NewTree.RootNode=&amp;nodes[0] return NewTree } SPV证明路径，自底向上获取节点的路径的兄弟结点的哈希值 先根据结点的index判断节点在树的具体位置，自顶向下访问路径，再将路径逆序即可获取SPV证明路径 func (t *MerkleTree) SPVproof(index int) ([][]byte, error) { t_len:=len(t.Leaf) if index&gt;t_len{ return nil,fmt.Errorf(\"Outof Index\") } depth:=0 leaf_number:=1 t_node:=t.RootNode.Left for t_node!=nil{ t_node=t_node.Left depth+=1 leaf_number*=2 } var n_path [][]byte t_node=t.RootNode for t_node!=nil &amp;&amp; t_node.Left!=nil{ if index&gt;=leaf_number/2{ index-=leaf_number/2 n_path=append(n_path,t_node.Left.Data) t_node=t_node.Right } else{ n_path=append(n_path,t_node.Right.Data) t_node=t_node.Left } leaf_number/=2 } var path [][]byte for i:=0;i&lt;len(n_path);i++{ path=append(path,n_path[len(n_path)-1-i]) } return path, nil } 验证SPV路径，将该节点的哈希值和SPV证明路径依次计算，最终和根节点的哈希值比较即可完成SPV路径的验证。 func (t *MerkleTree) VerifyProof(index int, path [][]byte) (bool, error) { if index&gt;len(t.Leaf){ return false,fmt.Errorf(\"Outof Index\") } data_sha:=sha256.Sum256(t.Leaf[index]) n_data:=data_sha[:] for _,t_data :=range path{ if index%2==1{ temp:=append(t_data,n_data...) temp2:=sha256.Sum256(temp) n_data=temp2[:] } else{ temp:=append(n_data,t_data...) temp2:=sha256.Sum256(temp) n_data=temp2[:] } index/=2 } for i:=0;i&lt;len(n_data);i++{ if t.RootNode.Data[i]!=n_data[i]{ return false,nil } } return true, nil } 判断Coinbase交易每个区块新建立时，可以加入一笔coinbase交易，这笔交易只有输出，没有输入，判断的基本依据为： 只出现在第一笔交易，其他交易均不是coinbase交易 输入的Txid为空，Vout为-1 func (t *Transaction) IsCoinBase() bool { if len(t.Vin[0].Txid)==0 &amp;&amp; (t.Vin[0].Vout==-1){ for i:=1;i&lt;len(t.Vin);i++{ if len(t.Vin[i].Txid)==0 &amp;&amp; (t.Vin[i].Vout==-1){ return false}} return true} return false} 计算公钥对应的地址比特币上的地址的计算如下 计算公钥的哈希值（RIPEMD16(SHA256(PubKey))） 地址计算前加入版本号 把步骤2的内容通过计算公钥哈希的双重SHA256哈希加密，取前4个字节作为校验和 版本号，公钥哈希，校验和的组合通过Base58加密生成比特币的地址 func (w *Wallet) GetAddress() []byte { key_hash:=HashPublicKey(w.PublicKey) var temp []byte temp=append(temp,version) temp=append(temp,key_hash...) checksum:=sha256.Sum256(temp) hash_checksum:=checksum[:] checksum=sha256.Sum256(hash_checksum) hash_checksum=checksum[:] var res []byte res=append(res,version) res=append(res,key_hash...) res=append(res,hash_checksum[0:checkSumlen]...) res=[]byte(base58.Encode(res)) return res } P2PKH锁定部分P2PKH指的是向公钥的哈希支付，根据公钥的地址的计算方法，类似的可以通公钥地址获取公钥的哈希： 公钥地址经过base58解码后，第一位是version版本号，后四位为校验和，中间即为公钥哈希 func (out *TXOutput) Lock(address []byte) { data,_:=base58.Decode(string(address)) out.PubKeyHash=data[1:len(data)-4] } 实验结果借助go test对实验结果进行检验 PS E:\\2023spring\\blockchain\\lab2\\lab2&gt; go test PASS ok lab2 0.657s PART2实验目的 进一步理解区块链上的数据结构 实现基于的POW共识算法出块 实现比特币上的账户创建和查询 理解UTXO的基本使用方法 实现区块链与数据库的交互 实验内容工作量证明工作量的证明机制（POW），简单来说就是通过提交一个容易检测，但是难以计算的结果，来证明节点做过一定量的工作。 首先完成Run函数，该函数代表矿工通过如下流程完成挖矿工作： 首先构建当前区块头，区块头包含版本号，上⼀个区块哈希值(32位)，当前区块数据对应哈希（32位，即区块数据的merkle根），时间戳，区块难度，计数器(nonce)。 添加计数器，作为随机数。计算器从0开始基础，每个回合+1 对于上述的数据来进行一个哈希的操作。 判断结果是否满足计算的条件： 如果符合，则得到了满足结果。 如果没有符合，从2开始重新直接2、3、4步骤。 func (pow *ProofOfWork) Run() (int64, []byte) { nonce := int64(0) var hash [32]byte var hashInt big.Int blkh := pow.block.Header for nonce &lt; maxNonce { var data []byte data=append(data,IntToHex(blkh.Version)...) data=append(data,blkh.PrevBlockHash[:]...) data=append(data,blkh.MerkleRoot[:]...) data=append(data,IntToHex(blkh.Timestamp)...) data=append(data,IntToHex(blkh.Bits)...) data=append(data,IntToHex(nonce)...) hash = sha256.Sum256(data) hashInt.SetBytes(hash[:]) if hashInt.Cmp(pow.target) == -1 { break } else { nonce++ } } return nonce, hash[:] } 借助Validate函数完成对挖矿结果的验证，即验证矿工给出的Nonce是否是该难题的答案。 func (pow *ProofOfWork) Validate() bool { var hashInt big.Int var hash [32]byte blkh := pow.block.Header var data []byte data=append(data,IntToHex(blkh.Version)...) data=append(data,blkh.PrevBlockHash[:]...) data=append(data,blkh.MerkleRoot[:]...) data=append(data,IntToHex(blkh.Timestamp)...) data=append(data,IntToHex(blkh.Bits)...) data=append(data,IntToHex(blkh.Nonce)...) hash = sha256.Sum256(data) hashInt.SetBytes(hash[:]) return hashInt.Cmp(pow.target) == -1 } UTXOUTXO(Unspent Transaction Outputs)，即没有花掉的交易输出，实际可以理解为在一次转账时剩余没有转出的资金。UTXO的交易模型上，用户通过使用未使用的交易输出（UTXO）来执行一笔交易。 构建新的UTXO交易的方法如下所示： 找到输入地址对应的交易PubKeyHash，借助findunspentOutputs找到输入账户的UTXO 根据UTXO构建交易并进行签名 完成找零操作：剩余的金额作为UTXO返回到原输入中 func NewUTXOTransaction(from, to []byte, amount int, UTXOSet *UTXOSet) *Transaction { var inputs []TXInput var outputs []TXOutput wal , _ := NewWallets() bc := UTXOSet.Blockchain pubKeyHash := HashPublicKey(wal.GetWallet(from).PublicKey) acc, validOutputs := UTXOSet.FindUnspentOutputs(pubKeyHash, amount) if acc &lt; amount { log.Panic(\"ERROR: Not enough funds\") } for txid, outs := range validOutputs { txID, err := hex.DecodeString(txid) if err != nil { log.Panic(err) } for _, out := range outs { input := TXInput{ Txid: txID, Vout: out, Signature: nil, PubKey: wal.GetWallet(from).PublicKey, } inputs = append(inputs, input) } out_1 := TXOutput{amount,nil} out_1.Lock(to) outputs = append(outputs, out_1) if acc &gt; amount { out_2 := TXOutput{acc-amount,nil} out_2.Lock(from) outputs = append(outputs, out_2) } tx := Transaction{nil, inputs, outputs} bc.SignTransaction(&amp;tx,wal.GetWallet(from).PrivateKey) tx.SetID() return &amp;tx } UTXO池比特币所有的交易都是放在UTXO池中，这样的好处是为了快速的得到某个UTXO是否当前可用。需要通过公私钥的唯一标识来算出我们当前的余额。在构建UTXO的交易时，我们需要通过UTXO池来需要当前属于自己的UTXO，然后获得相对应的账户金额，然后再生成对应的输出。FindUnspentOutputs函数来查询用户当前未未花费的UTXO金额及其映射关系(存储txid和对应的index，便于后续查找)，具体实现如下所示： func (u UTXOSet) FindUnspentOutputs(pubkeyHash []byte, amount int) (int, map[string][]int) { unspentOutputs := make(map[string][]int) totalAmount := 0 db := u.Blockchain.db err := db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(utxoBucket)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { outs := DeserializeOutputs(v) txid := hex.EncodeToString(k) for outIndex, out := range outs.Outputs { if out.IsLockedWithKey(pubkeyHash) { unspentOutputs[txid] = append(unspentOutputs[txid], outIndex) totalAmount += out.Value if totalAmount &gt;= amount { return nil } } } } return nil }) if err != nil { log.Panic(err) } return totalAmount, unspentOutputs } BlockChain除此之外，还需要完成mineblock来生成新的区块：针对一组交易在区块链上写入一个新块，维护区块链的相关信息 func (bc *Blockchain) MineBlock(transactions []*Transaction) *Block { var last_hash []byte err := bc.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) last_hash = b.Get([]byte(\"l\")) return nil }) if err != nil { log.Panic(err) } var prev_hash [32]byte copy(prev_hash[:],(last_hash)[:32]) newBlock := NewBlock(transactions,prev_hash) err = bc.db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) b.Put(newBlock.CalCulHash(), newBlock.Serialize()) b.Put([]byte(\"l\"), newBlock.CalCulHash()) bc.tip = newBlock.CalCulHash() return nil }) if err != nil { log.Panic(err) } return newBlock } 另外，为了维护UTXO，需要找到所有UTXO并构建映射，通过函数findUTXO实现： UTXO的特点：“未使用的交易” 对于每笔非CoinBase交易，每个输入都指向之前的输出，根据所有交易的输入判断之前的交易是否已被输出 维护UTXO和spentTXOs通过循环求得最终的UTXO func (bc *Blockchain) FindUTXO() map[string]TXOutputs { UTXO := make(map[string]TXOutputs) spentTXOs := make(map[string][]int) bci := bc.Iterator() for { block := bci.Next() for _, tx := range block.GetTransactions() { txID := hex.EncodeToString(tx.ID) Outputs: for outIdx, out := range tx.Vout { if spentTXOs[txID] != nil { for _, spentOutIdx := range spentTXOs[txID] { if spentOutIdx == outIdx { continue Outputs } } } outs := UTXO[txID] outs.Outputs = append(outs.Outputs, out) UTXO[txID] = outs } if tx.IsCoinBase() == false { for _, in := range tx.Vin { inTxID := hex.EncodeToString(in.Txid) spentTXOs[inTxID] = append(spentTXOs[inTxID], in.Vout) } } } if block.GetPrevhash() == [32]byte{} { break } } return UTXO } 实验结果本次实验基本完成了基于比特币的区块链搭建，具有以下功能： go run . createblockchain -address ADDRESS //创建区块链 go run . createwallet //创建钱包 go run . getbalance -address ADDRESS //查询账户余额 go run . listaddresses //查询区块链上的地址 go run . printchain //打印区块链 go run . reindexutxo //重构UTXO池 go run . send -from FROM -to TO -amount AMOUNT //发起转账交易 对实现的区块链进行go test ... PASS ok lab3 0.188s","categories":[{"name":"区块链","slug":"区块链","permalink":"http://sn1987a-1.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"代数结构习题课-1","slug":"代数结构习题课1","date":"2023-05-02T12:48:34.000Z","updated":"2023-09-23T13:29:20.211Z","comments":true,"path":"posts/94cbcba9.html","link":"","permalink":"http://sn1987a-1.github.io/posts/94cbcba9.html","excerpt":"","text":"2023spring代数结构习题课讲义 代数结构 第一次习题课2023.5.3 第三章 映射内容回顾 映射的基本定义 概念：映射，原像，像，值域，映射相等 给定集合A，B，从A到B的映射有$|B|^{|A|}$个 特殊映射：对于$f:A\\rightarrow B$: $B=A,\\forall a,f(a)=a$：恒等映射 $R_f=B$：满射 任给$a_1,a_2\\in A,a_1\\neq a_2\\Rightarrow f(a_1)\\neq f(a_2)$：单射 单射+满射：一一映射（双射） 相关性质：$f^{-1}$，$n!$个双射 映射的复合：$g\\circ f(a)=g(f(a))$ 从右往左计算 结合律：$(h\\circ g)\\circ f=h\\circ (g\\circ f)$ $f^{-1}\\circ f=f\\circ f^{-1}=I_A$ 复合运算保持单射/满射/双射 置换：映射到自身的双射 恒等映射也可以称为恒等置换 求逆置换：交换两行并按照第一行排序 奇置换与偶置换：由逆序的个数奇偶决定 轮换：特殊的置换，$\\sigma=(a_1a_2…a_r)$ 不相交的轮换的乘积可以交换 任何置换都可以表示成若干不相交的轮换之乘积 置换的阶：将置换表示为不相交的轮换，阶为各轮换的因子长度的最小公倍数 对换：两个元素的轮换 任何轮换都可以表示成对换之积 对换是奇置换，n元置换中，奇置换和偶置换各占一半 开关函数：$F_2={0,1},f(x_1,…x_n)$为$F_2^n$到$F_2$的映射即为n元开关函数，共有$2^{2^n}$个 求补运算$\\overline f$，逻辑加 $ +$，逻辑乘 $ \\cdot$ （注意和算术运算的区别） 结合律，交换律，分配律，$f+0=f;f\\cdot 1=f;f+\\overline f=1;f\\cdot \\overline f=0$ 小项表达式：唯一的表达$f(x_1,..x_n)=\\sum_{a_i=0/1,1\\leq i\\leq n} f(a_1,..a_n)x_1^{a_1}…x_n^{a_n}$ 作业题目 3.16 证明：任何n元置换都可以表示成(1 2),(2 3),…,(n-1,n)的乘积 方法1：用归纳法证明： n=2时，2元置换即为(1 2); n&gt;2时，假设对于任何k，$k\\le n$,满足任何k元置换都可以表示成(1 2),(2 3),…,(k-1,k)的乘积，考虑任何一个n元置换$\\sigma$,设该置换对应的位置i的元素为n，令$\\tau=(n-1\\ n)…(i+1\\ i+2)(i\\ i+1)\\sigma$，依次计算，即为将$\\sigma$的第i个元素和第i+1个元素对换，第i+1个元素和第i+2个元素对换…最终可以将元素n换到第n个位置，即$\\tau$为（n-1）元置换；将上式进行整理，原n元置换可以写为$\\sigma=(i+1\\ i+2)(i\\ i+1)…(n-1\\ n)\\tau$，根据归纳假设，$\\tau$可以写为(1 2),(2 3),…,(k-1,k)的乘积，因此$\\sigma$可以写为(1 2),(2 3),…,(n-1,n)的乘积。 综上所述，任何n元置换都可以表示成(1 2),(2 3),…,(n-1,n)的乘积。 方法2： 任何置换都可以表示为成不相交的轮换之积，任何轮换都可以表示成对换之积，因此只需讨论将对换表示为(1 2),(2 3),…,(n-1,n)的乘积。对换$(a_i\\ a_j),i&gt;j$可表示为$(a_{i+1}\\ a_{i+2})…(a_{j-2}\\ a_{j-1})(a_{j-1}\\ a_{j})…(a_{i+1}\\ a_{i+2})(a_i\\ a_{i+1})$从而得证。 3.17 求证下列恒等式 （1）$x_1=x_1x_2x_3+x_1\\overline x_2x_3+x_1x_2\\overline x_3+x_1\\overline x_2\\overline x_3$ $x_1=x_1(x_2+\\overline x_2)(x_3+\\overline x_3)=x_1x_2x_3+x_1\\overline x_2x_3+x_1x_2\\overline x_3+x_1\\overline x_2\\overline x_3$ （2）$x_1x_2+x_2x_3+x_3\\overline x_1=x_1x_2+\\overline x_1x_3$ $x_1x_2+x_2x_3+x_3\\overline x_1=x_1x_2+x_2x_3(x_1+\\overline x_1)+x_3\\overline x_1 = x_1x_2(1+x_3)+\\overline x_1x_3(x_2+1)=x_1x_2+\\overline x_1x_3$ 注意：开关函数的运算中$a+c=b+c$无法推出$a=b$ 补充习题注意，在置换/对换/轮换的计算中，乘积要从右往左计算，轮换的计算方式是将每个元素映射到右边的位置。 第四章 二元关系内容回顾关系 关系的定义： 相关概念：空关系（平凡关系），全关系 关系的性质：判断是否具有某种性质 自反性，反自反性，对称性，反对称性，传递性 关系的表示： 有序二元组：$xRy$ 关系矩阵：$mij=\\begin{cases}0,a_iR\\mkern-10.5mu/ a_j\\\\1,a_iRa_j\\end{cases} $ 关系图：如果有$a_iRa_j$，则画一条由$a_i$指向$a_j$的有向弧（环） 关系的运算： 相等，$&lt;,\\leq,&gt;,\\geq$ 并交补运算（交换律，结合律） 复合关系 ：结合律，幂运算$R^n=R^m\\circ R1^{n-m}$ 自反闭包：包含R且满足自反性质的最小关系 对称闭包，传递闭包 等价关系 满足自反，对称，传递 等价类$[a]_R$，代表元 集合的划分与集合上的等价关系一一对应（划分相同——等价关系本质相同） A/R：关于等价关系R的商集 序关系 $\\preceq$：自反，反对称，传递；偏序集$$ 可比较/不可比较 线序关系：任意两个元素都是可比较的（完全序关系） 序关系中的控制关系：y控制x，即$x\\hat \\preceq_\\neq y$，且不存在$z,x\\hat \\preceq_\\neq z ,z\\hat\\preceq_\\neq y$ 极大元，极小元 哈希图：最上方是极大元，最下方是极小元 最大元，最小元 最大元一定是极大元，最大元至多一个 （子集的）上界/下界：不一定有，不一定唯一 最小上界/上确界；最大下界/下确界 集合的势 等势：$A \\sim B$：存在双射 $\\mathscr P(E)$上的等价关系 有限集合 可数集合 ；可数无限集合：与自然数集合等势的集合 势的大小；支配：A和B的一个子集等势，则称B支配A，$A\\preceq B$：偏序关系 $A\\prec \\mathscr P(A) $ 无限集合 每个无限集合都有一个可数无限子集 每个无限集合都和它的某个真子集集合等势 作业题目4.7.设$A=\\{1,2,3,4\\},$在$\\mathscr{P} (A)$上定义关系“$\\sim$”。任给$S,T\\in \\mathscr{P}(A)$, S\\sim T,当且仅当\\quad |S|=|T|证明：“$\\sim$”是$\\mathscr{P}(A)$上的等价关系，并写出它的商集$\\mathscr{P}(A)/\\sim$。 自反性：$\\forall S\\in \\mathscr P(A),|S|=|S|\\Rightarrow S\\sim S$ 对称性：$\\forall S,T\\in \\mathscr P(A),S\\sim T\\Rightarrow |S|=|T|\\Rightarrow |T|=|S|\\Rightarrow T\\sim S$ 传递性：$\\forall S,T,V\\in \\mathscr P(A),S\\sim T,T\\sim V$ 商集：$\\{\\{\\empty\\},\\\\\\{\\{1\\},\\{2\\},\\{3\\},\\{4\\}\\},\\\\\\{\\{1,2\\},\\{1,3\\},\\{1,4\\},\\{2,3\\},\\{2,4\\},\\{3,4\\}\\},\\\\\\{\\{1,2,3\\},\\{1,2,4\\},\\{1,3,4\\},\\{2,3,4\\}\\},\\\\\\{\\{1,2,3,4\\}\\}\\}$ 4.16.$A=\\{a_1,a_2,…,a_n,…\\}$是任意集合。在偏序集$&lt;\\mathscr{P}(A),\\subseteq&gt;$中取子集序列$\\{a_1\\},\\{a_1,a_2\\},\\{a_1,a_2,a_3\\},…,\\{a_1,a_2,…,a_n,\\},…$,它们的并集是否是$\\mathscr{P}(A)$的一个极大元？为什么？ 若A为有限集合，显然子集序列的并集为极大元（反证法） 若A是可数无限集合，则并集P可能是极大元，也可能不是极大元。举例：设A为自然数集合 是极大元： $a_i=i-1,\\{a_1,a_2,…a_n,…\\}=\\{0,1,….n,..\\}=A$ 不是极大元：$a_i=i,\\{a_1,a_2,…a_n,…\\}=\\{1,2,…n,…\\}\\subset A$ 若A是不可数集合，则一定不是极大元，否则并集$P=A,{a_1,a_2,…a_n,…}$列举出了A的所有元素，与A是不可数集合矛盾。","categories":[{"name":"代数结构","slug":"代数结构","permalink":"http://sn1987a-1.github.io/categories/%E4%BB%A3%E6%95%B0%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"加密算法","slug":"区块链加密算法","date":"2023-04-28T12:48:34.000Z","updated":"2023-09-24T03:52:09.035Z","comments":true,"path":"posts/79dcde63.html","link":"","permalink":"http://sn1987a-1.github.io/posts/79dcde63.html","excerpt":"","text":"实验目的 理解非对称加密算法 理解椭圆曲线算法ECC 实现比特币上的椭圆曲线secp256k1算法 ECC算法流程ECC算法中，陷门函数是定义在有限域上的二元三次曲线y^2^=x^3^+ax+b上的点所组成的阿贝尔群。 公钥：点Q 私钥：大数k ECC算法是有限域Fp满足公式：Q=kP。 签名过程： 取一个新的随机数k，令$k*G\\equiv R\\ mod \\ N$ 计算S： uG + vP = R = kG \\\\ uG + veG = kG\\\\ u + ve = k \\\\ z/s + re/s = k\\\\ (z + re)/s = k\\\\ s = (z + re)/k 返回签名：signature(s,r) 签名的数字为（s,r） 验签过程： 计算u，v 计算uG+vP 判断(uG+vp).x是否和r模N同余，如果是，则签名成功 实验内容ECC签名func (ecc *MyECC) Sign(msg []byte, secKey *big.Int) (*Signature, error) { k,err :=newRand() if(err!=nil){ return nil,err } R := Multi(G,k) r:=R.X r=r.Mod(r,N) z:=crypto.Keccak256(msg) z_i := new(big.Int).SetBytes(z) s:=new(big.Int).Mul(new(big.Int).Add(z_i,new(big.Int).Mul(r,secKey)),Inv(k,N)) s=s.Mod(s,N) sig:=&amp;Signature{s,r} return sig,nil } ECC验签func (ecc *MyECC) VerifySignature(msg []byte, signature *Signature, pubkey *Point) bool { s:=signature.s r:=signature.r z:=crypto.Keccak256(msg) z_i := new(big.Int).SetBytes(z) s_inv:=Inv(s,N) s_inv=s_inv.Mod(s_inv,N) u:=new(big.Int).Mul(z_i,s_inv) u=u.Mod(u,N) v:=new(big.Int).Mul(r,s_inv) v=v.Mod(v,N) ans:=Add(Multi(G,u),Multi(pubkey,v)).X ans=ans.Mod(ans,N) return ans.Cmp(r)==0 }","categories":[{"name":"区块链","slug":"区块链","permalink":"http://sn1987a-1.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"ML算法：特征抽取","slug":"ML综合实验","date":"2023-01-10T12:48:34.000Z","updated":"2023-09-24T03:49:02.486Z","comments":true,"path":"posts/72ae2b6b.html","link":"","permalink":"http://sn1987a-1.github.io/posts/72ae2b6b.html","excerpt":"","text":"特征抽取实验目的本次实验的实验目的是对一数据集进行分类，因为数据集中存在着噪声数据，需要对数据进行特征抽取，并使用线性回归，决策树，神经网络，SVM以及XGBoost分别实现对模型的预测并进行评估。 实验原理特征抽取和特征选择对实验的训练数据集进行观察可得：对于每一条样本，有与之相关的120个feature（个别feature可能是na），但是对于训练有效的特征不足20个，如果对原数据集进行训练，可能会导致过拟合，训练过慢，效果较差等结果，因此要对数据进行特征抽取，选取对训练有益的特征 本次实验中，特征抽取使用了如下两种方法： 基于决策树抽取本部分借助sklearn中的DecisionTreeClassifier进行处理，因为每个特征具有对应的权重，对于分类结果帮助较大的feature的权重大，为了筛选出有用的信息，可以选择决策树中权重大的点，处理思路为： 将数据集划分为训练集和测试集，得到训练集对应的决策树，在测试集上测试准确率 如果测试集上的准确率大于25.5%（表明此次训练的结果较为有效），记录下此时所有feature对应的权重 重复上述过程，直到收集到的权重数大于100，将各个feature得到的权重相加，得到新的权重 根据新的权重，保留最大的二十个feature用于训练 类似的，不仅仅是基于决策树，基于XGBoost，SVM等通过多次构建模型找到权重最大的特征 RFE方法与上一种抽取方法类似，RFE也是借助反复构建模型寻找较好的特征，不同的是RFE借助递归的思路，依次找出特征中最好的特征并再下一轮训练中排除当前特征，在剩余的特征上重复训练，直到找出20个最好的特征。 RFE也可以采取线性回归，SVM等模型作为底层模型实现特征选择，本次实验中RFE借助sklearn库中的RFE函数以及线性回归函数作为数据抽取的方法 Relief-F方法Relief算法是用于两类数据的分类问题的特征权重计算方法，而Relief-F作为Relief算法拓展，可以实现多分类问题的特征权重计算，算法的主要步骤为： 将所有样本按类别分类，对于每类样本，分别抽取一个样本记作x 对于每一个x，在该类中找到x的k个最近邻，在不包含该类别的训练集中也找出k个最近邻 根据近邻及所属的类别计算特征的权重 对特征的权重进行派别，得到合适的特征 多分类任务在前面的实验中，已经完成了对二分类任务的逻辑回归、SVM模型，为了适应本实验的任务，要将其进行适当修改，以便实现多分类任务。 多分类学习可以有二分类学习器集成而来，有三种方法： 一对一 一对其余 多对多 其中，本实验采用了多对多的方式进行训练，由于本实验分类为四类，可以将多对多的分类学习简化设计如下： 设计不同的二分类器，每个二分类器将两个类别视作正类，另外两个类别视为负类，因此共需要六个二分类学习器 对于每个分类器，因为其对称性，正类和负类的权重可以视为一致的，在预测时，对于一个样本统计，将某一类别视为正类的概率，得到的最大的概率对应的类别视作该样本的预测值 实验步骤数据预处理 从数据集中读取数据 将空数据填充为该特征中其他不为空的数据的中位数 for column in list(feature.columns[feature.isnull().sum() &gt; 0]): val = feature[column].median() feature[column].fillna(val, inplace=True) 正则化数据 将数据集随机分为训练集和测试集（7：3） 特征抽取 基于决策树划分，得到权重最大的特征对应的序号 while 1: ...重新划分训练集和测试集 dtree=tree.DecisionTreeClassifier(splitter=\"random\",min_samples_leaf=3) dtree=dtree.fit(train_data,train_label) test_res=dtree.predict(test_data) sum=0 for i in range(test_label.size): if(test_label[i]==test_res[i]): sum+=1 if sum/test_label.size&gt;0.255: weight+=dtree.feature_importances_ t+=1 if t&gt;100: break max_indexs = heapq.nlargest(20, range(len(weight)), weight.take) 借助RFE划分 from sklearn.feature_selection import RFE from sklearn.linear_model import LinearRegression as LR linear_model=LR() s= RFE(linear_model, n_features_to_select=20, step=1).fit(Data, Label) Data = s.transform(Data) 线性回归在LogisticRegression中添加： def multi_fit(self,X,y): yi=np.zeros((6,y.size)) ### set yi theta=[] J=np.zeros(3000) for i in range(0,6): t,j,temp=self.fit(X,yi[i]) theta.append(t) J+=j return theta,J def multi_pred(self,X,multi_theta): m=X.shape[0] pre=[] X=np.hstack((np.ones((m,1)),X)) for i in range(0,6): theta=multi_theta[i] p=np.dot(X,theta) p=p.reshape(-1,1) pre.append(p) return pre 进行训练、预测、绘制图像 lr=LogisticRegression() theta,loss=lr.multi_fit(train_data,train_label) preds=lr.multi_pred(test_data,theta) test_r=[preds[0]+preds[1]+preds[2],preds[0]+preds[3]+preds[4],preds[1]+preds[3]+preds[5],preds[2]+preds[4]+preds[5]] x = np.arange(1,len(loss)+1) plt.plot(x,loss) plt.xlabel(u\"times\") plt.ylabel(u\"loss-value\") plt.show() sum=0 for i in range(test_label.size): for j in range(0,4): if test_label[i]==j: if test_r[j][i]&gt;=test_r[0][i] and test_r[j][i]&gt;=test_r[1][i] and test_r[j][i]&gt;=test_r[2][i] and test_r[j][i]&gt;=test_r[2][i]: sum+=1 sum/test_label.size 决策树调用sklearn.tree中的DecisionTreeClassifier实现： from sklearn import tree dtree=tree.DecisionTreeClassifier() dtree=dtree.fit(train_data,train_label) test_res=dtree.predict(test_data) 神经网络调用sklearn中的neural_network实现： from sklearn import neural_network as NN nn=NN.MLPClassifier() nn=nn.fit(train_data,train_label) test_res=nn.predict(test_data) SVM处理方式与线性回归的模型相似 XGBoost调用xgboost.sklearn库实现XGBoost xgb=XGB() xgb=xgb.fit(train_data,train_label) test_res=xgb.predict(test_data) 实验结果特征抽取 基于决策树进行特征选择 所有节点的权重数据:根据观察不难看出，不同特征的权重分布存在差距，大部分分布在0.8-1.0之间 RFE特征抽取 对RFE分别借助线性回归，SVM和随机森林的底层模型训练，发现线性回归训练时间较短，另外两个模型需要较长时间的训练，且这几类模型对训练结果的预测效果没有明显的影响，故选取线性回归模型进行RFE处理。 对特征的重要性进行排名，如下所示：筛选去前20个特征，进行后续训练和模型预测 模型训练结果五个模型最佳参数的训练结果： 模型 训练时间 准确率 LogisticRegression 15s 27.4% DecisionTree 0.4s 27.0% NeuralNetwork 2.3s 26.9% SVM 33s 26.3% XGBoost 4.5s 25.8% 总体来说，线性回归的训练效果较好，但几种模型均在较低准确率的较小范围内波动，并没有实现较好的结果。 对于不同的特征选择模型，甚至不进行特征选择，训练准确率的差距较小，在后续调参过程中不做区分。由于DecisionTree和NeuralNetwork模型的训练效果较好并且训练时间短，本次实验将重点分析该两类模型的调参效果。 逻辑回归迭代3000次，得到的损失函数如下所示： 该次训练结果准确率：26.8% 可以看出，模型训练的损失是逐渐递减至收敛的，但是损失的下降有限：从2.88下降到2.86，仅有2%的提升，说明逻辑回归无法较好的学习到模型哦那个的分布特征。 决策树使用GridSearchCV寻找最优参数： param = [{'criterion':['gini','entropy']}, {'criterion':['gini'],'max_depth':[3,5,6],'min_samples_leaf':[2,3,5],'min_impurity_decrease':[0.1,0.2,0.5]}, {'max_depth': [30,60,100], 'min_impurity_decrease':[0.1,0.2,0.5]}] grid = GridSearchCV(tree.DecisionTreeClassifier(),param_grid=param,cv=6) grid.fit(train_data,train_label) 得到的最优参数： 此时最优结果：26.8% 对参数max_depth取不同值统计准确率 重复几次即可发现，max_depth参数对准确率的影响的结果不明显，更多是随机的因素。（splitter=”random”） 同样，对于参数min_sample_leaf，也有类似的结果 神经网络一次训练过程中的损失率： 同样，使用GridSearchCV寻找最优参数： from sklearn.model_selection import GridSearchCV param = [{'hidden_layer_sizes':[(50,50),(30,30),(100, )],'alpha':[0.1,0.001,0.0001],'learning_rate_init':[0.1,0.005,0.001]}] grid = GridSearchCV(NN.MLPClassifier(),param_grid=param,cv=6) grid.fit(train_data,train_label) 此时的准确率为26.4% SVM实验中，该SVM模型采用梯度下降法实现。 此次训练的准确率：25.4% 由图可见，SVM模型的训练收敛速度较快，大约10次即可收敛，损失由8500下降到了3500，但是在测试集的准确率仍较低，说明SVM可能对训练集存在过拟合，也无法较好的学习到数据集中的数据。 XGBoost对应的参数和准确率： boost gamma max_depth max_delta_step 准确率 gblinear - - 0 25.6% gbtree 0 - 0 25.2% gbtree 0 3 0 25.7% gbtree 0.1 3 0 25.4% gbtree 0.1 3 1 25.8% gbtree 0 3 1 25.4% 可见，准确率最高的一组参数为：boost=’gbtree’,gamma=0.1,max_depth=3,max_delta_step=1 实验分析从实验结果的角度分析，本次实验的实验结果较不理想，训练效果最好的一组数据为借助RFE进行特征抽取，线性回归多分类模型（3000轮迭代），最终的准确率为27.4%，其他的模型均在26%上下浮动，对于四分类问题，这样的效果无疑是较差的，根本原因在于数据特征的抽取效果较差，例如本实验中采用了三种不同的模型来进行特征选择，每次选出的特征之间的重合率较低，并未找到真正有效的特征，学习器无法学到数据的分布特征，因此无论是后续调参还是更改模型，都无法得到较好的结果。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://sn1987a-1.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"编译原理-GVN","slug":"编译原理4","date":"2022-11-14T12:48:34.000Z","updated":"2023-09-24T05:30:05.756Z","comments":true,"path":"posts/7e7a9082.html","link":"","permalink":"http://sn1987a-1.github.io/posts/7e7a9082.html","excerpt":"","text":"思考题 请简述概念：支配性、严格支配性、直接支配性、支配边界。 支配性 在入口节点为b0的流图中，若bi在从b0到bj的所有路径中均出现，则称b1支配bj，其中Dom(bj)是所有支配bj的节点的集合 严格支配性 对于流图中给定的节点b，若节点$a\\in Dom(b)-b$,则称a严格支配b节点 直接支配性 对于流图中给定的节点b，严格支配b的节点集合为Dom(b)-b,在该集合中距离b最近的节点直接支配b，记为IDom(b) 支配边界 对于流图中给定的节点b，若节点a满足:(1)b支配a一个前驱q($q\\in preds(a),b\\in Dom(q)$)(2)b不严格支配a，将具有这种性质的a的集合记为b的支配边界DF(b) phi节点是SSA的关键特征，请简述phi节点的概念，以及引入phi节点的理由。 phi节点:出现在程序基本块汇合节点的对某一变量x进行一次新的定义，作为程序的一条指令，完成了将来自不同边的x的值进行合并的工作 引入理由:为了满足SSA的静态单赋值形式，沿着流图的不同路径，x的当前值可能被分配了一个唯一的名字，在多条路径的汇合处，不同的静态单赋值形式名必须调整为一个名字，phi节点的作用就是在路径汇合点将同一变量的多个形式名合并为一个名字。 观察下面给出的cminus程序对应的 LLVM IR，与开启Mem2Reg生成的LLVM IR对比，每条load, store指令发生了变化吗？变化或者没变化的原因是什么？请分类解释。 int globVar; int func(int x){ if(x &gt; 0){ x = 0; } return x; } int main(void){ int arr[10]; int b; globVar = 1; arr[5] = 999; b = 2333; func(b); func(globVar); return 0; } before Mem2Reg： @globVar = global i32 zeroinitializer declare void @neg_idx_except() define i32 @func(i32 %arg0) { label_entry: %op1 = alloca i32 store i32 %arg0, i32* %op1 %op2 = load i32, i32* %op1 %op3 = icmp sgt i32 %op2, 0 %op4 = zext i1 %op3 to i32 %op5 = icmp ne i32 %op4, 0 br i1 %op5, label %label6, label %label7 label6: ; preds = %label_entry store i32 0, i32* %op1 br label %label7 label7: ; preds = %label_entry, %label6 %op8 = load i32, i32* %op1 ret i32 %op8 } define i32 @main() { label_entry: %op0 = alloca [10 x i32] %op1 = alloca i32 store i32 1, i32* @globVar %op2 = icmp slt i32 5, 0 br i1 %op2, label %label3, label %label4 label3: ; preds = %label_entry call void @neg_idx_except() ret i32 0 label4: ; preds = %label_entry %op5 = getelementptr [10 x i32], [10 x i32]* %op0, i32 0, i32 5 store i32 999, i32* %op5 store i32 2333, i32* %op1 %op6 = load i32, i32* %op1 %op7 = call i32 @func(i32 %op6) %op8 = load i32, i32* @globVar %op9 = call i32 @func(i32 %op8) ret i32 0 } After Mem2Reg： @globVar = global i32 zeroinitializer declare void @neg_idx_except() define i32 @func(i32 %arg0) { label_entry: %op3 = icmp sgt i32 %arg0, 0 %op4 = zext i1 %op3 to i32 %op5 = icmp ne i32 %op4, 0 br i1 %op5, label %label6, label %label7 label6: ; preds = %label_entry br label %label7 label7: ; preds = %label_entry, %label6 %op9 = phi i32 [ %arg0, %label_entry ], [ 0, %label6 ] ret i32 %op9 } define i32 @main() { label_entry: %op0 = alloca [10 x i32] store i32 1, i32* @globVar %op2 = icmp slt i32 5, 0 br i1 %op2, label %label3, label %label4 label3: ; preds = %label_entry call void @neg_idx_except() ret i32 0 label4: ; preds = %label_entry %op5 = getelementptr [10 x i32], [10 x i32]* %op0, i32 0, i32 5 store i32 999, i32* %op5 %op7 = call i32 @func(i32 2333) %op8 = load i32, i32* @globVar %op9 = call i32 @func(i32 %op8) ret i32 0 } 删除的load/store: 第6，7行：程序中对变量x进行了多次赋值，在未开启Mem2Reg的IR中是通过冗余的访存实现的，在load语句前的程序块中已存在x对应的值，在删去该条load后，变量x不会被其他语句load，store语句也被删除，load和store是不必要的。 第13行：此处对x的值进行了存储，但是在该语句之后x并不是活跃变量，x的值不会被调用，因此该处的store是多余的。 第32，33行：程序中对变量b进行了赋值，又将b作为函数参数进行函数调用，函数调用时所用的值实际上就是立即数，是在该程序块中已存在对应的值，因此可以不用load，也无需store指令，此处可以删除load和store指令。 未变化的load/store: 第23行：此处store对全局变量globVar进行赋值，因为是用立即数更新数据的值，由于Mem2Reg不会对该全局变量进行处理，需要在此处存储变量的值，不存在冗余。 第31行：此处store对数组a中的元素利用立即数进行赋值，由于Mem2Reg不会对数组型元素进行处理，需要在此处存储变量的值，不存在冗余。 第35行：此处load将全局变量globVar的值赋给临时变量，用于后续函数调用作为函数的参数，且此前globVar对应的值在该块中不存在，不存在冗余，不需要删除。 指出放置phi节点的代码，并解释是如何使用支配树的信息的。（需要给出代码中的成员变量或成员函数名称） 放置伪代码的函数为src\\optimization\\Mem2Reg.cpp中的Mem2Reg::generate_phi函数。 step1：以基本块为单位，逐个遍历函数的所有指令，先找大活跃在多个基本块的变量及其对应的块，存储在live_var_2blocks中 step2：对于所有的变量，逐次遍历live_var_2blocks,在对应的dom集合bb_dominance_frontier_bb中依次寻找支配边界，如果在该基本块中未添加phi（bb_has_var_phi中不存在记录）,则插入phi：create_phi,在bb_dominance_frontier_bb中添加该语句，并在bb_has_var_phi中添加记录，防止重复添加。 算法是如何选择value(变量最新的值)来替换load指令的？（描述清楚对应变量与维护该变量的位置） 选择value来替换load指令的位置在src\\optimization\\Mem2Reg.cpp中的Mem2Reg::rename()函数。 对全局变量var_val_stack进行以下调用和维护： 第一次遍历基本块的所有指令：phi指令：根据插入的phi指令，将对应变量的最新定值的位置设为该phi语句 第二次遍历基本块中的所有指令：load指令：如果load的变量在var_val_stack中已经存在，则将该语句加入wait_delete，并维护对应的全局变量。store指令：将store存入内存的值作为最新定值 借助get_succ_basic_blocks补充因phi改动的var_val_stack对应的值 第三次遍历基本块中的所有指令：pop出var_val_stack中的最新定值 在第二次遍历中，对于load指令，如果load的变量在var_val_stack中已经存在，则将该语句加入wait_delete，并利用replace_all_use_with函数维护其他指令。最后将wait_delete进行删除，也就是删除load指令。 代码阅读总结此次实验的主要内容是熟悉代码优化的基础知识，了解SSA格式的IR的相关概念，并阅读了用来优化Lab3生成的IR指令的Mem2Reg相关代码,主要优化了冗余的load，store，alloca指令。主要收获是熟悉了支配节点，支配边界等概念，以及如何将这些概念用于代码优化，如何在程序中维护和利用这些属性来实现代码的优化。 PART2 实验要求本次实验要完成的目标是在lab4.1 SSA IR的基础上，根据实验框架完成对SSA IR基于数据流分析完成的GVN优化。 实验难点 根据LLVM IR的指令类型设计Expression子类的类型，并通过递归定义的方法定义值表达式，完成Value Expr 处理phi指令，构思设计copy stmt部分和intersect,ValuePhiFunc函数 实验设计实验思路ValueNumberGVN的核心就是建立全局值编号，本次实验中使用valueexpr作为值编号，每个等价类的valueexpr是唯一的。 为了解决可能存在的valueexpr相互依赖导致的无限递归的问题，将等价类运算符重载部分定义为： bool CongruenceClass::operator==(const CongruenceClass &amp;other) const { auto v1=value_expr_; auto v2=other.value_expr_; if(v2==nullptr&amp;&amp;v1==nullptr) return true; else if(v1==nullptr||v2==nullptr) return false; if(members_==other.members_) return true; return false; } 即，算法收敛的判断依据是根据等价类成员不再改变，而不是根据valueexpr的值不再改变，这样就可以避开valueexpr无限递归的情况。 为了获取一个变量的valueexpr，将getVN定义如下： 其中如果ve的表达式为SingleExpression的类型时，是在valueexpr寻找参数对应的值表达式时建立的Expression。 shared_ptr&lt;Expression&gt; GVN::getVN(const partitions &amp;pout, shared_ptr&lt;Expression&gt; ve) { if(ve==nullptr) return nullptr; auto sve=std::dynamic_pointer_cast&lt;SingleExpression&gt;(ve); if(sve!=nullptr) { auto num=dynamic_cast&lt;Constant*&gt;(sve-&gt;va()); if(num!=nullptr) return ConstantExpression::create(num); for(auto &amp;cc:pout) { if(cc-&gt;index_==0) return nullptr; for(auto &amp;mem:cc-&gt;members_) if(mem==sve-&gt;va()) return cc-&gt;value_expr_ ; } for(auto &amp;cc:pout) { if(cc-&gt;index_==0) return nullptr; if(*ve==*cc-&gt;value_expr_) return cc-&gt;value_expr_; } return nullptr; } valueexpr在Expression中新建若干子类，并完善对应的内部变量和创建，比较，打印等函数 Single Expression，存放非纯函数，load/store指令的value Constant Expression，常数 Binary Expression，二元指令的操作数和类型 Phi Expression，phi指令的操作数 Call Expression，函数调用指令的函数类型和和函数参数，仅考虑纯函数 Gep Expression，存gep指令的操作数 Cmp Expression，类型为icmp的指令的指令类型（cmp_op)和操作数 Fcmp Expression，类型为fcmp的指令的指令类型（cmp_op)和操作数 Trans Expression，类型转换的指令类型和操作数 根据指令类型的不同分别处理： phi指令：将在intersect中和transfer中处理，此处不会处理 void类型指令：此类指令不会被处理 call指令：若属于纯函数，找到参数的值表达式并建立CallExpression，否则新建一个SingleExpression类型的ve gep指令：类似于纯函数，找到各个参数对应的值表达式并建立GepExpression cmp,fcmp,binary,fp2si,si2fp,zext指令：找到参数对应的值表达式，进行常量传播，并建立对应的expression：CmpExpression,FcmpExpression,BinaryExpression,TransExpression 其他语句，新建SingleExpression作为值表达式 处理Phi由于Phi指令要作为Copy stmt加入每个基本块的前驱中，为了方便，可以在每个基本块指令遍历完后，遍历并处理该基本块后继中出现的phi指令，将后继块中的phi指令加入该基本块的等价类中。 Phi指令为四元指令，指令操作数依次为[op,label;op,label],此处可以通过get_name()获取label和bb的名字进行比对，如果相同，则借助transferFunction在该块等价类中添加该条语句。 auto succ=bb.get_succ_basic_blocks(); if(succ.size()&gt;0) for(auto s:succ) for(auto &amp;sinst:s-&gt;get_instructions()) if(sinst.is_phi()) { auto op0=sinst.get_operand(0); //op1/2/3=... if(op1-&gt;get_name()==bb.get_name()) pouts=GVN::transferFunction(&amp;sinst,op0,pouts); if(op3-&gt;get_name()==bb.get_name()) pouts=GVN::transferFunction(&amp;sinst,op2,pouts); } 为了处理存在了两个前驱块的基本块的pin，需要设计Join和intersect函数。 其中，Top块设计为只含有一个等价类，且等价类的索引为0的集合;Join函数遇到Top块时，规定Join(P, Top) = P = Join(Top, P)，否则逐个遍历等价类并调用intersect函数。 而对于Intersect函数，对于其他非phi语句，若members_存在交集，则必然有该两个等价类的值表达式一致，进行合并即可，否则合并得到的Ck为空；对于将出现在下一个基本块的（在上文中添加）的phi语句，就会存在members不为空且valueexpr不相等的情况，此时在Ck中根据Phi新建valueexpr和valuePhi语句，即可完成对Phi语句的处理。 for(auto i :Ci-&gt;members_) if(Cj-&gt;members_.find(i)!=Cj-&gt;members_.end()) { Ck-&gt;members_.insert(i); if(Ck-&gt;leader_==nullptr) Ck-&gt;leader_=i; } if(Ci-&gt;value_expr_==Cj-&gt;value_expr_) { Ck-&gt;value_expr_=Ci-&gt;value_expr_; Ck-&gt;value_phi_=Ci-&gt;value_phi_; Ck-&gt;leader_=Ci-&gt;leader_; } else if(Ck-&gt;members_.size()!=0) { Ck-&gt;value_phi_=PhiExpression::create(Ci-&gt;value_expr_,Cj-&gt;value_expr_); Ck-&gt;value_expr_=PhiExpression::create(Ci-&gt;value_expr_,Cj-&gt;value_expr_); } 此外，在valuePhiFunc函数中需要识别phi函数之间存在的冗余，函数思路如下： 只需要处理binary函数中的phi语句存在的冗余，并且该binary指令的lhs和rhs均为Phi类型，根据指令的值表达式即可进行上述类型判断，指令格式为bin(phi(vi1,vj1),phi(vi2,vj2)) 根据vi1,vi2,vj1,vj2(此时均为值表达式)创建新的二元表达式：c1=bin(vi1,vi2),c2=bin(vj1,vj2) 在该基本块的前驱块中找到c1,c2对应的值表达式，借助getVN实现，如果未找到对应的值表达式，则递归查找该前驱块的valuePhiFunc 如果找到对应的值表达式，借助两个值表达式新建phi指令并返回，否则返回nullptr transferFunctiontransferFunction函数的主要思路： 在已有等价类中判断该指令是否已存在，如果存在则删除，如果该指令在对应的等价类中作为leader出现，将重新指定leader 找到e对应的值表达式（getVN），如果找到，将x添加到对应的等价类集合中，（处理后继块phi语句的情况下可能会执行该步骤），返回pout 如果e为常数类，因为上文中未找到对应的等价类，将新建等价类，value_expr_即为该常数对应的常数表达式，添加到pout中并返回 调用valueexpr和valuePhifunc函数，找到对应的ve和vpf，并遍历已有等价类，如果已有等价类中存在该ve或vpf，即可在等价类中添加该成员，否则以该条指令为leader新建等价类，返回pout detectEquivalences在上述框架的基础上，完善detectequivalences函数： 不断深度优先遍历基本块，直到每个基本块的等价类集合不再改变 在label_entry位置处理函数参数，全局变量，对于这类参数直接新建等价类即可 对于每个基本块，如果包含多个前驱，调用join获取pin，否则直接将前驱块的等价类作为pin 遍历每条指令并调用transferFunction函数更改当前基本块等价类成员 访问当前基本块的后继基本块，处理phi函数 具体代码思路如下所示 for(auto &amp;bb:func_-&gt;get_basic_blocks()) if(&amp;bb==entry) continue; else pout_[&amp;bb]=clone(top); do next_value_number_=1; changed=false; for (auto &amp;bb : func_-&gt;get_basic_blocks()) partitions pouts={}; if(&amp;bb!=entry) if( bb.get_pre_basic_blocks().size()&gt;1) //use join() to deal with else for(auto s:predecessors) pouts=clone(pout_[s]); else //deal with func args and global var for(auto &amp;inst:bb.get_instructions()) if(!inst.is_void()&amp;&amp;!inst.is_phi()) pouts=GVN::transferFunction(&amp;inst,&amp;inst,pouts); //deal with phi instr if(pouts!=pout_[&amp;bb]) changed=true; pout_[&amp;bb]=std::move(pouts); while (changed); 常量传播常量传播/常量折叠是为了在编译时进行计算程序中存在的常数，如二元计算，cmp，类型转换指令，以便提供更多可优化的表达式，提高运行效率。只需要在两个地方处理：valueexpr部分和valuephifunc部分。 valueexpr部分：对binary，cmp，trans语句均进行常量传播： //二元 if(expr1-&gt;get_expr_type()==Expression::e_constant&amp;&amp;expr2-&gt;get_expr_type()==Expression:: e_constant) { auto e1=std::dynamic_pointer_cast&lt;ConstantExpression&gt;(expr1); auto e2=std::dynamic_pointer_cast&lt;ConstantExpression&gt;(expr2); auto expr=folder_-&gt;compute(instr,e1-&gt;get_c(),e2-&gt;get_c()); return ConstantExpression::create(expr); } //一元 if(ve-&gt;get_expr_type()==Expression::e_constant) { auto e=std::dynamic_pointer_cast&lt;ConstantExpression&gt;(ve); auto expr=folder_-&gt;compute(instr,e-&gt;get_c()); return ConstantExpression::create(expr); } 在valuePhiFunc中，只需处理对binary指令的常量传播，为了方便计算，在ConstFolder类中添加对compute的重载（参数为Instruction::opID,Constant,Constant\\) auto e1=std::dynamic_pointer_cast&lt;ConstantExpression&gt;(vi1); auto e2=std::dynamic_pointer_cast&lt;ConstantExpression&gt;(vi2); auto e=folder_-&gt;compute(opid,e1-&gt;get_c(),e2-&gt;get_c()); c1=ConstantExpression::create(e); 举例以bin.cminus为例，未开启代码优化时，生成的LLVM 代码如下： define i32 @main() { label_entry: %op0 = call i32 @input() %op1 = call i32 @input() %op2 = icmp sgt i32 %op0, %op1 %op3 = zext i1 %op2 to i32 %op4 = icmp ne i32 %op3, 0 br i1 %op4, label %label5, label %label14 label5: ; preds = %label_entry %op6 = add i32 33, 33 %op7 = add i32 44, 44 %op8 = add i32 %op6, %op7 br label %label9 label9: ; preds = %label5, %label14 %op10 = phi i32 [ %op8, %label5 ], [ %op17, %label14 ] %op11 = phi i32 [ %op7, %label5 ], [ %op16, %label14 ] %op12 = phi i32 [ %op6, %label5 ], [ %op15, %label14 ] call void @output(i32 %op10) %op13 = add i32 %op12, %op11 call void @output(i32 %op13) ret i32 0 label14: ; preds = %label_entry %op15 = add i32 55, 55 %op16 = add i32 66, 66 %op17 = add i32 %op15, %op16 br label %label9 } 开启代码优化后，最终生成的代码； define i32 @main() { label_entry: %op0 = call i32 @input() %op1 = call i32 @input() %op2 = icmp sgt i32 %op0, %op1 %op3 = zext i1 %op2 to i32 %op4 = icmp ne i32 %op3, 0 br i1 %op4, label %label5, label %label14 label5: ; preds = %label_entry %op6 = add i32 33, 33 %op7 = add i32 44, 44 %op8 = add i32 %op6, %op7 br label %label9 label9: ; preds = %label5, %label14 %op10 = phi i32 [ %op8, %label5 ], [ %op17, %label14 ] call void @output(i32 %op10) call void @output(i32 %op10) ret i32 0 label14: ; preds = %label_entry %op15 = add i32 55, 55 %op16 = add i32 66, 66 %op17 = add i32 %op15, %op16 br label %label9 } 其中，op13和op10等价，经过死代码删除，将删除计算op13与op11，op12的语句。 上述例子各个基本块的等价类如下所示： \"label_entry\": [[\"%op0\", ], [\"%op1\", ], [\"%op2\", ], [\"%op3\", ], [\"%op4\", ], ], \"label5\": [[\"%op0\", ], [\"%op1\", ], [\"%op2\", ], [\"%op3\", ], [\"%op4\", ], [\"%op6\", \"%op12\", ], [\"%op7\", \"%op11\", ], [\"%op8\", \"%op10\", ], ], \"label9\": [[\"%op0\", ], [\"%op1\", ], [\"%op2\", ], [\"%op3\", ], [\"%op4\", ], , [\"%op13\", \"%op10\", ], [\"%op11\", ], [\"%op12\", ], ], \"label14\": [[\"%op0\", ], [\"%op1\", ], [\"%op2\", ], [\"%op3\", ], [\"%op4\", ], [\"%op15\", \"%op12\", ], [\"%op16\", \"%op11\", ], [\"%op17\", \"%op10\", ],, ],}},] 思考题1.请简要分析你的算法复杂度 仅对程序的主要部分以指令为单位进行讨论，实验完成部分的代码由run()函数逐个分析每个函数，并进入detectEquivalences()函数，在detectEquivalences()函数中，对函数中的基本块不断进行遍历分析得到每个基本块的pin和pout等价类，直到pout收敛，代表该函数分析完成，一般来说，遍历的次数为一个较小的数（通常小于10），视为常数；而对于每个基本块，要依次遍历基本块中的指令，在transferfunction中完成对每个指令的分析，同时在等价类中遍历寻找值表达式或对应的值。 综上分析，对于一个程序，本实验算法的时间复杂度大约为$T(n)=O(n^2)$,其中n为指令条数 2.std::shared_ptr如果存在环形引用，则无法正确释放内存，你的 Expression 类是否存在 circular reference? 不存在。Expression的各个子类是递归定义的，其子类以及的构成方法如下： Single Expression，由一个Value *组成，用来处理特殊指令，如非纯函数，load,store指令等 Constant Expression，由一个Constant *组成 Binary Expression，由两个Expression和指令类型组成 Phi Expression，由两个Expression组成 Call Expression，由几个Expression和Function*组成 Gep Expression，由几个Expression组成 Cmp Expression，由两个Expression和指令类型组成 Fcmp Expression，由两个Expression和指令类型组成 Trans Expression，由一个Expression和指令类型组成 所有递归定义的Expression最终都会归结到Single Expression以及Constant Expression指令上，不会出现环形引用 3.尽管本次实验已经写了很多代码，但是在算法上和工程上仍然可以对 GVN 进行改进，请简述你的 GVN 实现可以改进的地方 本次实验ValuePhiFunc对Phi指令冗余的检测仅仅检测了Binaray指令的冗余情况，实际上可以扩大检测范围，并且增加检测冗余的形式，如检测phi(0, c+d)与 phi(0,c)+phi(0,d)，实现思路类似。 效率较低，对于规模较大的代码，GVN分析的效率会变慢，可以通过减少代码中不必要的遍历操作提高算法效率。 实验总结 本次实验基于论文《Detection of Redundant Expressions: A Complete and Polynomial-Time Algorithm in SSA 》基于数据流分析完成了SSA IR的GVN优化，通过动手实现和设计具体的算法，让我对数据流分析有了更清楚地认识 本次实验作为代码优化部分与前几次实验共同完成了Cminus的Compiler，对《编译原理与技术》一课的课程内容有了更清晰的整体认识。","categories":[{"name":"编译原理","slug":"编译原理","permalink":"http://sn1987a-1.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"编译原理-词法分析","slug":"编译原理1","date":"2022-09-25T12:48:34.000Z","updated":"2023-09-24T05:22:47.819Z","comments":true,"path":"posts/8254dc99.html","link":"","permalink":"http://sn1987a-1.github.io/posts/8254dc99.html","excerpt":"","text":"词法分析实验要求 完成基于flex的C-minus词法分析器 完成基于bison的C-minus语法分析器 实验难点 根据C-minus的词法使用正则表达式完成词法分析器 理解flex和bison的用法以及掌握flex，bison联动构建语法分析器的方法 正确构建C-minus的语法树 实验设计 正则匹配 正确匹配C-minus的所有token，以及注释，空格，换行等特殊字符，利用flex与token的名字关联起来（作为返回值），例如:\"if\" {pos_start = pos_end-1; pos_end ++; pass_node(yytext); return IF;},同时维护pos_start,pos_end，lines的值，表达式的顺序代表了匹配的优先级： 注释 \\/\\*(?:[^\\*]|\\*+[^\\/\\*])*\\*+\\/ 空格，制表符 \" \"|\\t 换行\\n 浮点数[0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+ 整形[0-9]+ 变量名 [a-zA-Z_]* 其他token \"if\" \"else\" \"while\" \"return\"\"void\" \"int\" \"float\" \"+\" \"-\" \"*\" \"/\" \"{\" \"}\" \"(\" \")\" \"[\" \"]\" \"&gt;=\" \"&gt;\" \"==\" \"&lt;=\" \"&lt;\" \"!=\" \"=\"\",\" \";\" token，type的数据类型 %union { struct _syntax_tree_node *node; } %token &lt;node&gt; ERROR ADD SUB IF ELSE WHILE RETURN INT %token &lt;node&gt;FLOAT VOID GE G E L LE NE MUX DIV DOT SEM %token &lt;node&gt;LEFT1 LEFT2 LEFT3 RIGHT1 RIGHT2 RIGHT3 ASS %token &lt;node&gt; INTEGER ID FLOATPOINT %type &lt;node&gt; program %type &lt;node&gt; type-specifier relop addop mulop %type &lt;node&gt; declaration-list declaration var-declaration fun-declaration %type &lt;node&gt; local-declarations compound-stmt statement-list statement expression-stmt %type &lt;node&gt; iteration-stmt selection-stmt return-stmt expression simple-expression %type &lt;node&gt; var additive-expression term factor integer float call %type &lt;node&gt; params param-list param args arg-list 构建语法树 利用bison根据C-minus的语法构建语法树，其中每个type都是语法树的非叶子节点，token都是语法树的叶子节点。例如： declaration-list: declaration-list declaration {$$=node(\"declaration-list\",2,$1,$2);} | declaration {$$=node(\"declaration-list\",1,$1);}; param-list: param-list DOT param {$$=node(\"param-list\",3,$1,$2,$3);} |param {$$=node(\"param-list\",1,$1);}; 实验结果验证 test测试样例 略 自行设计的样例 跨行注释和空行： /* This my testcase */ 输出：不在parser和lexer的分析中出现 数组定义 int y[2]输出| | | | | &gt;—+ var-declaration| | | | | | &gt;—+ type-specifier| | | | | | | &gt;— int| | | | | | &gt;— y| | | | | | &gt;— [| | | | | | &gt;— 2| | | | | | &gt;— ]| | | | | | &gt;— ; 循环 while (0) {y=0;} 输出| &gt;— while| &gt;— (| &gt;—+ expression| | &gt;—+ simple-expression| | | &gt;—+ additive-expression| | | | &gt;—+ term| | | | | &gt;—+ factor| | | | | | &gt;—+ integer| | | | | | | &gt;— 0| &gt;— )| &gt;—+ statement| | &gt;—+ compound-stmt| | | &gt;— {| | | &gt;—+ local-declarations| | | | &gt;— epsilon| | | &gt;—+ statement-list| | | | &gt;—+ statement-list| | | | | &gt;— epsilon| | | | &gt;—+ statement| | | | | &gt;—+ expression-stmt| | | | | | &gt;—+ expression| | | | | | | &gt;—+ var| | | | | | | | &gt;— y| | | | | | | &gt;— =| | | | | | | &gt;—+ expression| | | | | | | | &gt;—+ simple-expression| | | | | | | | | &gt;—+ additive-expression| | | | | | | | | | &gt;—+ term| | | | | | | | | | | &gt;—+ factor| | | | | | | | | | | | &gt;—+ integer| | | | | | | | | | | | | &gt;— 0| | | | | | &gt;— ;| | | &gt;— }","categories":[{"name":"编译原理","slug":"编译原理","permalink":"http://sn1987a-1.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"基于GPT-2的chatbot","slug":"chatbot","date":"2022-05-17T15:12:20.000Z","updated":"2023-09-23T13:14:31.422Z","comments":true,"path":"posts/156324.html","link":"","permalink":"http://sn1987a-1.github.io/posts/156324.html","excerpt":"","text":"chatbot设计该项目的仓库链接：https://github.com/Wonderful-Me/GPT-Chinese 信息爬取本部分通过网络爬虫实现了实时信息的获取，比如查询每日各个省份疫情的情况以及天气情况，微博热点新闻。在输入端输入对应的查询请求后，聊天机器人便可以伪装成浏览器访问对应的网站爬取数据并挑选出需要的数据并返回。 新冠疫情聊天人可以识别与“新冠疫情”相关的问题，自动爬取各个省份今日新冠疫情的新增情况，具体实现功能如下： 查询省份：可以对某个省份的疫情状况（新增确诊和新增无症状） 点击右下方链接即可跳转到相关网站查询详情 通过echarts柱状图显示各个省份的确诊情况，支持拖动和缩放 #alist 存储城市名，新增确诊和新增无症状 for i in citylist: if (i['today']['wzz_add'] == 0): clist.append([i['name'],i['today']['confirm'],0]) else: clist.append([i['name'], i['today']['confirm'], i['today']['wzz_add']]) 今日热搜聊天机器人可以识别与“今日热搜”相关的问题，自动爬取当前的微博热搜，具体功能如下： 返回当前热搜中热度最高的新闻资讯 点击热搜内容的文本即可跳转至热搜的链接了解详情 response = requests.get(\"https://weibo.com/ajax/side/hotSearch\") data_json = response.json()['data']['realtime'] for data_item in data_json: dic = {#微博词条的网址为'https://s.weibo.com/weibo?q=%23' + 词条名称 + '%23' 'title': data_item['note'], 'url': 'https://s.weibo.com/weibo?q=%23' + data_item['word'] + '%23', 'num': data_item['num'] } 天气查询聊天机器人可以识别与“今日天气”相关的问题，并且根据输入的城市爬取该城市的当日天气的详细情况。 #将输入的汉字用Pinyin转化为拼音字符串 city_pinyin=p.get_pinyin(sentence,'') #通过'https://www.tianqi.com/'+城市的拼音名即可访问目的城市天气 try: url = 'https://www.tianqi.com/'+city_pinyin r = urllib.request.Request(url=url, headers=headers) except urllib.error.URLError as e:#查找失败 return \"抱歉哈，找不到你所输入的城市\" #查找成功，利用beautifulsoup依次查找要找出的信息 weather.append(soup.select(...)[0].text) web前端聊天机器人的前端效果如下所示： 输入框每次按下按钮’发送’，且输入框不为空时，即可向机器人发送一条数据。 &lt;div class=\"b-footer\"&gt; &lt;input type=\"text\" name=\"text\" id=\"f-left\" placeholder=\"输入你想说的话...\"/&gt; &lt;div id=\"btn\"&gt;发送&lt;/div&gt; &lt;/div&gt; 对话框 发送完信息后，在对话框弹出该条文本，在机器人正在生成回答时显示加载动画 $(\".b-body\").append(\"&lt;div class='mWord'&gt;&lt;span&gt;&lt;img src=\\\"p1.png\\\" /&gt;&lt;/span&gt;&lt;p&gt;\" + text.val() + \"&lt;/p&gt;&lt;/div&gt;\"); //在对话框'b-body'中将输入信息以mWord的格式添加新的Div标签，内容包含输入的文本信息和头像图片 $(\".b-body\").append(\"&lt;div class='wait'&gt;&lt;span&gt;&lt;img src=\\\"p2.png\\\" /&gt;&lt;/span&gt; &lt;p&gt;&lt;/p&gt;&lt;div class='Ball'&gt;&lt;/div&gt;&lt;/div&gt;\"); //显示加载动画 $(\".b-body\").scrollTop(10000000); //将对话界面拉到页面最下方显示最新对话 机器人将回复信息返回前端 function(result) { $('.wait').remove();//删除加载动画标签 if(result[0]=='&lt;')//返回的内容为可以点击跳转的链接格式 $(\".b-body\").append(\"&lt;div class='rotWord'&gt;&lt;span&gt;&lt;img src=\\\"p.png\\\"/&gt;&lt;/span&gt; \" + result + \"&lt;/div&gt;\"); else//返回的内容为普通文本 $(\".b-body\").append(\"&lt;div class='rotWord'&gt;&lt;span&gt;&lt;img src=\\p.png\\\" /&gt;&lt;/span&gt; &lt;a id='member'&gt;\" + result + \"&lt;/a&gt;&lt;/div&gt;\"); $(\".b-body\").scrollTop(10000000); } 时间信息 每隔一分钟显示一次当前时间信息，如图所示： function setDate(){ d = new Date(); if (m != d.getMinutes()) {//m为已记录的时间信息，在对话时每分钟更新m，在对话框中显示当前时间 m = d.getMinutes(); $(\".b-body\").append('&lt;div class=\"timestamp\"&gt;' +'-------'+ d.getHours() + ':' + m +'-------'+ '&lt;/div&gt;');} } CSS渲染 静态渲染： 背景和文本框的渐变色 边框圆角效果 a对话框半透明效果 阴影效果 background: -webkit-linear-gradient(0, #xxx 0, ..., #xxx 100%);/*渐变效果*/ color: rgba(55, 55, 55, 0.3);/*0.3为透明度*/ border-radius: 15px;/*圆角效果*/ box-shadow: 10px -5px 20px 10px #xxx;/*阴影效果*/ 动态渲染 加载动画,循环播放三个跳动的点 .dot { /*基本属性*/ animation: pulse-outer 7.5s infinite ease-in-out;/*动画形式*/ } .dot:nth-child(2) {/*第二个点*/ left: 65px;/*偏移*/ animation: pulse-inner 7.5s infinite ease-in-out; animation-delay: 0.2s;/*动画延迟*/ } /*第三个点...*/ @keyframes pulse-outer { 0% { transform: scale(1); } ... 100% { height: 17.5px; } } 新消息弹出动画：在产生新对话时，对新弹出的文本框进行一次缩放，实现弹出的效果 .Word{ transform: scale(0); transform-origin: 0 0; animation: bounce 350ms linear both; } @keyframes bounce { 0%{transform:matrix3d(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1); } ... 100%{transform:matrix3d(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1); } } 动态LOGO：参考了Dribbble的模型 其他 echarts柱状图 利用了echarts模型，当询问新冠疫情的信息时，可以弹出如图所示柱状图，更直观地观察数据 动态跳转按钮 对于一些实时信息的查询，为了方便进一步了解详情，添加可以跳转的按钮 $(\"#btn2\").click(function() { if(is_ask==1)//正在查询信息 window.location.href=\"https://xxx\";//在新标签页打开链接 else location.reload([bForceGet]); //停留在原页面 }); 前后端交互聊天机器人前后端的信息交互和同步部分是通过Flask框架和Ajax（异步JavaScript和XML）实现的。数据交互的基本模式如下： Javascript部分: $(\"#btn\").click(function() { chatbot(); }); //每次检测到\"发送\"按钮按下且输入不为空时触发 function(){ var args= {url: \"url\",//与python函数对应的\"URL\"相同 type: \"GET\",//\"GET\"或\"POST\" //\"GET\"用于后端向前端发送信息,\"POST\"用于将输入的文字传到后端 success:function(result) {options();}} $.ajax(args); } python部分： @app.route('/url') def get_data(): data=func() return data @app.route('/') @app.route('/index') def index(): return render_template('index.html') //默认显示的主页 当用户在前端输入想要对机器人说的话，便可利用JS中的Ajax工具向后端传输数据，并获取后端发的数据返回到聊天框中，这样就完成了一组对话；另外，对于新冠疫情确诊柱状图的更新，也是通过Ajax将爬取到的数据传入JS的函数中完成的。","categories":[{"name":"CSII","slug":"CSII","permalink":"http://sn1987a-1.github.io/categories/CSII/"}],"tags":[{"name":"chatbot","slug":"chatbot","permalink":"http://sn1987a-1.github.io/tags/chatbot/"}]},{"title":"ChatBot","slug":"CSII","date":"2022-04-26T07:35:11.000Z","updated":"2023-09-23T13:14:52.332Z","comments":true,"path":"posts/26753.html","link":"","permalink":"http://sn1987a-1.github.io/posts/26753.html","excerpt":"","text":"the design of CHatBotsome resourcesGPT-2 中文文本生成 Re-Subject： 采用此组合为主要的参考内容，其他的为辅 https://github.com/yangjianxin1/GPT2-chitchat （近期也在开始琢磨这个项目） 使用指南见：GPT-2生成式多轮对话入门——-深入理解“用于中文闲聊的GPT2模型”项目_三重极简的博客-CSDN博客_gpt2 https://github.com/thu-coai/CDial-GPT【[论文](GPT.pdf)】 https://github.com/Morizeyao/GPT2-Chinese【信度高、体量大 / 相关面广，下辖可选项多】 hughqiu/GPT2-Chinese: Chinese version of GPT2 training code, using BERT or BPE tokenizer. (github.com) 【中意】 使用指南见：GPT-2中文文本训练及生成_是木子啦~的博客-CSDN博客_gpt2中文生成 数据集来源： 大规模中文自然语言处理语料 Large Scale Chinese Corpus for NLP (github.com) THUCTC: 一个高效的中文文本分类工具 (thunlp.org) the part I’m responsible forFront-end developmentuse HTML,css,js… there are several ideas I come up with. the basic chat frame the easy animination the loading animination(write a javascript function to generate a “div” when clicked and remove it after calculating) show time once a minute so on… it seems this part has been finished still need to combine it with others code the animination in the left is inspired by https://copepen.io patterned answersuse regular expressions or import jieba to deal with the input(jieba can deal the input in a loop) write a crawler to get the current information like the weather … import some database like wikipedia reference: https://github.com/brightmart/nlp_chinese_corpus#readme keep on learning…","categories":[{"name":"CSII","slug":"CSII","permalink":"http://sn1987a-1.github.io/categories/CSII/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"Knowledge Framework of OS PART II CH3","slug":"OS_notes2","date":"2022-03-07T07:35:11.000Z","updated":"2023-09-23T13:15:15.612Z","comments":true,"path":"posts/22413.html","link":"","permalink":"http://sn1987a-1.github.io/posts/22413.html","excerpt":"","text":"Part IIProcess Concept &amp; OperationsConcepts of Process the building of processing Pre-processor:like #define,#include —-try “gcc -E hello.c” Compiler and Optimizer compiler:Syntax checking and analyzing if no syntax:construct the intermediate codes i.e,assembly Optimizer :optimize the codes check the parameter of gcc Assembler and Linker assembler assembles hello.s and generate hello.o the linker puts together the objects files as well as library files compile multiple files? makefile What is a processprocess in memorya program is a program in execution a executable file load into mermory is Active process in memory : text section:program code stack heap data section program counter content of register process state a process executes changes states: new runnig waiting :for I/O ready—need CPU resources terminated the state diagram and the switch between graph LR A[new]--admitted--&gt;B[ready] C[wait]--I/O or event completion--&gt;B D[running]--interrupt--&gt;B D--I/O or event wait --&gt;C B--scheduler dispatch--&gt;D D--exit--&gt;E[terminated] PCB—process structureHow to locate /represent a process PCB:process control block or task control block program state program counter CPU registers CPU scheduling information memory-management information I/O status information Accouting informationprocess data structure in Linux represents by struct task_struct in C the relationship between program data&amp; PCB Conclusion on “what is a process” a program in execution only one process can be running on any processor at any instant two processes maybe associated with one program a process can be an execution environment for other codes. Process Operationsprocess:all the files,memory,accouting information a system must provide the mechanism for:process identification,process creation,process execution,process termination some basic system calls: getpid(),fork(),exec*(),wait(),exit() Process identification each process was given a unique id:process ID,PID use getpid() #include ‘.’:当前目录 use getpid()to check a program several times:get different PIDProcess creation a process may create several new processes parent process and chidren process the first process(the kernel runs when booting up)—-init PID=1,is running the program code “/sbin/init” the first task is to create more processes tree hierarchy all the process form a tree hierarchy program blossoming:command to view tree: “pstree” or “pstree -A”—-for ascii-character-only on display the termination can be happen at any time:the parent terminate before the children:turn a tree hierarchy to a forest(a process become a orphan) orphan process may make a difference…become a tree ,and when it terminate nobody will know? solve orphan process:re-parent operation the relationship between parent and children resource sharing options:all/subset/no execution options:execute concurrently/parent wait for children address space options:a duplicate of parent/a new program loaded into it to create :system call fork() printf(...getpid()..);fork;print(...getpid());:you will get three result(like 1234,1234,1235,not always cPID=pPID+1) the last print executed twice the fork():the parent and children executes the same codes,but not the same start:the children starts where the fork()is returned,the result of fork()will not loaded into children. the parent process will run first,using the same files like program counter and I/O devicesprogram execution fork( ) can only duplicate and run the same program——-use exec( ) execl( ) : a member of the exec() system call family(the family has 6 members),as an example example: …. execl(“/bin/ls”,”/bin/ls”,NULL);…. it means “ls”/or … execl(“/bin/ls”,”bin/ls”,”-l”,NULL) $1^{st}$ argument:the program name $2^{st}$ argument:the first argument to the program $3^{rd}$ argument:the second argument to the program $4^{th}$ argument:indicate the end of list of arguments the word after this function will not be executed anyway——-no new process will be created and the PCB will not change ,but the code will be replaced,it will run till meeting “exit()”,and will not return the former program ,losing many data as well note: fork() vs exec() fork()+exec()=?—(duplicate and then replace,the children will use exit(-1)to terminate)— write a system( ) library call——it will cause problem:the parents will first termination(actually cannot predict which will execute) fork()+exec() is not enough ,use system call fork()+exec()+wait(): “suspend the executions of parent process挂起父进程””wake the parent up after the childern is terminated唤醒” about wait() when to wake up: when one of the child processes changes from running to terminated does not suspend the calling process wait():usage: wait(NULL),has many cases while using case 1:the wait()system can suspend the calling parent process case 2: the parent will not suspend if there is no child process or there no running child process(still need time) more powerful wait?needs to wait for a particular child or detect child status changing(wait()can only waits for ant of the child and detect the status termination only) waitpid()—-read the man pages. program termination make a summarya process is created by cloning fork() :cloning is copying exec() wait()&amp;waitpid() the program exection is fundamental ,but not trivial:process is the place that hots a program and run it,and the exec*()changed the program the process is running,a process can run more than a program From Kernel Perspcetivedual modekernel-space &amp; user-space: kernel-space user-space stored what kernel data structure,kernel program,driven devices process memory,program code of the porcess accessed by whom kernel code user program &amp; kernel code a program will switch its execution from user mode and kernel mode (example : getpid() need to execute system call) user time &amp; system time user time : time spend on codes in user-space memory system time : time spend on codes in kernel-space memory total tunning time:user time + kernel time use tool: time(time ./filename): total/user/sys time the system callfork()fork behaved like cell division it create the child process by “cloning” form the parent process,including: program counter :CPU register ，that is why they both execute from the same line of code after fork() returns Program code memeory opened files(kernel’s internal) does not clone: PID return value of fork() parent process running time:just created ,is 0 action: the start—kernel-space update—user-mode update —-finish kernel-space updates: the running time will reset to 0 update pid the paretnt will have a new child and the child will have a pointer to its parent. user -space update: copying… array of opened files : array index: 0— standard of input stream :file *stdin 1— standard of output stream :file *stdout 2— standard error stream:file *stderr 3/beyond— storing the file you opened,e.g,fopen(),open,etc that’s why the parents process shares the same terminal output system with the child process exec*()action:start,end process itself does not change user-space memory: local veriable,dynamically-allocated memory will be cleared,and the global variable will reset based on new code,code + constant will changed to new program code (**)wait() \\&amp;exit()exit()——child side : not really remove the child process ,remain the entry of the child in the process table(template state) The child is now called zombie. Its storage in the kernel-space memory is kept to a minimum The PID (1235 in this example) and process structure are owned by the child. wake up the parent: The kernel notifies the parent of the child process about the termination of its child. The notification is a signal called SIGCHLD. signal: • What is signal? – A software interrupt – It takes steps as in the hardware interrupt • Two kinds of signals – Generated from user space • Ctrl+C, kill() system call, etc. – Generated from kernel and CPU • Segmentation fault (SIGSEGV), Floating point exception (SIGFPE), child process termination (SIGCHLD), etc. • Signal is very hard to master, will be skipped in this course – Reference: Advanced Programming Environment in UNIX – Linux manpage summary exit() Step (1) Clean up most of the allocated kernel-space memory. Step (2) Clean up all user-space memory. Step (3) Notify the parent with SIGCHLD Although the child is still in the system, it is no longer running. There is no program code!!! It turns into a mindless zombie… wait()——parent side: see the SIGCHLD signal and handle it. The kernel sets a signal handling routine (and it is a function pointer) to the process. That signal handling routine will be executed when SIGCHLD comes. By default, every process does not respond to the SIGCHLD signal (the signal handlers are set only when wait() is called). When SIGCHLD comes, the signal handling routine is invoked! Note: since the parent is still inside the system call, instead of the original program code, the parent process is still blocked in some sense… Default Handling of SIGCHLD Accept and remove the SIGCHLD; Destroy the child process that sends her the signal. case 2-—the wait() is called after the child already termintated,which is safe in case 2,the SIGCHlD is also sent to parent before,and when the wait() is called ,it can return and kill the child process completely. short summary of exit() &amp;wait() A process is turned into a zombie when… The process calls exit(). The process returns from main(). The process terminates abnormally. You know, the kernel knows that the process is terminated abnormally. Hence, the kernel invokes exit() by itself. Remember why exec*() does not return to its calling process in previous example… wait() is to reap zombie child processes You should never leave any zombies in the system. Linux will label zombie processes as &lt;defunct&gt;. To look for them:ps aux | grep defunct Learn waitpid() by yourself…? If a orphan does not have a parent wait() when terminate—may init a new parent . the role of wait() in the OS: Why calling wait() is important – It is not about process execution/suspension… – It is about system resource management. Think about it: – A zombie takes up a PID; – The total number of PIDs are limited; • Read the limit: “cat /proc/sys/kernel/pid_max” – What will happen if we don’t clean up the zombies? summaryconcepts: process data &amp; memoty PCB+ user-space mermory operations fork() exec*() wait()+exit()——come together , calling wait() is imporrtant so..what is the kernel doing?… ThreadsThreadMotivation of Multi-Threading and ConceptsThread concepts:why use , structure in memory, benefits and challenge, thread models Progreamming :Basic programming;implicit threading motivation: application side:most software applications are multithreaded,each application is implemented as a process with several threads of control.(web browser or wiord processor) still remember what kind of data are include in a process: text data,statck,heap inuser-space memory PCB in kernel-space memory system side:modern computers usually contain multicores,but each processor can run only one process ata time,so to improve the efficiency: assign one task to each core real parallelism the process cannot visit another process’s data and memory concurrency vs. parallelism internalsCode: all the threads use the same code. a thread starts with onr specfic function——named it the thread function a thread function can invoke other functions or system calls a thread could never return to the caller of the thread function Global variables: all thread share the same global variable zone and the same dynamically allocated memory all thread can read from and write to Local variables: each therad has its own memory range for local variable so the stack is a private zone Benefits allow an application to do parallel tasks simulaneously ease in data sharing peocess share resources via shared memory or message passing Economy allocation memory and resources for process creations is costly ,dozens of time tha creation threads… context-switch between processes is also costly,several times of slower Scalablilty: thread may be running in parallel on different cores programming challenges indentifying tasks: divide seperate and concurrent tasks balance: tasks should perform equal work of equal value data splitting: data must be divided to run on seperate cores tdata dependency:synchronization is needed testing and debugging Thread modelsthread should include : data/resources in user-space memory structure in kernel provide thread support: user thread: implement in user space kernel thread: supported and managed by kernel 1.many-to-one models :(many in user space and one in kernel) all the threads are mapped to one process structure in the kernel easy for the kernel to implement drawback:when a blocking system call is called ,all the thread will be blocked old UNIX &amp; green thread 2.one-to-one each thread is mapped to one process structure in the kernel a high degree of concurrency drawback: cannot create too many threads as it is restricted by the size of the kernel memory most Linux and Windows a process ,without multi-threading,is actually one thread for the scheduler.(when the schduler interets in process / thread) 3.many-to-many model avoid drawbacks in many-to-one and one-to-one——cannot be blocked , have a high degree of concurrency but most OS does not use man-to-many model(the drawback of one-to-one is not fatal) Basic ProgrammingThread library——-provide the programmer with an API for creating and managing threads. three main library threadings: POSIX Pthreads(user level or kernel level) Windows (kernel level) Java(implements using Windows API or Pthreads) creating multipule threadsasynchronous threading parent resumes execution after creating a child parent and child executes concurrency each thread run independently synchronous threading fork-join strategy : parents wait for children to terminate significant data sharing Pthreads: process is similar to thread process thread creation fork() pthread_create() I.D. type PID,an integer “pthread_t”,a structure who am i? getpid() pthread_self() wait for the child termination wait() or waitpid() pthread_join() terminaion exit() pthread_exit() kill? kill() pthread_kill() issue 1:create thread int main(void) pthread_t tid; pthread_create(&amp;tid,NULL,hello,\"hello world\");//函数名和函数需要的参数 pthread_join(tid,NULL); return 0; } void *hello (void * input) { printf(\"%s\",(char*)input); pthread_exit(NULL); } issue 2: passing parameter: local variable can be changed —-the stack of the new thread is on the same piece of the user-space memory as the main thread,not a new process,the pthread_create only create an address to the new thread ,the address is a pointer pointing to a variable stack of the main thread. issue 3:multiple threads: pthread_t tid[5]; for(i=0;i&lt;5;i++) pthread_create(tid[i],NULL,xxx,xxx); for(i=0;i&lt;5;i++) pthread_join(tid[i],NULL); issue 4: return value—-thread termination ,passing return value. void do_your_job(void *input){ ... *output=.....; pthread_exit(output); } ... pthread_join(tid,(void**)output); other threading — windows thread or java threads. Implicit Threading applications are containing hundreds or even thousands of threads program correctness is more difficult with explicit threads how to address the programming difficulties? transfer the creation and managements of the threadings from programmers to compliers and run-time libraries implicit threading two methods 1.thread pools 2.OpenMP !!!thread poolsproblem with multithreaded servers time required to create threads,which will be discarded once completed their work unlimited threads could exhaust the system resources solve: thread pool idea:create a number of threads in a pool where they wait for a work procedure: awaken a thread if necessary returns to the pool after completion wait until one becomes free if the pools cpntains no available thread advantages usually sightly faster to service a request with an existing thread than create a new thread allow the number of threads in the applications to be bound to the size of the pool OpenMPprovides supports for parallel programming in shared-memory environments set of compliers directives and an API for C,C++,FORTRAN Threading Issuessemantics of fork() and exec()1.fork():some UNIX has two versions: the new process duplicates all threads duplicates only the thread that invokes fork() exec(): usually work as normal: replace the running process ,includind all threads 2.signal handling signals are used in UNIX systems to notify a process that a particular event has occurred asnychronous signal and synchronous signal default handler or user-defined handler where should a signal be delivered in multi-thread program? to the thread signal applies all the threads a certain thread assign a specific thread to receive all the signals of all the threads deliver a signal to specific thread to receive all the signals for the process 3.thread cancellation terminating a thread before it has finished two genernal approaches: asynchronous cancellation terminates the target thread immediately problem:troublesome then updating data defferred cancellation:allow the target thread to periodically check if it should be cancelled(can be cancelled safely) three models: asynchronous,defferred,off(disabled cancellation) default : defferred 4.thread-local storage some applications ,each threads may needs its own copy of certain data. thread-local stroage:TLS TLS is visible across function invocations similar to static data TLS data are untique to each thread summary of thread virtually all morden OSes support multi-threading a thread is a basic unit of the CPU utilization each comprises a thread ID,a program counter,a,register set,a stack all the threads within a process share code section ,data,section,other resources like openfiles and signals take great care when writing multi-threaded programs,and also— mutual exclusion synchronization Process communication &amp; Synchronizationthe processes within a system may be independent cooperating any process that shares the data is a cooperating process interprocess communication —-IPCtwo models: shared memory message passing IPC is used for exchanging data between processes cooperating processes need IPC for exchanging data two nodels： shared memory establish a shared memory region,read/write to share region accesses are treated as routine memory accesses faster producer-consumer problem a buffer os needed to allow processes to run concurrently the requirement: a buffer is a shared object,and is a queue problem: when producer wants to put anew item but the buffer is already full solution: the producer need to suepended ,and the consumer should wake the producer up after it has dequeue an item problem: when comsumer wants to dequeue an item but it is empty solution: the consumer is suspended and the producer should wake the cinsumer up… a producer process produces a unit of data ,and writes that a piece of data to the tail of the buffer a consumer process removes a unit of data from the head of the bounded buffer at one time message passingneed a message queue to exchange communictating processes may reside on different computer conntected by a network IPC provide : send+receive exchange message require kernel intervention easier to implement in a distributed system if two process wish to communicate,they need: establish a communication link between exchange messages via send/receive issues: naming: direct/indirect direct: opreations: send and receive properties of indirect communication allow a link to be associated with at most two processes allow one process at a time to execute a receive opreation allow the system to select arbitrarily the receiver ,and sender is notified who the receiver is the mailbox is owned by the process (ownership may be passed)and the OS(neede a method to create ,send/receive.delete) synchronization : synchronous— blocking/asynchronous— non- blocking dofferent combinations :1.when the send and the receive are blocking , we have a rendezvous between the processes; 2. other conbinations need buffering buffering messages reside in a temporary queue , whic can be implemented in three ways: zero capacity—no message qre queued, sender must wait for the receiver(no buffering) bounded capacity — finite length of n mesages,sender must wait if link is full undounded capacity - infinite length,sender never waits POSIX shared memoryPOSIX shared memory is orgranized using memory-mapped file,associate the region of shared memory with a file. illustrate wth the producer-consumer problem: producer create a shared memory object shm_fd=shm_open (name,O_CREAT |O_RDWR,0666);(perminssions ) configure object size ftruncate(shm_fd,SIZE); establish a memory-mapped file containing the object prtr mmap(0,SIZE,PORT_WRITE),MAP_SHARED,shm_fd,0);(changes to the shared-memory object) consumer open the shared-memory obect shm_fd=shm_open(name,O_RDONLY,0666); memory map the object ptr=mmap(0,SIZE,PORT_READ,MAP_SHARED,shm_fd,0); remove the shared memory object shp_unlink(name); Socketsa sockets is defined as an endpointer for communication(over a network) a pair of processes employ a pair of sockets a socker is indentified by an IP address and a port number all ports below 1024 are used for standard services telnet server listens to port 23 FTP server:port 21 HTTP server :port 80 Socket uses a client-server architecture server waits for incoming client request by listening to a specific port accepts a connection from the client socket to complete the connection all connection must be unique(establishing a new connection on the same host needs another port&gt;1024) special IP address 127.0.0.1(loopback)refers to itself PipesPipe ia a shared memory using pipes is a way to realize IPC acts as a conduit two processes to communicate issues : communication: unidirectional/bidirectional half/full duplex must the relationship exists between the communicating processes pipes used over a network two common pipes: ordinary pipes and named pipes ordinary pipes no name in file system only used for related process(parent-child relationship) unidirectional ceases to exit after communication has finished allow communication in standard producer-consumer style producer write to one end and the consumer reads from the other end UNIX pipe UNIX treats a pipe as a special file (child inherits it from parent) create : pipe(int fd[]);fd[0]-read end,fd[1]-write end create accesses the ordinary read(),write()system calls fork() duplicates parent’s file descriptors,and parents and child use each end of the pipe pipes are anonymous named pipes UNIX treats as typical file:mkfifo(), open(), read (), write(),close() no parent-child relaitionship is necessary(or processes must reside one the same machine) several processes can use the named pipes for communication continue to exist communication is bidiectional(still half-duplex) 课程主页 主观题规范：逻辑/语言规范","categories":[{"name":"OS","slug":"OS","permalink":"http://sn1987a-1.github.io/categories/OS/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"Knowledge Framework of OS PART I CH1&CH2","slug":"OS_notes","date":"2022-02-28T14:52:11.000Z","updated":"2023-09-23T13:15:19.112Z","comments":true,"path":"posts/28913.html","link":"","permalink":"http://sn1987a-1.github.io/posts/28913.html","excerpt":"","text":"Knowledge Framework of OS :PART I CH1&amp;CH2textbook: Operating System Concepts 10th Edition check course home : http://staff.ustc.edu.cn/~ykli/os2022 ch1 Overview of an Operating Systemsystem organizationcomputer-system organization One or more CPUs, device controllers connect through common bus providing access to shared memory Concurrent execution of CPUs and devices competing for memory cycles I/O devices and the CPU can execute concurrently Each device controller is in charge of a particular device type Each device controller has a local buffer CPU moves data from/to main memory to/from local buffers Device controller informs CPU that it has finished its operation by causing an interrupt computer start-up bootstrap program (启动程序)is loaded at power-up or reboot (firmware) System processes or system daemons After fully booted, waits for events to occur – Signaled by interrupt interrupt handling :can be triggered by hardware and software: Hardware sends signal to CPU Software executes a special operation:system call procedure :CPU stop-&gt;executes the service routine-&gt;CPU resumes operating system is interrupt driven interrupt architecture must save the address of the interrupted instruction interrupt timeline: Interrupt transfers control to the interrupt service routine . A table of pointers to interrupt routines, the interrupt vector,can be used to provide necessary speed .The table of pointers is stored in low memory. Storage Structure Main memory :random access,typically small size and volatile(易失性) Instruction-execution cycle 1.Fetch an instruction from memory and store in register – Decode instruction (fetch operands if necessary) 2. Store result back to memory Secondary storage – extension of main memory that provides large nonvolatile storage capacity (like heard disks ,solid-state disks—faster and nonvolatile) caching—small ,important principle,in hardware ,opearting system,software. I/O structure:interrupt driven Direct Memory Access Structure:Device controller transfers blocks of data from buffer storage directly to main memory without CPU intervention,one interrupt per block System Architecture(处理器)CPU—most use a single general-purpose processor Multiprocessors system:parallel systems,multicore systems, advances:Increased throughput;Economy of scale;Increased reliability two types: SMP:symmetric multiprocessing,all processors are peers AM:asymmetric multiprocessing,boss-worker relationship Multicore:: include multiple cores on a single chip .More efficient and less power distinguish:multicore &amp;SMP,multicore is more efficient but costs more. Clustered Systems:multiple systems working together ​ -SAN:storage-area network ​ -some are HPC:high-performance computing ​ -DLM:distributed lock manager,to avoid conflicting So… Where is the OS? Four components of a computer system – Hardware – provides basic computing resources (CPU, memory, I/O devices) – Users: People, machines, other computers – App. programs – define the ways in which the sys. resources are used to solve the computing problems ​ • Word processors, compilers, web browsers, database systems, video games, etc. – Operating system ​ • Controls and coordinates use of hardware among various applications and users What is the OS? •It stands between the hardware and the user. – A program that acts as an intermediary between a user of a computer and the computer hardware • Operating system goals: – Execute user programs &amp; make solving user problems easier – Make the computer system convenient to use – Use the computer hardware in an efficient manner – Design tradeoff between convenient and efficiency • How good is this design? – The user does not have to program the hardware directly • Processes as the starting point! – Whatever programs you run, you create processes. ​ • i.e., you need processes to open files, utilize system memory, listen to music, etc. – So, process lifecycle, process management, and other related issues are essential topics of this course What Operating Systems Do? system view control program resource alocator User view wanr convenience in use and performance usability ,battery life, resource utilization,tradeoff… well..OS has no universalyy accepted defination Operating Systems OperationsOS Operationscontrol programs/resource allocator Mutliprogramming:needed for efficiency,job run via job scheduling Time sharing,分时操作系统,logical extension in which CPU switches jobs so frequently that users can interact with each job while it is running, creating interactive computing allow many user to share the computer issues:– If several jobs ready to run at the same time:CPU scheduling . If processes don’t fit in memory, swapping moves them in and out to run . Virtual memory allows execution of processes not completely in memory Interrupt Driven Mechanism (in Multiprogramming)software and hardware Hardware interrupt by one of the devices software :(exception or trap),needed to request for opaerating system service Dual-mode Operation多模式操作 user mode or kernel mode,and transistion between them system callsystem call is similar to a function call ,but it is inside the OS,named OS kernel System calls are the programming interface between processes and the OS kernel System calls provide the means for a user program to ask the operating system to perform tasks A system call usually takes the form of a trap to a specific location in the interrupt vector, treated by the hardware as a software interrupt The system call service routine is a part of the OS usually primitive,important,fundamental(like time()system call) Roughly speaking, we can categorize system calls as follows: | Process | FileSystem | Memory || ———— | ————— | ——— || Security | Device | | distinguish between system call and library function call(library file:in windows :DLL dynameically linked library ,in Linux SO,shared objects) OS standards: ProcessProcess vs ProgramA process is an execution instance of a program,a process is not bounded to execute just one program.A process is active and has its own local states command about processes like ps—report a vast amount of information about every process in system(try ps -ef) shell—-a process launching pad System has many processes, some user, some operating system running concurrently Memory Java don’t have the above layout,and C is too low Storage ManagementFile System,FS like FAT16, FAT32, NTFS, Ext3, Ext4, BtrFS a FS must record :directories,files,allocated,space,free space Two face of a file system:1.storage design of the file system.(how it stored)2.the opreations of the file systems operations:creating can be replaced by opening;copying can be replaced by read and write;moving can be replaced by rename(in one disks),so the necessary operations are open,read,write,close,rename,delete,.. A FS is independent of an OS,an OS can use many FS Kernal Data StructuresLists,Trees,Hash Map and Bitmaps MISCProtection and Security this course will discuss the security of File System Computing Environments trandition to mobile:IOS ,Android Distributed computing ,like networkTCP/IP Client-Server(C-S computing) Peer-to-Peer computing—去中心化 Virtualization Cloud Computing (较成熟) Real-Time Embedded Systems Open-sourced OS Open-Source Operating Systems—-GNU LINUX,BSD UNIX(including mac OS) summary OS Overview OS Concept Multiprogramming &amp; Multitasking Dual Mode &amp; System Call OS Components Process Management Memory Management Storage Management Computer System Organization &amp; Architecture Interrupt ch2 Operating System StructuresOperating System Services common classes :Convenience of the user and Efficiency of the system Operating systems provide an environment for execution of programs and services to programs and users User Operating System Interfaceexecution:1.Load a program into memory 2.run the program3.end execution(normally or abnormally) for Helping Users I/O operations File-system manipulation communications implementations:(shared memory and Message passing) error detection,error types error handlingfor Ensuring Efficiency for ensuring efficiency resource allocation accounting—to keep track of usage (usage statistics) the protection and security for Helping Users user interface(UI) form: CLI(command line),Batch,GUI(Graphics User Interface) CLI:shells,two ways of implementing commands: 1.The command interpreter itself contains the code • Jump to a section of its code &amp; make appropriate system call • Number of commands determines the size of CLI 2.Implements commands through system program (UNIX) • CLI does not understand the command • Use the command to identify a file to be loaded into memory and executed • Exp: rm file.txt (search for file rm, load into memory and exe w/ file.txt) • Add new commands easily touchsreen interface…virtual keyboard?voice command System CallsProgramming interface to the service provided by the OS Each OS ha its own Program Call System Call &amp;&amp; function Why us API? for System Call,a simple program like copy may make heavy use of OS,and not user friendly Mostly accessed by programs via a high-level API rather than direct system call use,and is easy of use(Simple programs may make heavy use of the OS)Program portability(Compile and run on any system that supports the same API ) remember the logic relationship between API and Program calls API:application programming interface common APIs:Win32 API for Windows,POSIX API,JAVA API(JAM,java virtual machine) How to use API? 1.via a library of code provided by OS2.Libc:UNIX/Linux with a C language API-System Call-OS relationship Type of System Call Process COntrol example: MS_DOS File Manipulation Device Manipulation Information Maintenance Communications Protection Operating System Structure掌握优势和问题，不需要记住例子 simple structure :MS_DOS Monolothic Structure :UNIX limited structing beyond simple but not fully layered Layered Approach not efficient Microkernel System Structure Modules Hybrid System:combine different systems structure Examples:Linux,Windows,Mac OS X structure,IOS,Android… Operating System Design and Implementation… is not solvable first problem :design goals and specifications improtant principle to separate(Mechanism for how to do and policy for what will be done）Examples (Timer Mechanism for CPU protection and Priority Mechanism in job scheduling) benefits:maximum flexbility OS implementation much variation,earily in ass,now in C/C++ Acutually use a mix of language(body in C,lower levels in ass,system programs in C/C++,scripting language) pros and cons MISC:Debugging,Generation &amp;System Bootdebugging like GDB failure analysis:log files,core dump,crash dump performance tuning: trace list of the system behavior &amp; interactive tools(top displays the resources of usage processes) Kernighan’s LAW:”Debug is twice as hard as writing the code in the first place.Therefore,if you write the code as cleverly as possible,you are ,by defination,not smart to debug it.” Operation system Generation—-OS is designed to run on any of a class of machines the system must be configured or generate for each specific computer site SYSGEN program:it obtains the information concerning the specfic configuration of the hardware system system boot system booting on most computer systems common bootstrap loader allows selection of kernel from multipule disks,versions,kernel options Summary of part I :ch1&amp;ch2 operating system overview ——multiprogramming &amp; multitasking OS operations:system call &amp; dual mode OS components computing environment OS structure process managements memory managements storage managements","categories":[{"name":"OS","slug":"OS","permalink":"http://sn1987a-1.github.io/categories/OS/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"以git-ftp为主的学习记录","slug":"git-ftp","date":"2022-02-27T07:46:11.000Z","updated":"2023-09-23T13:15:41.582Z","comments":true,"path":"posts/15203.html","link":"","permalink":"http://sn1987a-1.github.io/posts/15203.html","excerpt":"","text":"以git-ftp为主的学习记录 原本的目的是美化个人FTP主页（之前都是用FileZilla进行课程pdf文件等的传输，看到同学的个人主页后突然意识到也可以利用hexo完成相关功能，虽说没什么用，但也记录一下学习的过程。 ……遇到了好多问题&gt; _ &lt;尚未完成 操作环境：win11 wsl2+Ubuntu 20.04 LTS,USTC ftp（默认首页为public_html下的index.html文件 git-ftp关联优点：便于管理ftp 在github中创建名为git-ftp的repo后，使用git clone操作克隆到本地（或者可以在本地进行git init操作，创建.git文件，使用git remote操作与远程链接； 因为2021年8月13起github不允许在git操作时进行登录确认，因此要提前配置好： git config --global user.name YOURNAME git config --global user.email YOUREMAIL 要使用git-ftp的功能，需要先安装git-ftp：（确保git已经安装）sudo apt-get install git-ftp 此外，要进行ftp的config操作： git config git-ftp.url ftp-url git config git-ftp.user ftp-user git config git-ftp.password pswd 若想对以上内容进行查看，可以在本仓库.git目录进行查看和修改 [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [git-ftp] password = pswd user = name url = ftp-url [remote \"origin\"] #后序添加完可以查看url和fetch内容 对于git-ftp的相关操作，可以阅读 官方文档 。 之后可以对该目录进行初始化:git ftp init,或者对已存在的文件进行git catchup操作。 之后常用的操作就是git ftp push.顺便提一句，可能会遇到“Dirty repository :Having uncommited changes.Exiting…”的问题，就要先进行git add .,git commit ..,git push的操作。 此时仍无法进行git ftp push的操作，因为这一操作需要安装lftp：sudo apt-get install lftp,安装后即可使用。 hexo搭建为了防止hexo操作将其他文件一并删除，此处可以新建一个文件夹存储hexo框架：hexo init page,打开目录底下的_config.yml进行修改，并且将deploy进行修改：(对生成的public_dir文件的位置大概也需要改) PS:对于_config.yml的内容修改，可以不需要重新进行hexo g deploy: type: ftpsync host: # ftp服务器地址 user: # ftp用户名 pass: # 你的ftp用户密码 remote: # 你要上传到的地址，例如/wwwroot port: # ftp端口，不同的ftp可能会不一样 delete: true # 上传本地文件是否删除ftp中的所有文件 verbose: true # 是否打印调试信息 ignore_errors: false # 是否忽略错误 大部分的操作为hexo的常规操作，但与利用域名搭建的hexo博客不同，这里需要安装插件： npm install hexo-deployer-ftpsync –save 这里还有一个问题，hexo d后，我的原本存在public_html底下的文件被删除？ 如果使用git clone安装了新主题，如此次安装了”Archer”主题，若hexo版本在4.0.0以上，需要将/themes/Archer目录下的_config.yml重命名为 _config.archer.yml，并移动到根目录，同时，因为使用的是git clone操作， 会将原repo的.git文件clone到本地，默认为与原repo关联，这个repo我们是没有权限进行修改的，相对于两个git项目进行了嵌套，外层无法update内部的repo，这时在根目录下进行git add .或者git add all操作均是无法将Archer文件的内容进行push的，也就无法进行git ftp push操作，解决方法就是利用git remote remove操作取消内部的git关联。 遇到的琐事使用hexo操作时 ，发生对于Yaml的报错提示，从StackOverflow得知需要更新npm版本，遂进行更新，使用npm install -g npm时，又发生报错，大致意思为可以检测到新版本但是当前的node.js不兼容新版本，无法完成更新，而且此项更新未完成时，可能会对于npm安装其他的插件有影响。 google了半天，终于搞清楚了： 我在一开始安装npm时未安装nvm，二者的关系是：npm时node.js的包管理工具，nvm是node.js的版本管理工具，二者均是node.js应用程序开发的工具，因此要更新Node.js到最近版本，需要先安装nvm，$ wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | sh,其中sh可以替换成shell的具体名称，如我的就是zsh，默认为bash，安装完之后可以在~/.nvm看到该文件夹，不知道为什么，我的执行上述操作后无反应，重新启动了wsl才正常进行，完成后，在对应的配置文件( ~ /.bashrc或者~/.zshrc)中添加： export NVM_DIR=\"$([ -z \"${XDG_CONFIG_HOME-}\" ] &amp;&amp; printf %s \"${HOME}/.nvm\" || printf %s \"${XDG_CONFIG_HOME}/nvm\")\" [ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" # This loads nvm 完成后保存退出，source ~/.zshrc，即可使用nvm命令 nvm install可以指定安装Node.js 的版本 ，可以选比较近的稳定版本17.0.0，安装完后nvm ls查看已安装版本： ❯ nvm ls -&gt; v17.0.0 system default -&gt; v17.0.0 iojs -&gt; N/A (default) unstable -&gt; N/A (default) node -&gt; stable (-&gt; v17.0.0) (default) stable -&gt; 17.0 (-&gt; v17.0.0) (default) lts/* -&gt; lts/gallium (-&gt; N/A) lts/argon -&gt; v4.9.1 (-&gt; N/A) lts/boron -&gt; v6.17.1 (-&gt; N/A) lts/carbon -&gt; v8.17.0 (-&gt; N/A) lts/dubnium -&gt; v10.24.1 (-&gt; N/A) lts/erbium -&gt; v12.22.10 (-&gt; N/A) lts/fermium -&gt; v14.19.0 (-&gt; N/A) lts/gallium -&gt; v16.14.0 (-&gt; N/A) 之后就可以对npm进行更新了。npm -v可以查看现有的版本，问题解决了 这里还有一个问题，就是nvm安装的版本居然也不是全局版本，在另外一个目录下进行npm -v或者node -v竟然也是原版本… emmmm 后面暴躁到不想记录了呜呜呜 利用CSS对界面优化2022.3.1update:learn how CSS works CSS相关资源： https://chokcoco.github.io/CSS-Inspiration/#/ https://cssreference.io/ 这个网站整合了很多CSS工具： https://juejin.cn/post/6982363593241002014 HTML CSS工具网站,可以copy已有模板（nice！）和实时观察到html,CSS,JS的呈现结果 https://codepen.io","categories":[{"name":"git","slug":"git","permalink":"http://sn1987a-1.github.io/categories/git/"}],"tags":[{"name":"WSL2","slug":"WSL2","permalink":"http://sn1987a-1.github.io/tags/WSL2/"}]},{"title":"WSL2美化","slug":"WSL2美化","date":"2022-01-21T14:12:20.000Z","updated":"2023-09-23T13:15:07.152Z","comments":true,"path":"posts/15684.html","link":"","permalink":"http://sn1987a-1.github.io/posts/15684.html","excerpt":"","text":"WSL2美化本文简要记录基于Windows11对WSL的终端进行美化的主要步骤。 环境：Ubuntu 20.04，Windows Terminal(WT) 主要工具和插件：zsh，oh my zsh, povwerlevel10k(powerlevel9k也可以),autozsh-autosuggestions , zsh-syntax-highlig 下图是我的美化结果。 对Windows terminal的外观进行美化在微软应用商店搜索Windows terminal即可下载最新版本，如果不想用Windows Terminal，也可以下载另外一个跨平台终端——Tabby Terminal，点击下载)，配置方案也类似，但亲测效果不如WT。 修改默认配置打开Windows Terminal，点击上方栏中“v”按钮，选择侧边栏中的“setting.json”文件并打开，后文中对WT的配置均对该文件进行修改（可以用VScode打开）。 例如，若要规定默认打开的界面是WSL2/WSL的界面，即可在actions一栏进行修改： \"defaultProfile\": \"{07b52e3e-de2c-5db4-bd2d-ba144ed6c273}\",//括号内对应的序列可在setting.json文件里查找到Ubuntu对应的GUID 修改配色方案在setting.json最后部分有schemes一栏，代表WT的配色方案，每个配色方案的name项即为名称，系统默认提供了一部分配色方案以及名称，但都不是很好看，将自定义配色添加到schemes底下即可新增配色方案，自定义配色网站)提供了较多推荐的配色，可以直接复制。 以下为我选择的配色： { \"name\": \"ChallengerDeep\", \"black\": \"#141228\", \"red\": \"#ff5458\", \"green\": \"#62d196\", \"yellow\": \"#ffb378\", \"blue\": \"#65b2ff\", \"purple\": \"#906cff\", \"cyan\": \"#63f2f1\", \"white\": \"#a6b3cc\", \"brightBlack\": \"#565575\", \"brightRed\": \"#ff8080\", \"brightGreen\": \"#95ffa4\", \"brightYellow\": \"#ffe9aa\", \"brightBlue\": \"#91ddff\", \"brightPurple\": \"#c991e1\", \"brightCyan\": \"#aaffe4\", \"brightWhite\": \"#cbe3e7\", \"background\": \"#1e1c31\", \"foreground\": \"#cbe1e7\", \"selectionBackground\": \"#cbe1e7\", \"cursorColor\": \"#fbfcfc\" }, 添加完配色方案后，还应该对profiles部分进行修改，以便于使用最新配色方案。如果只需要对虚拟机部分添加如下文本，可以只修改name为“Ubuntu-xx.xx”的部分（当然其他部分也只是复制粘贴）。 \"colorScheme\": \"ChallengerDeep\", 修改字体Windows原装字体不支持很多符号的显示，这里推荐修改默认字体 比较简单的，可以在微软官方下载)Cascadia Code PL字体，或者是下载文件后右键单击该字体对应的.otf/.ttf文件并选择安装。 当然有功能更加强大，应用更加广泛的字体Nerd Fond(Hack Nerd Fond)，包含了更多字符库，点击下载]( https://github.com/ryanoasis/nerd-fonts ))。 安装完成后，同样在profiles目录的Ubuntu-xx.xx里修改： \"fontFace\": \"Hack Nerd Fond\" \"fontSize\": 10, 设置背景和透明效果均是在perfiles目录内 添加背景图： \"backgroundImage\": \"E:\\\\wallpaper\\\\wp3.jpg\",//背景的地址 添加透明效果（0~1，越小表示越透明） \"acrylicOpacity\": 0.8, \"useAcrylic\": true 指定启动时的默认路径： \"startingDirectory\": \"./\", 这样Windows Terminal基本就配置好了。 美化WSL2步骤： 将原有的shell替换为zsh 安装oh my zsh 关键字高亮以及自动填充插件 安装powerlevel10k 安装完自动填充以及高亮插件后对文件zshrc进行的主要添加为： source /usr/share/zsh-autosuggestions/zsh-autosuggestions.zsh source /usr/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh 这里主要从安装powerlevel10k开始记录。 在命令行输入： sudo vim ~/.zshrc 打开配置文件后，找到THEME一行，修改为： ZSH_THEME=\"powerlevel10k/powerlevel10k\" 之后重启或输入命令 p10k configure 之后填写弹出的问卷即可自定义并保存当前配置文件。如果需要使用其他路径的文件，可以使用source命令进行导入。","categories":[{"name":"WSL2","slug":"WSL2","permalink":"http://sn1987a-1.github.io/categories/WSL2/"}],"tags":[{"name":"WSL2","slug":"WSL2","permalink":"http://sn1987a-1.github.io/tags/WSL2/"}]},{"title":"DataStruct基础知识","slug":"2021数据结构复习","date":"2022-01-11T12:12:20.000Z","updated":"2023-09-23T13:16:04.642Z","comments":true,"path":"posts/131000.html","link":"","permalink":"http://sn1987a-1.github.io/posts/131000.html","excerpt":"","text":"2021数据结构复习 考试范围数据结构 算法时间复杂度空间复杂度分析 线性表 顺序表示 链式表示 线性链表 循环链表 双向链表 一元多项式（实验内容） 栈 数值转换，括号匹配，行编辑程序，迷宫求解，表达式求值 队列 定义 链队列 循环队列 串 定长顺序存储 堆分配存储 串的块链存储 数组 顺序表示 特殊存储：特殊矩阵，稀疏矩阵 广义表 定义和存储结构 *广义表的递归算法 求广义表深度 复制广义表 建立广义表的存储结构 树和二叉树 二叉树 定义，性质，存储结构 遍历二叉树 线索二叉树 树和森林 树的存储结构 树和二叉树之间的转换 树和森林的遍历 Huffman树相关问题 图 定义和术语 存储结构 数组表示法 邻接表 十字链表 邻接多重表 图的遍历 DFS BFS 图的连通性问题 无向图连通分量和生成树 最小生成树 最短路径问题 从某一点到其他各个顶点的最短距离 每一对顶点之间的最短路径 查找 静态查找表 顺序表查找 有序表查找 索引顺序表查找 动态查找 二叉排序树和 *平衡二叉树 B-树和B+树 哈希表 构造方法 处理冲突 查找 `#define INFEASIBLE -1 `#define OVERFLOW -2 线性表顺序表逻辑上相邻，物理上相邻，随机存取 #define LIST_SIZE 100 #define LISTINCREMENT 10 typedef struct { ElemType *elem; int length; int listsize; }SqList; 动态分配： void *malloc(); free(void *p); void *realloc(void *p,unsigned int size);//可变大/变小 基本操作略 链表表示逻辑上相邻不代表物理上相邻，非随机存取 （区别不同逻辑结构的插入删除操作） 单链表typedef struct LNode { elemtype data; struct LNode *next; }Lnode ,*LinkList; 基本操作： Status GetElem_L(LinkList L,int i,ElemType &amp;e); Status ListInsert_L(LinkList &amp;L,int i，ElemType e); //获取结点的前驱耗时间，T(N)=O(N) Status ListDelete_L(LinkList &amp;L,int i，ElemType &amp;e); Status CreateList_L(LinkList &amp;L); 创建：头插法（$T(N)=O(N)$），尾插法($T(N)=O(N^2)$)(头插法创建较好) 作业习题：就地逆置单链表 有头结点：L指向头结点，除头结点各点均有前驱； 无头结点：空表时L为NULL； 循环链表 便于从一个结点出发，访问全部的结点 在O(1)的时间内找到链表的第一个结点和最后一个结点（头指针==尾指针） 静态链表和动态链表静态链表(若语言不支持指针类型的存储的情况) #define MAXSIZE 1000 typedef struct{ ElemType data; int cur;//代替指针域 }component,SLinkList[MAXSIZE]; 数组的第0个分量可以视为（备用链的）头结点； 静态链表的模拟动态分配与释放（未利用的点i[cur]=0;) 动态链表与静态链表的运用：例：求差集 双向链表typedef struct DuLNode{ ElemType data; struct DuLNode *prior; struct DuLNode *next; }DuLNode ,*DuLinkList; 可带头结点，可不带（多半是带的）。 其他表示根据题目要求规定进行设计，如同时存储单链表的头和尾，特殊线性表——有序表。 例题1.双向循环链表的自身变换，如将$L=\\{a_1,a_2,…..a_n\\}$变换为$L’=\\{a_1,a_3,….a_n,…a_4,a_2\\}$ ​ (顺着后向链，前向链进行插入) 栈与队列难点：递归与非递归实现，循环队列 栈LIFO 只能在Top端进行插入删除操作 Traverse操作是从栈底到栈顶进行访问 多为顺序栈：约定：S.top指向栈顶元素的下一个位置 #define STACK_INT_SIZE 100 #define STACKINCREMENT 10 typedef struct { ElemType *base; ElemType *top; int stacksize;//当前分配容量 }SqStack； 栈空：S.base==S.top 栈满：S.top-S.base&gt;=S.stacksize 入栈：S.top++; 出栈: S.top - - ； 链栈：无栈满问题，可以不必引入头结点（在第一个结点处进行插入删除操作）。 栈的基本应用1.数制转换 2.行编辑程序（已不常用） ​ 用栈保存终端输入的一行字符进行逐行处理；遇到‘#’退一格（出栈），遇到‘@’退一行（清空栈ClearStack），其他字符入栈，最后遍历，清空栈。 3.表达式求值 表达式表示方法： 中缀表达式，记得加括号 前缀表达式（波兰式）-+abc d-ea 后缀表达式（逆波兰式）ab+cdea- - 表达式求值也可以用二叉树表示：分支保存运算符，叶子结点保存操作数，中序访问：中缀表达式；先序访问：前缀表达式；后序访问：后缀表达式 要先确保中缀表达式合法：括号匹配 默认运算式结尾为’#’ 可以进行的操作：中缀表达式转化为先/后缀表达式，先/后缀表达式求值，中缀表达式直接求值。注意：不涉及中缀表达式的运算不需考虑优先级。 [1]中缀表达式转后缀表达式：运算符入栈 [2]中缀表达式求值：运算符（包括左括号）和运算数两个栈，按照操作符优先级进行运算，'#'优先级最低。 [3]前缀表达式串求值：运算符和运算数入同一个栈，如果有两个运算数则进行运算 [4]前缀表达式与后缀表达式相互转化：思路相反，同样用栈，类似波兰式/逆波兰式求值，将字符串视作运算数。 [5]后缀表达式求值：运算数入栈 4.栈与递归的实现 应用：构建其他数据结构：表，图，树和二叉树 ​ 问题求解：Hanoi塔问题，迷宫问题/N皇后问题（回溯） 队列FIFO，允许在队尾rear插入，队头head删除（获取队头元素GetHead(L,&amp;e),遍历操作Traverse(L，visit())从head到rear）. 链队列（通常）typedef struct QNode{ ElemType data; struct QNode *next; }QNode,*QueuePtr; typedef struct { QueuePtr front; QueuePtr rear; }LinkQueue; （最好是引入头结点——队空：L.front ==L.rear） 循环队列(处理假溢出)#define MAXSIZE 100 typedef struct{ ElemType *base; int front; int rear;//指向队尾元素的下一个位置 }SqQueue； 队空标志：Q.front==Q.rear 多申请一个空间，队满标志：Q.front==(Q.rear+1)%MAXSIZE INCREMENT：重新分配空间，并遍历原队列进行复制 应用：离散事件模拟 串概念：串的长度，空串，子串，主串，子串/字符在串中的位置 是特殊的线性表：处理对象为个体（字符）或整体（子串） 操作： StrAssign(S,\"...\");//赋值 StrCpoy(T,S);//复制串 StrCompare(S,T);//比较 ConCat(T,\"...\");//拼接 SubString(Sub,S,i,j);//取子串Sub为Si,...Sj Index(s,\"a\",i);//返回S中i后第一层出现子串的首个字母的位置 Replace(S,\"..\",\"..\");//将子串全部替换为目标子串 StrInsert(S,i,\"...\");//在i处插入子串 StrDelete(S,i,j);//删除Si到Sj的子串 具体存储结构顺序映像存储密度低 定长顺序存储，下表为0的位置存储串的长度（basic)或串值最后加入无关字符，如’\\0’ (C)。 堆分配存储——顺序映像 typedef struct{ char *ch;//malloc() 动态分配 int length; }HString; ​ 块链存储——链式映像 typedef struct Chunk{ char ch[CHUNKSIZE]; struct Chunk *next; }Chunk; typedef struct{ Chunk *head,*tail; int curlen }LString; 块链存储中的插入，删除，寻找子串，定位，拼接算法复杂化处理（作业题目） 串的模式匹配算法好像不考。 应用举例应用于文本编辑，页插入/删除，行插入/删除，页表，行表，起始地址，长度… 建立关键词词索引表 数组和广义表数组的操作貌似也不考，补充三元表，特殊数组在后续算法课中。 广义表广义表是线性表的推广，元素类型可以是原子或子表，习惯上用大写字母表示子表，小写字母表示原子。（也可以看作特殊定义的图） 表处理语言LISP中，将广义表视作基本的数据结构。 表头：表中的第一个元素 GetHead(L) 表尾：除去第一个元素外的其余元素组成的表 GetTail(L) 基本定义 空表 A=( ) 长度：元素个数，如B=(a,(b,c,d))长度为2，第二个元素为表 A=(a,A) 可以递归定义的表 GetHead(((())))=(()); GetTail((()))=() 深度：括号的重数的最大值 广义表的存储结构数据元素不同，难以用顺序表存储。 头尾链表存储typedef enum{ATOM,LIST}ElemTag; typedef struct GLNode{ ElemTag tag; union{ AtomType atom; struct {GLNode *hp,*tp;}ptr; }; }*GList; 拓展线性链表存储typedef enum{ATOM,LIST}ElemTag; typedef struct GNode{ ElemTag tag; union{ AtomType atom; struct GLNode *hp; }; struct GLNode *tp; }*GLIst; 广义表的相关操作此部分不考代码设计，可能有读代码分析的题目 递归算法，归纳思维 广义表的深度规定：LS为原子：DEPTH=0； ​ LS为空表：DEPTH=1； ​ 归纳项：$DEPTH(LS)=1+Max\\{DEPTH(a_i)\\},\\ n&gt;=1$ 假设采用头尾链表存储： int GListDepth(GLIst L)//递归 { if(!L) return 1; if(L-&gt;tag==ATOM) return 0; for(max=0,pp=L;pp;pp=pp-&gt;ptr.tp) { dep=GListDepth(pp-&gt;ptr.hp); if(dep&gt;max) max=dep; } return max+1; } //可以用队列实现非递归算法，在每层开始处设置标志 复制广义表归纳：复制LS—&gt;复制表头+复制表尾 Status CpoyList(GList &amp;T,GList L) {//假定头尾链表存储 if(!L) { T=NULL; return OK;} T=(GList)malloc(sizeof(GLNode)); T-&gt;tag=L-&gt;tag; if(T-&gt;tag==ATOM) {T-&gt;atom=L-&gt;atom; return OK:} CopyList(T-&gt;ptr.hp,L-&gt;ptr.hp); CopyList(Y-&gt;ptr.tp,L-&gt;ptr.tp); return OK; } 可以用栈实现非递归算法。 广义表结构的建立由字符串建立广义表 表头+表尾递归处理 ... 其他应用作业题目：就地逆置广义表(逆转所有子表)递归处理 ``` 注：广义表的存储格式一般可以自选 常见思路：1.将广义表看作表头表尾两部分进行递归处理 ​ 2.将广义表看作n个并列子表组成的表 ## 树和二叉树 **二叉树的遍历，二叉树和森林的相互转换等相关算法设计** ### 定义 空树n=0; 表示方法： 树形表示，嵌套表示，广义表表示，凹入表示 术语：高度，层次（1，2，...，h），度，祖先，子孙，有序树，无序树，终端结点，非终端结点，内部结点... 操作： ```c++ TreeDepth(T); Parent(T,cur_e); LeftChild(T,cur_e); RightSibling(T,cur_e); InsertChild(&amp;T,p,i,c);//插入子树 DeleteChild(&amp;T,p,i); TraverseTree(T,visit()); 二叉树每个结点最多有两个子树，度数一定是2，分左右。 性质： 第i层最多有$2^{n-1}$个结点 深度为h的二叉树最多$2^{h}-1$个结点（上述两条可以推广到n叉树的情况） $n_0=n_2+1;\\ \\ \\ n=n_0+n_1+n_2;\\ \\ \\ n-1=n_1+n_2$ 若包含n个结点的树只有叶子结点和度数为k的结点，则树中包含的叶子结点为：$n_0=n-(n-1)/k$ 满二叉树：深度为h且含有$2^{h}-1$个结点的二叉树 完全二叉树：前k-1层为满二叉树，第k层结点全在靠左边 具有n个结点的完全二叉树的深度：$h=[log_2n]+1$ 若对一有n个结点的完全二叉树按层序编号，则对任意结点有： 若i=1，为根结点，无双亲；若i&gt;1，双亲结点为[i/2] 若2i&gt;n,则结点i无左孩子，否则左孩子为2i。 若2i+1&gt;n，则i无右孩子，否则右孩子是2i+1. 上述结论可以大致推广到k叉树 二叉树的存储结构： 顺序存储：空间开销大 链式存储：二叉链（保存双亲结点变成三叉链） typedef struct{ ElemType data; struct BiTNode *lchild,*rchild; }BiTNode,*BiTree; 二叉树的相关算法遍历先/中/后序遍历：每个结点均被访问三次 递归/非递归（栈）算法实现。 最好使用函数调用的结果而不是返回值：为实现函数出现异常时改变Status及时终止 相关运用： 创建二叉树：类比先序访问 清空释放二叉树，或以某个结点为祖先的子树：后序访问 先序/后序拓补序列可以唯一确定一个二叉树。 非递归后序遍历要注意：设置访问标志tag 求深度 层次遍历递归/非递归（队列）实现 ​ ——先访问的结点，子结点也会优先访问 对二叉树进行层次遍历可以判断该二叉树是否为完全二叉树。 找到距离x最近的叶子子孙及距离：从x开始进行层次遍历，找到第一个叶子结点即可（每层末尾加一个虚结点进行计算距离 输出距离x最近的所有叶子及其数目 输出x到最近叶子子孙结点的路径：修改原队列：不释放已经遍历的结点并记录每个结点的双亲信息 二叉树的创建 完全二叉树的顺序映射 先序拓扑序列 先序+中序或后序+中序也可唯一确定的一棵二叉树—-线索化二叉树 线索二叉树利用叶子结点的未使用的指针域，加两个标记 typedef enum{Link,Thread}PointerTag; typedef struct BiThrNode { ElemType data; struct BiThrNode *lchild,*rchild; PointerTag ltag,rtag; }BiThrNode,*BiThrTree; 先序/中序/后序线索化二叉树：对应遍历顺序的相应前驱，后继，其算法可以类比相应的遍历算法。 中序线索化中规中矩，基本是中序遍历的拓展，左孩子为前驱，右孩子为后继； 先序/后序线索化二叉树 相互对称，难点：找前驱和后继 后序找到前驱的方法： 若该结点无左孩子，前驱由lchild指向 若该结点有左右孩子，前驱为右孩子 若该结点只有左孩子，前驱为左孩子 后序找到结点的后继 若结点为根结点，后继为空 若结点为双亲的右孩子或没有右兄弟，后继为双亲 若为有右兄弟的左孩子，且右兄弟为叶子结点，后继为右兄弟 若为有右兄弟的左孩子，且右兄弟不是叶子结点，则后继为右兄弟后序遍历的第一个结点 后序找到结点的后继 若结点为根结点，前驱为空 若结点为双亲的左孩子或没有左兄弟，前驱为双亲 若为有左兄弟的右孩子，且左兄弟为叶子结点，前驱为左兄弟 若为有左兄弟的右孩子，且左兄弟不是叶子结点，则前驱为左兄弟先序遍历的最后一个结点 先序找到后继的方法 若该结点无右孩子，后继由右孩子指向 若该节有左右孩子，其后继为左孩子 若该结点有右孩子且无左孩子，其后继为右孩子 涉及求结点的双亲的问题———三叉链表 树的存储结构双亲表示法可以用于顺序存储 #define MAX_TREE_SIZE 100 typedef struct{ ElemType data; int parent; }PTNode; typedef struct{ PTNode nodes[MAX_TREE_SIZE]; int n;//结点数 }PTree; 孩子表示法#define MAX_TREE_SIZE 100 typedef struct{ int child; struct CTNode *next; }*ChildPtr; typedef struct{ ElemType data; ChildPtr firstchild; }CTBox; typedef struct { CTBox nodes[MAX_TREE_SIZE]; int n,r;//结点数和根的位置 }CTree; 孩子兄弟表示法typedef struct CSNode{ ElemType data; struct CSNode *firstchild,*nextsibling; }CSNode,*CSTree; 树的遍历先根遍历&lt;—-&gt;二叉树的先序遍历 后根遍历&lt;—-&gt;二叉树的中序遍历 应用：通常以孩子-兄弟链表示 统计树的高度 统计树中叶子结点的个数（叶子结点的标志：Firstchild为空） 求树的度 树和森林与二叉树之间的转换…没讲，不知道考不考 Huffman树相关概念：最优树，路径长度（带权），结点带权路径长度，$WPL=\\sum_{i=1}^nw_il_i$ Huffman编码（算法应该不考，考也无所谓） 开拓问题求解相关思路课本没讲？。？应该不考OvO 划分等价类，回溯法求解问题，树的计数/编号 图相关概念：有向图，无向图，带权/无权图路径和连通性，连通和强连通，子图，生成树，顶点/弧（相关概念复习图论再写） 一般算法中不考虑带权图的权值为负数的情况 基本操作 PS:操作包含对点vex，对边arc的操作 Status LocateVex(G,u); Status GetVex(G,v); Status FirstAdjVex(G,v); Status NextAdjVex(G,v,w); Status InsertVex(G,v); Status InsertArc(&amp;G,v,w); Status DeleteVex(&amp;G,v); Status DeleteArc(&amp;G,v,w); Status DFSTraverse(G,v,Visit()); Status BFSTraverse(G,v,Visit()); 图的存储结构用顺序表存储顶点集，不是顺序映像 最常用的还是邻接表 用以下方法存储关系集合 数组表示—邻接矩阵#define INFINITY INT_MAX typedef enum{DG,DN,AG,AN}GraphKind;//有向/无向，带权/无权 typedef struct ArcCell{ //带权图：adj代表权值，INFINITY代表不相邻 //无权图0代表不相邻，1代表相邻 int adj; InfoType *info;//指向相关信息的指针 }ArcCell,AdjMatrix[MAX_VERTEX_NUM][MAX_VEXTEX_NUM]; typedef struct { VextexType vexs[MAX_VEXTEX_NUM]; AdjMatrix arcs; int vexnum; int arcnum; GraphKind kind; }MGraph; 无向图的邻接矩阵：对阵矩阵 链表表示—邻接表/逆邻接表typedef struct ArcNode{ int adjvex; struct ArcNode *nextarc; InfoType *info; }ArcNode; typedef struct { VexType data; ArcNode *firstarc; }VNode,AdjList[MAX_VERTEX_NUM]; typedef struct{ AdjList vertices; int vexnum,arcnum; GraphKind kind; }ALGraph; 对于有向图，比较容易计算的是顶点的出度，而入度要对所有的边进行遍历才能求出（反之为逆邻接表）。 对于稀疏图（$v&gt;log_2a$），多采用邻接表，避免空间浪费，否则可以选用邻接矩阵。 十字链表—有向图弧结点数=弧数 方便求出顶点的入度和 出度 typedef struct ArcBox{ int tailvex,headvex; struct ArcBox *hlink,*tlink; InfoType *info; }ArcBox; typedef struct VexNode{ VextexType data; ArcBox *firstin,*firstout; }VexNode; typedef struct{ VexNode xlist[MAX_VERTEX_NUM]; int vexnum,arcnum; }OLGraph; 邻接多重表—无向图邻接表中：边结点数==2*边数 临界多重表：边结点数==边数 typedef enum{unvisited ,visited}VisitIf; //边结点 typedef struct EBox{ VisitIf mark; int ivex,jvex; struct Ebox *ilink,jlink; InfoType *info; }EBox; //顶点结点 typedef struct VexBox{ VexType data; EBox *firstedge; }VexBox; //临界多重表 typedef struct { VexBox adjmulist[MAX_VEXTEX_NUM]; int vexnum,edgenum; }AMLGraph; 图的遍历对顶点的遍历——引入标记数组visitd[0,…n-1]，防止顶点被多次访问。 访问结束可以得到图的生成树（连通图可以从一个顶点完成全部的遍历，非连通图要在外部加循环确保所有顶点均被访问，有向图注意强连通），后续连通性模块将讨论。 可以基于图的多种存储结构进行相似的遍历，算法可以基于ADT Graph（调用ADT的函数，如FirstAdjVex，NextAdjVex等）或某种存储结构写。 DFS深度优先遍历——树的先序遍历 生成从起点v出发的深度优先生成树，v可能存在多个子树 非递归实现：利用栈及时进行现场保护和现场维护 BFS广度优先遍历——树的层次遍历 判断两个顶点是否存在路径 得到某点到任意一个顶点之间的最短路径（无权） 求距离v的最短距离最长/最短的顶点 求距离v距离为k的所有顶点 遍历算法的应用 求一条包含图中所有顶点的简单路径 不一定存在，基于DFS寻找，是否能找到与具体顶点的选择有关 对DFS的修改：要回溯，添加计数器记录当前路径的结点数n，查找失败时恢复原来的状态，n-- 可以修改算法，选择输出一条路径或者全部路径（最好是一条？），统计最短路径的条数 求距离v的最短距离最长的顶点和最长的路径值 对BFS进行修改，在每层结尾入队一个特殊元素 最后一个出队列的一定是路径最长的顶点 图的连通性问题基本概念：连通分量的顶点集，生成树，DFS生成树，BFS生成树，生成森林 同样可以基于ADTGraph或具体的存储方式写出不同的算法 BFS/DFS生成树/生成森林 有向图的强连通分量 从某顶点出发，以该顶点为尾做DFS，按照其所有邻接点的搜索都完成的顺序（退出DFS的顺序）存储到数组 从存储到数组的顶点出发，沿着该顶点为头的弧进行逆向DFS，能访问到的顶点则在同一个强连通分量中 复杂度近似和DFS遍历的复杂度相同 最小生成树MST——无向连通网的最小代价生成树 “若（u，v)为具有最小权值的边，则必存在包含该边的最小生成树” Prim算法——最小生成树不断壮大的过程 适用于稠密图$T(N,e)=O(N^2)$ Kruskal算法——连通分量不断合并的过程 适用于稀疏图$T(N,e)=O(N*log (e))$ 关节点和重连通分量 关节点：删除v后一个连通分量变为两个/两个以上 若生成树的根至少有两棵或两棵以上的子树，则该结点必是关节点 若生成树的某非叶子结点v的某棵子树的结点均没有指向v的祖先的边，则v为关节点 叶子结点一定不是关节点 重连通图：不含关节点的图，保证了任意两个顶点至少存在两条路径 连通度：若连通图G至少删去K个顶点才能变成不连通，则该图的连通度为k 改造DFS可以得到图的关节点，判断是否为重连通图 引入数组low[v]:生成树中以v为根的子树中结点到v的祖先的边所关联的祖先的最小次序号 若对于v，v的孩子结点w有low[w]&gt;=visited[v]，则说明v为关节点 有向无环图（ DAG）的应用 检测有向图中是否有环： 从顶点v出发，若DFS结束前发现出现u到v的回边，则有环 DAG是描述一项活动或系统的进行过程的工具： ​ 顶点—子工程，边—子工程之间的约束 应用： 拓扑排序问题描述：偏序-&gt;全序 偏序：集合X上的元素是自反的，反对称的，传递的 一、AOV网：Activity on vextex network 进行拓扑排序的方法： 在有向图中选取一个没有前驱的顶点并输出 在图中删除该顶点和以该顶点为尾的弧 转1，除非已经输出全部顶点或不存在无前驱的顶点 有向无环图保证了该图存在拓扑排序，存在拓扑排序保证了有向图中没有环 对于一个有向无环图，进行DFS遍历，第一个退出循环的顶点即为出度为0的顶点，（可以）是拓扑排序的最后一个顶点 若有向图的邻接矩阵为三角矩阵，则该途中存在拓扑有序序列 二、AOE网：Activity on edge network 问题：完成整项工程的最短时间/关键路径/事件的最早发生时间 关键活动：最早发生时间（e(i)）==最晚发生时间（l(i)） 最早发生时间：拓扑有序 最晚发生时间：逆拓扑有序 关键路径：输出关键活动（可能不止一条） 最短路径无权图的最短路径：广度优先搜索 带权有向图的最短路径——dijkstra算法 按路径长度递增的顺序产生最短路径 求任意两个顶点的最短路径 对Dijkstra算法进行循环：$O(T,e)=O(n^3)$ 具体实现应该不会考，会考画图？ Floyd（Wallshall算法）：求vi，vj之间的最短路径，依次使得中间路径序号不大于k的最短路径，k依次递增。 查找Search Table操作：检索/查找（静态），插入/删除（动态） 关键字：主关键字唯一，次关键字不唯一 静态查找顺序查找通过顺序表/线性链表进行查找 0的位置设置“哨兵”：避免每一次查找都要判断是否查找完毕，减少比较次数 查找成功：ASL=$(n+1)/2$ 查找不成功：ASL=n+1 有序表的查找 折半查找 基本思想：用low/high做标记，查找区间折半缩小 性能分析：查找过程可以用二叉树判定树表示，判定树的形态与n直接相关（不是完全二叉树但胜似完全二叉树），查找层次即为二叉树的层次，也代表ASL 查找成功或不成功：$ASL&lt;=[log_2n]+ 1$ n&gt;=50时，可近似得到结果：$ASL_{bs}\\approx log_2(n+1)-1$ 斐波那契查找 根据斐波那契的特征对标进行分割:开始表中的记录个数比斐波那契数小1，则将定值与F(n-1)进行比较，类似折半查找 特点：分割时只需进性加减运算 平均性能比折半查找好，但最坏的情况比折半查找糟糕 插值查找 $i=\\frac{key-ST.elem[l].key}{ST.elem[h].key-ST.elem[l].key}(h-l+1)$ 只适用于关键字均匀分布的情况，这种情况下平均性能优于折半查找 静态树表查找 根据各个记录的查找概率求ASL PH值：判定树内带权路径长度$PH=\\sum_{i=1}^nw_ih_i$,其中$w_i=c*p_i$为权，$h_i$为层次 PH值最小：静态最优查找树——构造需要的时间开销过高 构造较好的次优查找树 …写到这里发现查找树表不考，再见 索引顺序表 起因：顺序查找表效率低而折半查找等要求查找表有序 思想：分块有序——索引有序（索引包含最大项和起始指针） 过程：先折半查找记录所在的块，再顺序查找元素 $ASL_{bs}=L_b(查找块)+L_w(查找元素)$ 动态查找二叉查找树BSTBinary Search Tree查找算法可以基于二叉树的先序遍历算法写出 中序遍历BST可以得到关键字的有序序列 BST的插入算法：查找失败的同时添加叶子结点 BST的删除算法： 若P为叶子结点，直接删除并修改双亲的指针域 若P只有左子树或右子树，将P删除并使P的双亲指针域指向P的孩子 若P有左右子树，将P与P的右子树的最左边的元素进行互换（中序遍历的首个元素），换言之，将P与P在树中中序访问序列的直接前驱或直接后继进行交换即可，避免树的长高 BST的建立：二叉树的形态与输入的次序直接相关，若原本有序将得到每层只有一个结点的糟糕情况 平均性能分析：$P(n)&lt;=2(1+1\\frac{1}{n})ln\\ n$ 平衡二叉树AVL树深度与log(N)同量级 引入平衡因子BF：-1，0，1 AVL树的旋转部分不会单独考察算法设计，理解过程即可 LL型旋转：在A结点的左孩子的左子树插入结点 RR型旋转：在A结点的右孩子的右子树插入结点 LR型旋转：在A结点的左孩子的右子树插入结点，先左转再右转 RL型旋转：在A结点的右孩子的左子树插入结点，先右转再左转 在对AVL树进行插入和删除操作时及时维护平衡 性能分析：$T(N)=O(log\\ N)$ B-树定义： 每个结点至多有m个子树 若根结点不是叶子结点，至少有两棵子树 除根结点外的非得终端结点至少$\\lceil m/2\\rceil$个子树 非终端结点包含以下信息：$(n,A_0,K_1,A_1,K_2,…,K_n,A_n)$，其中n为关键字数目，$K_i$为关键字，$A_i$为指针，且$A_{i-1}$指向的所有结点的关键字小于$K_i$,大于$K_{i-1}$ 所有叶子结点都出现在同一层次上,且不携带信息，可以视作查找失败，指向这些结点的指针为空，图中表示为F 相关算法 查找：纵向查结点，横向查关键字 通常存储在磁盘中，是数据库的主要索引结构 查找效率的首要因素：层次 通常取m=3，此时又称为2-3树 含有N个关键字的m阶B-树的最大深度：$log_{\\lceil m/e\\rceil}(\\frac{N+1}{2})$ 较为特殊的插入删除操作： …应该不考察算法，要会画图 B+树B-树的变形树，具体区别： 有n棵子树的结点包含了n个关键字 所有叶子结点包含了关键字的信息，以及指向这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大排序 非终端结点为索引部分，结点仅含有最大或者最小关键字 B+树不是树；支持顺序查找（横向），随机查找（纵向） 键树好像不考键树 哈希表Hash函数：H(key) 便于一次存取确定所查记录 将一组关键字利用H(key)和处理冲突的函数映射到有限的连续地址——hash表（散列） Hash函数的构造方法： 直接定址法（x) 数字分析法/平方取中法 折叠发：移位叠加，间界叠加 除留余数法 随机数法 … 处理冲突的方法：s 开放定址法 线性探测再散列+1，+2，… 平方探测再散列+1,-1,+4,-4 伪随机探测再散列 链地址法：关键字为同义词的的各个元素存储在线性链表中 再哈希法：$H_i=RH_i(key),i=1,2,..k$不易产生聚集，但会增加计算的时间 建立公共溢出区域：发生冲突都填入溢出表 ​ 二次聚集：在处理同义词冲突的过程中又添加了非同义词的冲突的现象 Hash表的查找算法根据Hash函数以及冲突处理方法确定 查找的ASL：分成功与不成功计算，时间复杂度为未知 装填因子$\\alpha=$记录数/Hash表表长 通常Hash表长m和除留余数法的p的关系： p&lt;=m,且p为素数或最小不包含小于20的质因子的合数。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://sn1987a-1.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"图论期末复习","slug":"图论","date":"2022-01-05T15:42:30.000Z","updated":"2022-02-26T07:11:20.781Z","comments":true,"path":"posts/12532.html","link":"","permalink":"http://sn1987a-1.github.io/posts/12532.html","excerpt":"","text":"图论复习未完成——不想写了 图的基本概念 阶：图G中顶点的个数$\\nu (G)=|V(G)|$（简记为$\\nu,V$） $\\epsilon (G)=|E(G)|$（简记为$\\epsilon ,E$） 无限图：$\\nu(G)+\\epsilon (G)=+\\infty$，否则成为有限图 关联/相邻/邻顶：$\\psi (e)=\\{u,v\\}$ 重边/环 简单图：无环无重边 完全图 二分图 完全二分图 零图 星图 度数$deg(\\nu)=d_1(\\nu)+2\\times l(\\nu)$ 最大/最小度数$\\delta (G)=min_{\\nu \\in V(G)},\\Delta (G)=max_{\\nu\\in V(G)}$ 无向图$\\sum_{\\nu\\in V(G)}{deg(\\nu)=2\\epsilon(G)}$ 给定图G，G中度数为奇数的顶点个数为偶数 真子图，生成子图（V(H)=V(G)），顶点导出子图，边导出子图 补图，边图：边图的边对应原图的顶点，顶点对应原图的边 并，交 积：$G\\times H=(V’,E’)$,边集合分为三类： 两个顶点在的两个分量在原图中均相邻 有一个分量在原图中相邻，另外一个分量为同一个顶点 路径/行迹/轨道/回路/圈 连通/不连通：连通存在距离 图的同构：元素之间的二元关系完全相同 Ulam猜想：G与H全等 等价于 对任何$\\nu \\in V(G),G-\\nu=V-\\nu$ 有向图D：$D=(V(D),E(D),\\psi _D)$ $\\sum_{\\nu\\in V(G)}{deg^-(\\nu)}(入度)=\\sum_{\\nu\\in V(G)}{deg^+(\\nu)}(出度)=\\epsilon(G)$ 定理：G为二分图当且仅当G中无奇圈 最长轨道 反证例：若G为简单图，$\\delta (G)&gt;=2$，则G中必含圈 ​ 若G为简单图，$\\delta (G)&gt;=3$，则G中必含有偶圈 最短路径问题$\\omega (P_0(u,v))$——Dijkstra算法 ​ 证明略。 类似最短路径的相关思路——如取生成子图最大边数： 任给无向图G，存在H为G的生成子图，满足： H是二分图 任给$u\\in V(G)=V(H),有d_H(u)&gt;=d_G(u)/2$ 取H为边数最大的二分图，假设不满足条件2 树基本概念: 树叶/分支点（树枝） 森林/平凡树 以下命题等价 图的连通性平面图匹配理论Euler图和Hamilton图图的着色有向图网络流理论图矩阵和图空间","categories":[{"name":"图论","slug":"图论","permalink":"http://sn1987a-1.github.io/categories/%E5%9B%BE%E8%AE%BA/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"图论","slug":"图论","permalink":"http://sn1987a-1.github.io/tags/%E5%9B%BE%E8%AE%BA/"}]},{"title":"图论补充内容","slug":"图论补充","date":"2021-12-11T12:12:20.000Z","updated":"2023-09-23T13:14:57.702Z","comments":true,"path":"posts/15331.html","link":"","permalink":"http://sn1987a-1.github.io/posts/15331.html","excerpt":"","text":"图论补充内容图论的基本知识汇总已以PDF形式上传至科大个人主页链接，此部分补充内容主要记录图论在实际算法问题方面的知识学习，部分内容来源于网络。 计算复杂性问题P问题、NP问题、不可判定问题P问题：能够在多项式时间内可用算法求解的问题。举例：找到Euler回路NP问题：非确定型多项式时间（nondeterministic polynomial-time）问题，指不确定是否存在多项式时间的求解算法，但可以在多项式时间内验证一个猜测解的正确性的问题。举例：找Hamilton回路（实际上是NPC问题，尚且未知有限性算法）。不可判定问题(undecidable problem)：”不可能“解出的问题。举例：让C编译器找出所有的语法错误和无限循环。 与NP相关的问题有P，NP，NP Hard ，NPC问题，其中NP Hard 与NPC问题的具体描述为： NP hard问题：Non-deterministic Polynomial hard problem(NPH)问题，如果所有NP问题可在多项式时间内转化（归约，意思是解决了后者也就相应的解决了前者）成某个问题，则该问题称为NP难问题。这里规约的意思是将一个特殊问题一般化，即将原问题推广为一个最一般的、最有概括性、也更难的、计算复杂度更高的问题，这个问题具有最高的计算复杂度，如果这个最一般的问题也能有多项式时间求解算法，那么那些特殊的原问题也能有多项式时间求解算法。解决了这个NP hard问题，所有NP问题都能够被解决了。 NP hard问题不一定是NP问题，有可能是不可判定问题。这时候说明原问题也是不可判定的。 NPC问题：Non-deterministic Polynomial complete problem ，如果所有NP问题可在多项式时间内归约成某个NP问题，则该NP问题称为NP完全问题。NPC包含了NP中最难的问题。解决了这个NPC问题。所有NP问题都能够被解决了。 NPC问题相当广泛，包括来自操作系统（调度和安全）、数据库系统、运筹学、逻辑学、特别是图论等不同领域的问题。可满足性问题、哈密顿圈问题、巡回售货员问题、最长路径问题都是NPC问题。 装箱(bin packing)问题、背包(knapsack)问题、图的着色(graph coloring)问题以及团(clique)的问题都是著名的NPC问题。NPC问题相当广泛，包括来自操作系统（调度和安全）、数据库系统、运筹学、逻辑学、特别是图论等不同领域的问题。 背包问题(Knapsack problem)是一种组合优化的NP完全问题。问题可以描述为：给定一组物品，每种物品都有自己的重量和价格，在限定的总重量内，我们如何选择，才能使得物品的总价格最高。问题的名称来源于如何选择最合适的物品放置于给定背包中。相似问题经常出现在商业、组合数学，计算复杂性理论、密码学和应用数学等领域中。也可以将背包问题描述为决定性问题，即在总重量不超过W的前提下，总价值是否能达到V？它是在1978年由Merkel和Hellman提出的。背包问题已经研究了一个多世纪，早期的作品可追溯到1897年数学家托比亚斯·丹齐格（Tobias Dantzig，1884-1956）的早期作品 ，并指的是包装你最有价值或有用的物品而不会超载你的行李的常见问题。 NPC算法的复杂度更倾向于$O(e^n)$,NP Hard 算法的时间复杂度甚至可能达到$O(n^n)$. 在本课程里出现的NPC问题： 图着色（边/顶点/面着色） Hamilton圈算法 …? 随机游走Random Walk 随机游走（英语：Random Walk，缩写为 RW），是一种数学统计模型，它是一连串的轨迹所组成，其中每一次都是随机的。[1][2]它能用来表示不规则的变动形式，如同一个人酒后乱步，所形成的随机过程记录。1905年，由卡尔·皮尔逊首次提出。 ——来自维基百科 靠随机游走解出来了tx的自定义阴间一笔画红包 ——来自群友 算法思想： 该算法要实现的是搜索，从起始点s开始找到目的地t。 给定一个图，从起点开始走的每一步都让其有一定的概率$\\alpha$跳转到图中的任意一个点上，还有$ 1-\\alpha$的概率会行走到任意一个与该点相连的点上。不断的重复上述过程，直到找到目的地中。 步骤 将实际问题抽象为图的形式，并用临接表、邻接矩阵等存图方式将图存储在计算机中； 用一个变量记录当前所处的位置（图中点的标号），每次随机一个[0, 1]之间的数，若其小于等于随机跳跃概率$\\alpha $则随机一个[1, n]的数字并跳转，否则随机一个$x,x\\in S$，其中S为与当前点相连的点的集合； 不断重复第二步并记录路径，直到找到目的地t. 该算法的思想也被应用到了PageRank算法中，作为Google等搜索引擎的网页检索算法。（PageRank中心性算法的本质就是随机游走（详见课本中心型算法部分，考试不考）。","categories":[{"name":"图论","slug":"图论","permalink":"http://sn1987a-1.github.io/categories/%E5%9B%BE%E8%AE%BA/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"HUFFMAM Tree","slug":"11-11","date":"2021-11-11T11:46:11.000Z","updated":"2023-09-23T13:16:23.062Z","comments":true,"path":"posts/1120.html","link":"","permalink":"http://sn1987a-1.github.io/posts/1120.html","excerpt":"","text":"Huffman 编码解压缩关于Huffman编码的知识,在上个学期数据结构已经学过,作为较为复杂的一次实验耗费了不少时间,可说实话,上个学期在数据结构投入的经历确实不算大,最终的成绩也相当不理想,但这个学期还得重新学数据结构(信计数据结构不能互认就离谱orz),同样类型的实验,不同的心境 ,不同的要求,只求要一个好一点点的分数啦 大致实验要求基于Huffman编码来实现压缩器和编码器,使其可以对任意文件进行解压缩操作. 实现方法:命令行执行/GUI界面(还不会…)/运行程序交互界面 本实验的测试数据:文件包括:.txt .png .wav .mp4 .zip","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://sn1987a-1.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"模拟与数字电路期中复习","slug":"模拟与数字电路复习","date":"2021-11-05T15:42:30.000Z","updated":"2023-09-23T13:15:11.002Z","comments":true,"path":"posts/15234.html","link":"","permalink":"http://sn1987a-1.github.io/posts/15234.html","excerpt":"","text":"模拟与数字电路[TOC] 2022.1.15 模拟与数字电路期末考试2021.11.11期中考试主要内容： 数字逻辑概论: 数值转换 二进制数的算术运算 逻辑代数&amp;HDL基础 反演规则 对偶规则 最大项/最小项 表达式化简 直接化简 卡诺图 逻辑函数表示方法之间的转换 真值表 表达式 逻辑图 波形图 逻辑门电路 组合逻辑电路/PLD✨ 锁存器和触发器✨ 时序逻辑电路（仅包含同步时序电路）✨ 信号——数字部分；周期性；占空比：高电平占周期的百分比 进制进制：Binary Octal Hexadecimal（0x）二进制转换：“误差不大于$2^{-n}$” &lt;=&gt; “精确到小数点第n位” 第n位“四舍五入”即可 二进制的算术运算：补码=原码取反+1；补码表示范围$-2^{n-1}~2^{n-1}-1$ 补码转原码：从右往左找到第一个‘1’，将这个1之前的取反，该数字和之后的保持原值即可。 (X+Y)_补=(X)_补+(Y)_补 (X-Y)_补=(X)_补-\\overline{(Y)_补}+1溢出：运算结果超出补码的表示范围 ​ 出现场合：同号相加，异号相减———&gt;判断结果是否正确（是否溢出）：判断计算过程中符号位和次高位的进位情况，当且仅当符号位有进位且次高位无进位时计算结果溢出。 溢出解决方案—-符号拓展：通过利用两个或多个符号位，初始统一置0或1，最终结果看第一位的状态。 BCD码（无特殊说明BCD码均指8421码）有权码：8421码，5421码，2421码（数字代表各位的权重） 无权码：余3码，余3循环码 余3循环码：（0~9） 数值 0 1 2 3 4 5 6 7 8 9 余3循环码 0010 0110 0111 0101 0100 1100 1101 1111 1110 1010 格雷码编码顺序依次变化时，相邻代码有且仅有一位不同，最大和最小之间也差一位，也称循环码（余3循环码也满足该条件）（0~15） 格雷码——&gt;二进制码转化：从最高位到最低位依次相加 数值 0 1 2 3 4 5 6 7 8 9 A B C D E F 格雷码 0000 0001 0011 0010 0110 0111 0101 0100 1100 1101 1111 1110 1010 1011 1001 1000 二进制码 0000 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111 进制转换： 任意进制-&gt;十进制：按位权展开后相加 (N)_R=\\sum_{i=-m}^{n-1}k_i*R^i ​ 2.十进制-&gt;任意进制： ​ 整数部分：辗转除基取余，先得较低有效位 ​ 小数部分：辗转乘积取整，先得最高有效位 逻辑代数基本定律： 交换律 A B=B A; A+B=B+A; 结合律 A(BC)=(AB)C; A+(B+C)=(A+B)+C; 分配律 A(B+C)=AB+AC; A+BC=(A+B)(A+C); 吸收律 A+A B=A; A(A+B)=A; 反演律 $\\overline{A+B}=\\overline {A}*\\overline {B}$ ; $\\overline{AB}=\\overline{A}+\\overline{B};$ 代入规则:在任一逻辑恒等式中,若以一个逻辑表达式代替恒等式两边所有出现的某一变量,则所得表达式依然成立.利用该结论可以把上述定律推广到n元的情况,即反演律可以写成: \\overline{A_1*A_2*...*A_n}=\\overline{A_1}+\\overline{A_2}+...+\\overline{A_n} \\overline{A_1+A_2+...+A_n}=\\overline{A_1}*\\overline{A_2}*...*\\overline{A_n}反演和对偶反演规则:对于任意表达式Y,将所有表达式中的’*’和’+’互换,将所有的’0’与’1’互换,把逻辑变量取反. 对偶规则:对于任意表达式Y,将所有表达式中的’*’和’+’互换,但不改变所有的’0’与’1’互换和逻辑变量. 利用对偶规则可以对上述基本定律进行拓展. 逻辑表达式对于一个逻辑函数,有多个逻辑表达式:(下以/AB+A/C为例) 与或式——-$\\overline {AB}+A\\overline C;$ 或与式———$(A+\\overline B)*(\\overline A+C)$ 与非-与非式———$\\overline {\\overline{\\overline AB}\\ \\ \\overline {A\\overline C}}$————-最简与或式求两次反 或非-或非式———$\\overline {(\\overline A+B)+(\\overline A+\\overline C)}$———最简或与式求两次反 与或非式———$\\overline {\\overline A\\ \\overline B+AC}$—————先求/Y的最简与或式,然后求反 最小项与最大项最小项:包含全部输入变量的乘积项,每个变量均以自身变量或反变量出现一次.对于n变量逻辑函数,共有2^n个最小项,记为mi,其中i为最小项的编号[1]. [1]编号:编号方法:原变量和反变量分别带表1和0,带入逻辑表达式得到的二进制数对应的十进制数记为编号i. 对于任意一个最小项,有且仅有一组变量使得mi=1成立,且对于不同的i,对应不同的变量; 全体最小项的并恒等于1; 任意两个最小项的交恒等于0; 最大项:包含全部输入变量的或项,每个变量均以自身变量或反变量出现一次.对于n变量逻辑函数,共有2^n个最大项,记为Mi,其中i为最大项的编号[2]. [2]编号:编号方法:原变量和反变量分别带表1和0,带入逻辑表达式得到的二进制数取反对应的十进制数记为编号i. 性质可以和最小项类似 最大项和最小项的关系: \\overline{M_i}=m_i; M_i=\\overline{m_i}卡诺图卡诺图通常用在逻辑变量在5以内的情况. 卡诺图物理上相邻的逻辑变量在逻辑上相邻(上下相邻,左右相邻,,循环相邻,对角不相邻)——-循环码 无关项x:不允许或不可能出现的最小项/对应的函数值是任意值. 卡诺图化简逻辑表达式 规范作图： 00 01 11 10顺序 注明各个逻辑变量名称 画圈标记—-写对应表达式 最简或与式——圈0取反 圈0取反后不一定是原问题的最简与或式.(?) 逻辑门电路PMOS:高电平不导通,低电平导通.不能接地 NMOS:高电平导通,低电平不导通,不能接高电平 非门:2个CMOS;与非门/或非门:4个CMOS;与门/或门:6个COMS 组合逻辑电路定义:对于一个逻辑电路,在任何一个时刻的输出状态只与输入状态有关,与电路自身状态无关. 电路功能分析思路: 根据输入输出写出各级逻辑表达式,直到输入和输出信号的逻辑表达式; 将各个逻辑表达式化简和变换得到最简表达式; 根据表达式列出真值表; 根据真值表和最简逻辑表达式对组合逻辑电路进行分析,最后确定其功能. 组合逻辑电路设计过程 明确实际问题的逻辑功能,确定输入输出和表示符号; 根据对电路逻辑功能的要求写出真值表; 利用真值表得出逻辑表达式并进程化简变换;(卡诺图) 利用得到的逻辑表达式画出电路图. 画波形图要点: 画出原题的波形,画出时钟信号的边缘的虚线… 典型组合逻辑电路编码器优先编码器CD4532: 8信号输入3信号输出; 输入输出均以高电平有效; EI/EO:输入/输出使能端,均高电平有效,否则输出端均为低电平,EI为低电平时GS,EO必定是低电平, EI是1且输入均为低电平时EO输出为1,可以用于连接下一编码器的使能输入端```````````` ; GS:编码工作状态:EI是一且至少有一个高电平输入(表明正在工作)时为1; 优先级:I7&gt;I6&gt;…&gt;I0. 译码器74x138/74x139 输入输出低电平有效 E_3高电平有效 数据分配器数据选择器数值比较器基本算术电路 半加器 全加器 多位数加法器(串行进位加法器/超前进位加法器) PLD分类 PROM 或阵列可编程逻辑 PLA 与或阵列均可编程逻辑 PAL与阵列可编程逻辑 锁存器和触发器细节: 相对于锁存器,触发器的不同在于沿时钟边沿触发 画图时时钟信号小三角;上升沿一般用CP表示;下降沿/CP;有圆圈通常表示下降沿触发. 激励方程: SR ff:Q^{n+1}=S+\\overline RQ^n(SR=0) Dff: Q^{n+1}=D JKff:Q^{n+1}=J\\overline {Q^n}+\\overline KQ^n时序逻辑电路时序逻辑电路分析Mealy型:输出是当前状态和输入的函数 Moore型:输出是当前状态的函数 分析思路 根据逻辑图写出逻辑方程 输出方程(判断Mealy/Moore) 激励方程:每个触发器的输入驱动方程(J/K=…) 状态方程:激励方程代入触发器的特征方程得到(Q(n-1)=…) 列出状态表_根据mealy/moore型画出对应的表——-&gt;画出状态图(图例!)/时序图 最后确定电路的逻辑功能 时序逻辑电路设计 给定逻辑功能的要求（文字描述或者是波形图）， 求相应的逻辑电路 设计的一般步骤 建立原始状态图（状态可以用易懂或易写的方式表示）和原始状态表 状态化简（在面对同输入得到同输出和同次态NS的现 Q 态是等价的) 状态编码 求状态方程和输出方程 检查自启动 选择触发器类型，求激励方程（激励表或其他方法） 画出逻辑图 尽量要求自己设计同步时序电路，因为后面在写verilog的时候一般都用统一的时钟 另外异步时序电路输出信号质量差，工作速度低 以上内容为期中考试主要内容，其中的逻辑电路分析和设计的重难点在期末考试中仍会涉及 期末考试额外的内容： 数字系统设计 数字系统结构 算术逻辑单元 寄存器传送 具体问题求解：最大值/排序/乘法电路 Verilog HDL Timing Analysis &amp; Synchronization 存储器，PLD，ListProcessor 二极管 三极管 基本放大电路 集成运放 逻辑门电路 ADC和DAC Verilog HDL/FSM常量表示形式： 整数型&lt;+/-&gt;&lt;位宽&gt;’&lt;基数符号(D/d,B/b,O/o,H/h)&gt;&lt;数值&gt; 实数型：1·科学计数法 2·十进制计数法 符号常量定义 parameter 数据变量类型： net(wire) register(reg) 定义格式： wire/reg [MSB/LSB] r1,r2,... 赋值语句：连续赋值语句assign；过程块赋值inital/always 常用语法（过程块赋值内）case/if else/begin end 模块实例化1.位置映射modulename M(A,B,C)；2.名称映射modulename M(.A(a),.C(c),.B(b))——不可混用 运算符 算术运算符 逐位计算 关系运算符 位运算符：~ ,&amp;,^ , | , ^~ / ~^（同或） 逻辑运算符：&amp;&amp;，！，|| 位拼接符：{, , } {n{}} 移位运算符：&gt;&gt;,&lt;&lt;,&gt;&gt;&gt;(算数右移) 缩位运算符（单目运算符）：&amp;，~&amp;，| ，~|，^, ^~, ~ ^ 条件运算符：？： 运算符优先级= = module (input i,output o,inout io); wire ...; parameter M=...; reg [M:m]...; assign ...; modulename name(i,o); initial begin ...; end always @(...) begin if ...; else ...; case (敏感表达式) 1:...; 2:...; ... default:...; endcase end endmodule 使用if/case语句时应该避免出现锁存器。 组合逻辑：阻塞赋值（blocking） ：‘=’块内赋值语句顺序执行 时序逻辑：非阻塞赋值（non-locking）：‘&lt;=’块内赋值语句并发进行 FSM 一段式/两段式/三段式 CS：现态；NS：次态；OUT：输出 两段式：一个时序过程描述CS，另一个组合描述NS和OUT 三段式：两个时序描述CS和OUT，一个组合过程描述NS 时序逻辑电路2寄存器寄存器是若干具有相同外观电路结构的共享时钟和控制信号的触发器 普通寄存器/移位寄存器 74x194:双向通用移位寄存器 功能表： 不添加其他逻辑门即可实现位拓展 应用：实现序列检测 计数器累计时钟脉冲次数，可以用来分频，定时，产生节拍脉冲 模：循环遍历的有效状态数 异步递增计数器：电路简单，易于拓展，但工作效率低，不适用 同步递增计数器： 74x161 74x160:模10计数器，与74x161相似 任意进制计数器构成 •用N进制计数器构成 M 进制计数器 •若 M &lt; N ，可在计数过程中设法跳过 N-M 个多余状态 ​ –反馈清零法，简称清零法 ​ –反馈置数法，简称置数法 •若 M &gt; N ，用多片 N 进制计数器级连，配合清零 / 置数法构成 要注意同步清零和异步清零清零时的数值是不一致的，通常同步+1=异步，置数同理——可以画状态图，异步的临界状态可以画虚线 用移位寄存器实现计数器，如环形计数器：将串行输入与串行输出直接相连，计数状态等于寄存器的位数。 扭环型计数器：约翰孙计数器，计数状态是环形计数器的2倍 有效循环：每次状态转换只更改一位 数字系统开关去抖动 数字系统组成：Data Path+Control Unit 实例：时序二进制乘法器，求最大值，排序","categories":[{"name":"数字电路","slug":"数字电路","permalink":"http://sn1987a-1.github.io/categories/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"}]},{"title":"线性筛","slug":"Algorithm","date":"2021-10-24T15:43:35.000Z","updated":"2023-09-23T13:16:30.242Z","comments":true,"path":"posts/15547.html","link":"","permalink":"http://sn1987a-1.github.io/posts/15547.html","excerpt":"","text":"线性筛的理解和应用最近在准备相关算法竞赛，正好班里有写博客的活动，就在此记录下自己菜不成声学习的过程。&gt;v&lt; 为算出小于等于n的素数的个数，较自然也是最暴力的的方法便是对每个小于n的正整数进行判定，这样的方法显然达到最优的复杂度，暴力硬解的结果无疑是最终喜提“Time Limit Exceeded”。 为提高算法效率，就要引入“筛”的思想——主要思想是：我们选出一个数n时无论n是素数还是合数，2n,3n,..都是合数，我们无需对这类数进行是否为素数的判断。 Eratosthenes 筛法 （埃拉托斯特尼筛法，简称埃氏筛）埃氏筛算法的主要思想是：如果我们从小到大考虑每个数，然后同时把当前这个数的所有（比自己大的）倍数记为合数，那么运行结束的时候没有被标记的数就是素数了。具体算法如下： int Eratosthenes(int n) { int p = 0; for (int i = 0; i &lt;= n; ++i) is_prime[i] = 1; is_prime[0] = is_prime[1] = 0; for (int i = 2; i &lt;= n; ++i) { if (is_prime[i]) { prime[p++] = i; // prime[p]是i,后置自增运算代表当前素数数量 for (int j = i * i; j &lt;= n; j += i) // 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i // 的倍数开始，提高了运行速度 is_prime[j] = 0; //是i的倍数的均不是素数 } } return p; } 埃氏筛通常可以称为普通筛，结构比较简单，也比较容易理解，其核心就是对找到的素数的倍数通过一次循环进行标记，虽然要额外占用O(n)的内存空间保存标记，但非常高效地减少了程序复杂度。 我们应该注意到，埃氏筛在对数字进行标记筛选时，存在重复筛选，比如6既可以被2筛掉，又可以被3筛掉。原因：任意一个整数可以写成一些素数的乘积 n=p1^ip2^jp3^k其中p1&lt;p2&lt;p3，这样这个数n能被p1,p2和p3筛掉,反复被标记，尤其在n比较大的时候，n可能有相当多个素因子，被多次标记，显然浪费了时间。 Euler筛法(线性筛)基于普通筛的不足之处，Euler对其做出了修改——直观地来说，当我们用埃氏筛法对一个素数的n倍进行筛选时，若正在被标记的这个倍数已经足够大，大到超过一特定的数字后，那这个数一定有更大的素因子，能在后续过程中再次被标记，此时就可以停止循环，算法继续对下一个未标记的数进行是否为素数的判断。 通过观察不难发现，若当前正在处理n的i倍数in，i能整除n，那么i与下一个要进行筛选的数的乘积这个合数肯定会被n乘以某个数提前筛掉。因此这里的i便是我们要找的“特定的数字”，利用这一数字提前break掉循环，可以使得每个数字均被筛选一次，将时间复杂度降到最低，这也就是Euler筛的算法思想，实现代码如下所示。 void init() { phi[1] = 1; for (int i = 2; i &lt; MAXN; ++i) { if (!vis[i]) { phi[i] = i - 1; pri[cnt++] = i; } for (int j = 0; j &lt; cnt; ++j) { if (1ll * i * pri[j] &gt;= MAXN) break; vis[i * pri[j]] = 1; if (i % pri[j]) { phi[i * pri[j]] = phi[i] * (pri[j] - 1); } else { // i % pri[j] == 0 // 换言之，i 之前被 pri[j] 筛过了 // 由于 pri 里面质数是从小到大的，所以 i 乘上其他的质数的结果一定会被 // pri[j] 的倍数筛掉，就不需要在这里先筛一次，所以这里直接 break // 掉就好了 phi[i * pri[j]] = phi[i] * pri[j]; break; } } } } 关键之处在：if(i%prime[j]==0) break; 这句代码保证了每个数最多被筛一次，将时间复杂度降到了线性。 证：prime[]数组中的素数是递增的,当i能整除prime[j]，那么iprime[j+1]这个合数肯定会被prime[j]乘以某个数筛掉。因此，这里直接break掉，将iprime[j+1]及之后的给后面的数去筛。这种方法能保证每个数只被筛一遍，又能保证每个数都被筛到。 为了更好的理解，画出前面几次筛的情况: 一般来说，当筛选范围n较小时，埃氏筛和欧氏筛复杂度较相近，甚至埃氏筛表现更好，但随着n的增大，欧氏筛的优越性也逐渐体现出来，可以达到埃氏筛3-4倍的速度。 参考： 1.线性筛的理解及应用 - Rogn - 博客园 (cnblogs.com) 2.线性筛_历尽千帆-CSDN博客_线性筛","categories":[{"name":"算法","slug":"算法","permalink":"http://sn1987a-1.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://sn1987a-1.github.io/tags/%E7%AE%97%E6%B3%95/"}]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://sn1987a-1.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"编译原理","slug":"编译原理","permalink":"http://sn1987a-1.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"Golang","slug":"Golang","permalink":"http://sn1987a-1.github.io/categories/Golang/"},{"name":"前端","slug":"前端","permalink":"http://sn1987a-1.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"HPC","slug":"HPC","permalink":"http://sn1987a-1.github.io/categories/HPC/"},{"name":"AI","slug":"AI","permalink":"http://sn1987a-1.github.io/categories/AI/"},{"name":"区块链","slug":"区块链","permalink":"http://sn1987a-1.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"代数结构","slug":"代数结构","permalink":"http://sn1987a-1.github.io/categories/%E4%BB%A3%E6%95%B0%E7%BB%93%E6%9E%84/"},{"name":"人工智能","slug":"人工智能","permalink":"http://sn1987a-1.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"CSII","slug":"CSII","permalink":"http://sn1987a-1.github.io/categories/CSII/"},{"name":"OS","slug":"OS","permalink":"http://sn1987a-1.github.io/categories/OS/"},{"name":"git","slug":"git","permalink":"http://sn1987a-1.github.io/categories/git/"},{"name":"WSL2","slug":"WSL2","permalink":"http://sn1987a-1.github.io/categories/WSL2/"},{"name":"数据结构","slug":"数据结构","permalink":"http://sn1987a-1.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"图论","slug":"图论","permalink":"http://sn1987a-1.github.io/categories/%E5%9B%BE%E8%AE%BA/"},{"name":"数字电路","slug":"数字电路","permalink":"http://sn1987a-1.github.io/categories/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/"},{"name":"算法","slug":"算法","permalink":"http://sn1987a-1.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://sn1987a-1.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"Gin","slug":"Gin","permalink":"http://sn1987a-1.github.io/tags/Gin/"},{"name":"Vue","slug":"Vue","permalink":"http://sn1987a-1.github.io/tags/Vue/"},{"name":"并行数据结构","slug":"并行数据结构","permalink":"http://sn1987a-1.github.io/tags/%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"CGO","slug":"CGO","permalink":"http://sn1987a-1.github.io/tags/CGO/"},{"name":"Go","slug":"Go","permalink":"http://sn1987a-1.github.io/tags/Go/"},{"name":"chatbot","slug":"chatbot","permalink":"http://sn1987a-1.github.io/tags/chatbot/"},{"name":"WSL2","slug":"WSL2","permalink":"http://sn1987a-1.github.io/tags/WSL2/"},{"name":"图论","slug":"图论","permalink":"http://sn1987a-1.github.io/tags/%E5%9B%BE%E8%AE%BA/"},{"name":"算法","slug":"算法","permalink":"http://sn1987a-1.github.io/tags/%E7%AE%97%E6%B3%95/"}]}